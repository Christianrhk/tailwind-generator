<!DOCTYPE html>
<!--[if IE 7]>
<html class="ie ie7" lang="en-US">
<![endif]-->
<!--[if IE 8]>
<html class="ie ie8" lang="en-US">
<![endif]-->
<!--[if !(IE 7) & !(IE 8)]><!-->
<html lang="en-US">
<!--<![endif]-->
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<title>programming | Noise</title>
<link rel="profile" href="https://gmpg.org/xfn/11">
<!--[if lt IE 9]>
	<script src="https://noise.getoto.net/wp-content/themes/z/js/html5.js"></script>
	<![endif]-->
<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//fonts.googleapis.com' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel="alternate" type="application/rss+xml" title="Noise &raquo; Feed" href="https://noise.getoto.net/feed/" />
<link rel="alternate" type="application/rss+xml" title="Noise &raquo; Comments Feed" href="https://noise.getoto.net/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Noise &raquo; programming Tag Feed" href="https://noise.getoto.net/tag/programming/feed/" />

<script src="//www.googletagmanager.com/gtag/js?id=UA-1237038-1" data-cfasync="false" data-wpfc-render="false" type="text/javascript" async></script>
<script data-cfasync="false" data-wpfc-render="false" type="text/javascript">
				var mi_version = '8.7.0';
				var mi_track_user = true;
				var mi_no_track_reason = '';
				
								var disableStrs = [
															'ga-disable-UA-1237038-1',
									];

				/* Function to detect opted out users */
				function __gtagTrackerIsOptedOut() {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						if ( document.cookie.indexOf( disableStrs[ index ] + '=true' ) > -1 ) {
							return true;
						}
					}

					return false;
				}

				/* Disable tracking if the opt-out cookie exists. */
				if ( __gtagTrackerIsOptedOut() ) {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						window[ disableStrs[ index ] ] = true;
					}
				}

				/* Opt-out function */
				function __gtagTrackerOptout() {
					for ( var index = 0; index < disableStrs.length; index++ ) {
						document.cookie = disableStrs[ index ] + '=true; expires=Thu, 31 Dec 2099 23:59:59 UTC; path=/';
						window[ disableStrs[ index ] ] = true;
					}
				}

				if ( 'undefined' === typeof gaOptout ) {
					function gaOptout() {
						__gtagTrackerOptout();
					}
				}
								window.dataLayer = window.dataLayer || [];

				window.MonsterInsightsDualTracker = {
					helpers: {},
					trackers: {},
				};
				if ( mi_track_user ) {
					function __gtagDataLayer() {
						dataLayer.push( arguments );
					}

					function __gtagTracker( type, name, parameters ) {
						if (!parameters) {
							parameters = {};
						}

						if (parameters.send_to) {
							__gtagDataLayer.apply( null, arguments );
							return;
						}

						if ( type === 'event' ) {
							
															parameters.send_to = monsterinsights_frontend.ua;
								__gtagDataLayer( type, name, parameters );
													} else {
							__gtagDataLayer.apply( null, arguments );
						}
					}
					__gtagTracker( 'js', new Date() );
					__gtagTracker( 'set', {
						'developer_id.dZGIzZG' : true,
											} );
															__gtagTracker( 'config', 'UA-1237038-1', {"forceSSL":"true","link_attribution":"true"} );
										window.gtag = __gtagTracker;											(function () {
							/* https://developers.google.com/analytics/devguides/collection/analyticsjs/ */
							/* ga and __gaTracker compatibility shim. */
							var noopfn = function () {
								return null;
							};
							var newtracker = function () {
								return new Tracker();
							};
							var Tracker = function () {
								return null;
							};
							var p = Tracker.prototype;
							p.get = noopfn;
							p.set = noopfn;
							p.send = function (){
								var args = Array.prototype.slice.call(arguments);
								args.unshift( 'send' );
								__gaTracker.apply(null, args);
							};
							var __gaTracker = function () {
								var len = arguments.length;
								if ( len === 0 ) {
									return;
								}
								var f = arguments[len - 1];
								if ( typeof f !== 'object' || f === null || typeof f.hitCallback !== 'function' ) {
									if ( 'send' === arguments[0] ) {
										var hitConverted, hitObject = false, action;
										if ( 'event' === arguments[1] ) {
											if ( 'undefined' !== typeof arguments[3] ) {
												hitObject = {
													'eventAction': arguments[3],
													'eventCategory': arguments[2],
													'eventLabel': arguments[4],
													'value': arguments[5] ? arguments[5] : 1,
												}
											}
										}
										if ( 'pageview' === arguments[1] ) {
											if ( 'undefined' !== typeof arguments[2] ) {
												hitObject = {
													'eventAction': 'page_view',
													'page_path' : arguments[2],
												}
											}
										}
										if ( typeof arguments[2] === 'object' ) {
											hitObject = arguments[2];
										}
										if ( typeof arguments[5] === 'object' ) {
											Object.assign( hitObject, arguments[5] );
										}
										if ( 'undefined' !== typeof arguments[1].hitType ) {
											hitObject = arguments[1];
											if ( 'pageview' === hitObject.hitType ) {
												hitObject.eventAction = 'page_view';
											}
										}
										if ( hitObject ) {
											action = 'timing' === arguments[1].hitType ? 'timing_complete' : hitObject.eventAction;
											hitConverted = mapArgs( hitObject );
											__gtagTracker( 'event', action, hitConverted );
										}
									}
									return;
								}

								function mapArgs( args ) {
									var arg, hit = {};
									var gaMap = {
										'eventCategory': 'event_category',
										'eventAction': 'event_action',
										'eventLabel': 'event_label',
										'eventValue': 'event_value',
										'nonInteraction': 'non_interaction',
										'timingCategory': 'event_category',
										'timingVar': 'name',
										'timingValue': 'value',
										'timingLabel': 'event_label',
										'page' : 'page_path',
										'location' : 'page_location',
										'title' : 'page_title',
									};
									for ( arg in args ) {
																				if ( ! ( ! args.hasOwnProperty(arg) || ! gaMap.hasOwnProperty(arg) ) ) {
											hit[gaMap[arg]] = args[arg];
										} else {
											hit[arg] = args[arg];
										}
									}
									return hit;
								}

								try {
									f.hitCallback();
								} catch ( ex ) {
								}
							};
							__gaTracker.create = newtracker;
							__gaTracker.getByName = newtracker;
							__gaTracker.getAll = function () {
								return [];
							};
							__gaTracker.remove = noopfn;
							__gaTracker.loaded = true;
							window['__gaTracker'] = __gaTracker;
						})();
									} else {
										console.log( "" );
					( function () {
							function __gtagTracker() {
								return null;
							}
							window['__gtagTracker'] = __gtagTracker;
							window['gtag'] = __gtagTracker;
					} )();
									}
			</script>

<link rel='stylesheet' id='wp-block-library-css' href='https://noise.getoto.net/wp-includes/css/dist/block-library/style.min.css?ver=5.8.4' type='text/css' media='all' />
<link rel='stylesheet' id='twentyfourteen-lato-css' href='https://fonts.googleapis.com/css?family=Lato%3A300%2C400%2C700%2C900%2C300italic%2C400italic%2C700italic&#038;subset=latin%2Clatin-ext' type='text/css' media='all' />
<link rel='stylesheet' id='genericons-css' href='https://noise.getoto.net/wp-content/themes/z/genericons/genericons.css?ver=3.0.3' type='text/css' media='all' />
<link rel='stylesheet' id='twentyfourteen-style-css' href='https://noise.getoto.net/wp-content/themes/z/style.css?ver=5.8.4' type='text/css' media='all' />
<!--[if lt IE 9]>
<link rel='stylesheet' id='twentyfourteen-ie-css'  href='https://noise.getoto.net/wp-content/themes/z/css/ie.css?ver=20131205' type='text/css' media='all' />
<![endif]-->
<script type='text/javascript' src='https://noise.getoto.net/wp-content/plugins/google-analytics-for-wordpress/assets/js/frontend-gtag.min.js?ver=8.7.0' id='monsterinsights-frontend-script-js'></script>
<script data-cfasync="false" data-wpfc-render="false" type="text/javascript" id='monsterinsights-frontend-script-js-extra'>/* <![CDATA[ */
var monsterinsights_frontend = {"js_events_tracking":"true","download_extensions":"doc,pdf,ppt,zip,xls,docx,pptx,xlsx","inbound_paths":"[]","home_url":"https:\/\/noise.getoto.net","hash_tracking":"false","ua":"UA-1237038-1","v4_id":""};/* ]]> */
</script>
<script type='text/javascript' src='https://noise.getoto.net/wp-includes/js/jquery/jquery.min.js?ver=3.6.0' id='jquery-core-js'></script>
<script type='text/javascript' src='https://noise.getoto.net/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2' id='jquery-migrate-js'></script>
<style type="text/css" id="wp-custom-css">
			.crap {color: black}		</style>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-6472219848970595",
          enable_page_level_ads: true
     });
</script></head>
<body class="archive tag tag-programming tag-1255 group-blog masthead-fixed list-view full-width">
<div id="page" class="hfeed site">
<header id="masthead" class="site-header" role="banner">
<div class="header-main">
<h1 class="site-title"><a href="https://noise.getoto.net/" rel="home">Noise</a></h1>
<div class="search-toggle">
<a href="#search-container" class="screen-reader-text" aria-expanded="false" aria-controls="search-container">Search</a>
</div>
<nav id="primary-navigation" class="site-navigation primary-navigation" role="navigation">
<button class="menu-toggle">Primary Menu</button>
<a class="screen-reader-text skip-link" href="#content">Skip to content</a>
<div class="menu-small-container"><ul id="primary-menu" class="nav-menu"><li id="menu-item-208616" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-208616"><a href="https://noise.getoto.net/">Home</a></li>
<li id="menu-item-208614" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-208614"><a href="https://noise.getoto.net/about/">About</a></li>
</ul></div> </nav>
</div>
<div id="search-container" class="search-box-wrapper hide">
<div class="search-box">
<form role="search" method="get" class="search-form" action="https://noise.getoto.net/">
<label>
<span class="screen-reader-text">Search for:</span>
<input type="search" class="search-field" placeholder="Search &hellip;" value="" name="s" />
</label>
<input type="submit" class="search-submit" value="Search" />
</form> </div>
</div>
</header>
<div id="main" class="site-main">
<section id="primary" class="content-area">
<div id="content" class="site-content" role="main">
<header class="archive-header">
<h1 class="archive-title">Tag Archives: programming</h1>
</header>
<article id="post-1397467" class="post-1397467 post type-post status-publish format-standard hentry tag-deep-dive tag-linux tag-programming tag-security">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2022/06/29/live-patching-security-vulnerabilities-inside-the-linux-kernel-with-ebpf-linux-security-module/" rel="bookmark">Live-patching security vulnerabilities inside the Linux kernel with eBPF Linux Security Module</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2022/06/29/live-patching-security-vulnerabilities-inside-the-linux-kernel-with-ebpf-linux-security-module/" rel="bookmark"><time class="entry-date" datetime="2022-06-29T14:45:00+03:00">2022-06-29</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/frederick-lawler/" rel="author">Frederick Lawler</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Frederick Lawler">Frederick Lawler</a> original <a href="https://blog.cloudflare.com/live-patch-security-vulnerabilities-with-ebpf-lsm/">https://blog.cloudflare.com/live-patch-security-vulnerabilities-with-ebpf-lsm/</a></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2022/06/image1-57.png" class="kg-image" alt="Live-patching security vulnerabilities inside the Linux kernel with eBPF Linux Security Module"></figure>
<p><img src="https://blog.cloudflare.com/content/images/2022/06/Linux---Warp.png" alt="Live-patching security vulnerabilities inside the Linux kernel with eBPF Linux Security Module"></p>
<p><a href="https://www.kernel.org/doc/html/latest/admin-guide/LSM/index.html">Linux Security Modules</a> (LSM) is a hook-based framework for implementing security policies and Mandatory Access Control in the Linux kernel. Until recently users looking to implement a security policy had just two options. Configure an existing LSM module such as AppArmor or SELinux, or write a custom kernel module.</p>
<p><a href="https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.7">Linux 5.7</a> introduced a third way: <a href="https://docs.kernel.org/bpf/prog_lsm.html">LSM extended Berkeley Packet Filters (eBPF)</a> (LSM BPF for short). LSM BPF allows developers to write granular policies without configuration or loading a kernel module. LSM BPF programs are verified on load, and then executed when an LSM hook is reached in a call path.</p>
<h2 id="let-s-solve-a-real-world-problem">Let’s solve a real-world problem</h2>
<p>Modern operating systems provide facilities allowing &#8220;partitioning&#8221; of kernel resources. For example FreeBSD has &#8220;jails&#8221;, Solaris has &#8220;zones&#8221;. Linux is different &#8211; it provides a set of seemingly independent facilities each allowing isolation of a specific resource. These are called &#8220;namespaces&#8221; and have been growing in the kernel for years. They are the base of popular tools like Docker, lxc or firejail. Many of the namespaces are uncontroversial, like the UTS namespace which allows the host system to hide its hostname and time. Others are complex but straightforward &#8211; NET and NS (mount) namespaces are known to be hard to wrap your head around. Finally, there is this very special very curious USER namespace.</p>
<p>USER namespace is special, since it allows the owner to operate as &#8220;root&#8221; inside it. How it works is beyond the scope of this blog post, however, suffice to say it&#8217;s a foundation to having tools like Docker to not operate as true root, and things like rootless containers.</p>
<p>Due to its nature, allowing unpriviledged users access to USER namespace always carried a great security risk.  One such risk is privilege escalation.</p>
<p>Privilege escalation is a common attack surface for operating systems. One way users may gain privilege is by mapping their namespace to the root namespace via the unshare <a href="https://en.wikipedia.org/wiki/System_call">syscall</a> and specifying the <em>CLONE_NEWUSER</em> flag. This tells unshare to create a new user namespace with full permissions, and maps the new user and group ID to the previous namespace. You can use the <a href="https://man7.org/linux/man-pages/man1/unshare.1.html">unshare(1)</a> program to map root to our original namespace:</p>
<p></p>
<pre><code class="language-sh">$ id
uid=1000(fred) gid=1000(fred) groups=1000(fred) …
$ unshare -rU
# id
uid=0(root) gid=0(root) groups=0(root),65534(nogroup)
# cat /proc/self/uid_map
         0       1000          1
</code></pre>
<p></p>
<p>In most cases using unshare is harmless, and is intended to run with lower privileges. However, this syscall has been known to be used to <a href="https://nvd.nist.gov/vuln/detail/CVE-2022-0492">escalate privileges</a>.</p>
<p>Syscalls<em> clone</em> and <em>clone3</em> are worth looking into as they also have the ability to <em>CLONE_NEWUSER</em>. However, for this post we’re going to focus on unshare.</p>
<p>Debian solved this problem with this <a href="https://sources.debian.org/patches/linux/3.16.56-1+deb8u1/debian/add-sysctl-to-disallow-unprivileged-CLONE_NEWUSER-by-default.patch/"> &#8220;add sysctl to disallow unprivileged CLONE_NEWUSER by default&#8221;</a> patch, but it was not mainlined. Another similar patch <a href="https://lore.kernel.org/all/1453502345-30416-3-git-send-email-keescook@chromium.org/">&#8220;sysctl: allow CLONE_NEWUSER to be disabled&#8221;</a> attempted to mainline, and was met with push back. A critique is the <a href="https://lore.kernel.org/all/87poq5y0jw.fsf@x220.int.ebiederm.org/">inability to toggle this feature</a> for specific applications. In the article “<a href="https://lwn.net/Articles/673597/">Controlling access to user namespaces</a>” the author wrote: “&#8230; the current patches do not appear to have an easy path into the mainline.” And as we can see, the patches were ultimately not included in the vanilla kernel.</p>
<h2 id="our-solution-lsm-bpf">Our solution &#8211; LSM BPF</h2>
<p>Since upstreaming code that restricts USER namespace seem to not be an option, we decided to use LSM BPF to circumvent these issues. This requires no modifications to the kernel and allows us to express complex rules guarding the access.</p>
<h3 id="track-down-an-appropriate-hook-candidate">Track down an appropriate hook candidate</h3>
<p>First, let us track down the syscall we’re targeting. We can find the prototype in the <a href="https://elixir.bootlin.com/linux/v5.18/source/include/linux/syscalls.h#L608"><em>include/linux/syscalls.h</em></a> file. From there, it’s not as obvious to track down, but the line:</p>
<p></p>
<pre><code class="language-c">/* kernel/fork.c */
</code></pre>
<p></p>
<p>Gives us a clue of where to look next in <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/fork.c#L3201"><em>kernel/fork.c</em></a>. There a call to <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/fork.c#L3082"><em>ksys_unshare()</em></a> is made. Digging through that function, we find a call to <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/fork.c#L3129"><em>unshare_userns()</em></a>. This looks promising.</p>
<p>Up to this point, we’ve identified the syscall implementation, but the next question to ask is what hooks are available for us to use? Because we know from the <a href="https://man7.org/linux/man-pages/man2/unshare.2.html">man-pages</a> that unshare is used to mutate tasks, we look at the task-based hooks in <a href="https://elixir.bootlin.com/linux/v5.18/source/include/linux/lsm_hooks.h#L605"><em>include/linux/lsm_hooks.h</em></a>. Back in the function <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/user_namespace.c#L171"><em>unshare_userns()</em></a><em> </em>we saw a call to <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/cred.c#L252"><em>prepare_creds()</em></a>. This looks very familiar to the <a href="https://elixir.bootlin.com/linux/v5.18/source/include/linux/lsm_hooks.h#L624"><em>cred_prepare</em></a> hook. To verify we have our match via <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/cred.c#L291"><em>prepare_creds()</em></a>, we see a call to the security hook <a href="https://elixir.bootlin.com/linux/v5.18/source/security/security.c#L1706"><em>security_prepare_creds()</em></a><em> </em>which ultimately calls the hook:</p>
<p></p>
<pre><code class="language-c">…
rc = call_int_hook(cred_prepare, 0, new, old, gfp);
…
</code></pre>
<p></p>
<p>Without going much further down this rabbithole, we know this is a good hook to use because <em>prepare_creds()</em> is called right before <em>create_user_ns()</em> in <a href="https://elixir.bootlin.com/linux/v5.18/source/kernel/user_namespace.c#L181"><em>unshare_userns()</em></a> which is the operation we’re trying to block.</p>
<h3 id="lsm-bpf-solution">LSM BPF solution</h3>
<p>We’re going to compile with the <a href="https://nakryiko.com/posts/bpf-core-reference-guide/#defining-own-co-re-relocatable-type-definitions">eBPF compile once-run everywhere (CO-RE)</a> approach. This allows us to compile on one architecture and load on another. But we’re going to target x86_64 specifically. LSM BPF for ARM64 is still in development, and the following code will not run on that architecture. Watch the <a href="https://lore.kernel.org/bpf/">BPF mailing list</a> to follow the progress.</p>
<p>This solution was tested on kernel versions &gt;= 5.15 configured with the following:</p>
<p></p>
<pre><code>BPF_EVENTS
BPF_JIT
BPF_JIT_ALWAYS_ON
BPF_LSM
BPF_SYSCALL
BPF_UNPRIV_DEFAULT_OFF
DEBUG_INFO_BTF
DEBUG_INFO_DWARF_TOOLCHAIN_DEFAULT
DYNAMIC_FTRACE
FUNCTION_TRACER
HAVE_DYNAMIC_FTRACE
</code></pre>
<p></p>
<p>A boot option <code>lsm=bpf</code> may be necessary if <code>CONFIG_LSM</code> does not contain “bpf” in the list.</p>
<p>Let’s start with our preamble:</p>
<p><em>deny_unshare.bpf.c</em>:</p>
<p></p>
<pre><code class="language-c">#include &lt;linux/bpf.h&gt;
#include &lt;linux/capability.h&gt;
#include &lt;linux/errno.h&gt;
#include &lt;linux/sched.h&gt;
#include &lt;linux/types.h&gt;

#include &lt;bpf/bpf_tracing.h&gt;
#include &lt;bpf/bpf_helpers.h&gt;
#include &lt;bpf/bpf_core_read.h&gt;

#define X86_64_UNSHARE_SYSCALL 272
#define UNSHARE_SYSCALL X86_64_UNSHARE_SYSCALL
</code></pre>
<p></p>
<p>Next we set up our necessary structures for CO-RE relocation in the following way:</p>
<p><em>deny_unshare.bpf.c</em>:</p>
<p></p>
<pre><code class="language-c">…

typedef unsigned int gfp_t;

struct pt_regs {
	long unsigned int di;
	long unsigned int orig_ax;
} __attribute__((preserve_access_index));

typedef struct kernel_cap_struct {
	__u32 cap[_LINUX_CAPABILITY_U32S_3];
} __attribute__((preserve_access_index)) kernel_cap_t;

struct cred {
	kernel_cap_t cap_effective;
} __attribute__((preserve_access_index));

struct task_struct {
    unsigned int flags;
    const struct cred *cred;
} __attribute__((preserve_access_index));

char LICENSE[] SEC(&quot;license&quot;) = &quot;GPL&quot;;

…
</code></pre>
<p></p>
<p>We don’t need to fully-flesh out the structs; we just need the absolute minimum information a program needs to function. CO-RE will do whatever is necessary to perform the relocations for your kernel. This makes writing the LSM BPF programs easy!</p>
<p><em>deny_unshare.bpf.c</em>:</p>
<p></p>
<pre><code class="language-c">SEC(&quot;lsm/cred_prepare&quot;)
int BPF_PROG(handle_cred_prepare, struct cred *new, const struct cred *old,
             gfp_t gfp, int ret)
{
    struct pt_regs *regs;
    struct task_struct *task;
    kernel_cap_t caps;
    int syscall;
    unsigned long flags;

    // If previous hooks already denied, go ahead and deny this one
    if (ret) {
        return ret;
    }

    task = bpf_get_current_task_btf();
    regs = (struct pt_regs *) bpf_task_pt_regs(task);
    // In x86_64 orig_ax has the syscall interrupt stored here
    syscall = regs-&gt;orig_ax;
    caps = task-&gt;cred-&gt;cap_effective;

    // Only process UNSHARE syscall, ignore all others
    if (syscall != UNSHARE_SYSCALL) {
        return 0;
    }

    // PT_REGS_PARM1_CORE pulls the first parameter passed into the unshare syscall
    flags = PT_REGS_PARM1_CORE(regs);

    // Ignore any unshare that does not have CLONE_NEWUSER
    if (!(flags &amp; CLONE_NEWUSER)) {
        return 0;
    }

    // Allow tasks with CAP_SYS_ADMIN to unshare (already root)
    if (caps.cap[CAP_TO_INDEX(CAP_SYS_ADMIN)] &amp; CAP_TO_MASK(CAP_SYS_ADMIN)) {
        return 0;
    }

    return -EPERM;
}
</code></pre>
<p></p>
<p>Creating the program is the first step, the second is loading and attaching the program to our desired hook. There are several ways to do this: <a href="https://github.com/cilium/ebpf">Cilium ebpf</a> project, <a href="https://github.com/libbpf/libbpf-rs">Rust bindings</a>, and several others on the <a href="https://ebpf.io/projects/">ebpf.io</a> project landscape page. We’re going to use native libbpf.</p>
<p><em>deny_unshare.c</em>:</p>
<p></p>
<pre><code class="language-c">#include &lt;bpf/libbpf.h&gt;
#include &lt;unistd.h&gt;
#include &quot;deny_unshare.skel.h&quot;

static int libbpf_print_fn(enum libbpf_print_level level, const char *format, va_list args)
{
    return vfprintf(stderr, format, args);
}

int main(int argc, char *argv[])
{
    struct deny_unshare_bpf *skel;
    int err;

    libbpf_set_strict_mode(LIBBPF_STRICT_ALL);
    libbpf_set_print(libbpf_print_fn);

    // Loads and verifies the BPF program
    skel = deny_unshare_bpf__open_and_load();
    if (!skel) {
        fprintf(stderr, &quot;failed to load and verify BPF skeleton\n&quot;);
        goto cleanup;
    }

    // Attaches the loaded BPF program to the LSM hook
    err = deny_unshare_bpf__attach(skel);
    if (err) {
        fprintf(stderr, &quot;failed to attach BPF skeleton\n&quot;);
        goto cleanup;
    }

    printf(&quot;LSM loaded! ctrl+c to exit.\n&quot;);

    // The BPF link is not pinned, therefore exiting will remove program
    for (;;) {
        fprintf(stderr, &quot;.&quot;);
        sleep(1);
    }

cleanup:
    deny_unshare_bpf__destroy(skel);
    return err;
}
</code></pre>
<p></p>
<p>Lastly, to compile, we use the following Makefile:</p>
<p><em>Makefile</em>:</p>
<p></p>
<pre><code class="language-makefile">CLANG ?= clang-13
LLVM_STRIP ?= llvm-strip-13
ARCH := x86
INCLUDES := -I/usr/include -I/usr/include/x86_64-linux-gnu
LIBS_DIR := -L/usr/lib/lib64 -L/usr/lib/x86_64-linux-gnu
LIBS := -lbpf -lelf

.PHONY: all clean run

all: deny_unshare.skel.h deny_unshare.bpf.o deny_unshare

run: all
	sudo ./deny_unshare

clean:
	rm -f *.o
	rm -f deny_unshare.skel.h

#
# BPF is kernel code. We need to pass -D__KERNEL__ to refer to fields present
# in the kernel version of pt_regs struct. uAPI version of pt_regs (from ptrace)
# has different field naming.
# See: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=fd56e0058412fb542db0e9556f425747cf3f8366
#
deny_unshare.bpf.o: deny_unshare.bpf.c
	$(CLANG) -g -O2 -Wall -target bpf -D__KERNEL__ -D__TARGET_ARCH_$(ARCH) $(INCLUDES) -c $&lt; -o <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="486c08">[email&#160;protected]</a>
	$(LLVM_STRIP) -g <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="301470">[email&#160;protected]</a> # Removes debug information

deny_unshare.skel.h: deny_unshare.bpf.o
	sudo bpftool gen skeleton $&lt; &gt; <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="8aaeca">[email&#160;protected]</a>

deny_unshare: deny_unshare.c deny_unshare.skel.h
	$(CC) -g -Wall -c $&lt; -o <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="7155315f1e">[email&#160;protected]</a>
	$(CC) -g -o <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="d2f692">[email&#160;protected]</a> $(LIBS_DIR) <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="2703670948">[email&#160;protected]</a> $(LIBS)

.DELETE_ON_ERROR:
</code></pre>
<p></p>
<h3 id="result">Result</h3>
<p>In a new terminal window run:</p>
<p></p>
<pre><code class="language-sh">$ make run
…
LSM loaded! ctrl+c to exit.
</code></pre>
<p></p>
<p>In another terminal window, we’re successfully blocked!</p>
<p></p>
<pre><code class="language-sh">$ unshare -rU
unshare: unshare failed: Cannot allocate memory
$ id
uid=1000(fred) gid=1000(fred) groups=1000(fred) …
</code></pre>
<p></p>
<p>The policy has an additional feature to always allow privilege pass through:</p>
<p></p>
<pre><code class="language-sh">$ sudo unshare -rU
# id
uid=0(root) gid=0(root) groups=0(root)
</code></pre>
<p></p>
<p>In the unprivileged case the syscall early aborts. What is the performance impact in the privileged case?</p>
<h3 id="measure-performance">Measure performance</h3>
<p>We’re going to use a one-line unshare that’ll map the user namespace, and execute a command within for the measurements:</p>
<p></p>
<pre><code class="language-sh">$ unshare -frU --kill-child -- bash -c &quot;exit 0&quot;
</code></pre>
<p></p>
<p>With a resolution of CPU cycles for syscall unshare enter/exit, we’ll measure the following as root user:</p>
<ol>
<li>Command ran without the policy</li>
<li>Command run with the policy</li>
</ol>
<p>We’ll record the measurements with <a href="https://docs.kernel.org/trace/ftrace.html">ftrace</a>:</p>
<p></p>
<pre><code class="language-sh">$ sudo su
# cd /sys/kernel/debug/tracing
# echo 1 &gt; events/syscalls/sys_enter_unshare/enable ; echo 1 &gt; events/syscalls/sys_exit_unshare/enable
</code></pre>
<p></p>
<p>At this point, we’re enabling tracing for the syscall enter and exit for unshare specifically. Now we set the time-resolution of our enter/exit calls to count CPU cycles:</p>
<p></p>
<pre><code class="language-sh"># echo 'x86-tsc' &gt; trace_clock 
</code></pre>
<p></p>
<p>Next we begin our measurements:</p>
<p></p>
<pre><code class="language-sh"># unshare -frU --kill-child -- bash -c &quot;exit 0&quot; &amp;
[1] 92014
</code></pre>
<p></p>
<p>Run the policy in a new terminal window, and then run our next syscall:</p>
<p></p>
<pre><code class="language-sh"># unshare -frU --kill-child -- bash -c &quot;exit 0&quot; &amp;
[2] 92019
</code></pre>
<p></p>
<p>Now we have our two calls for comparison:</p>
<p></p>
<pre><code class="language-sh"># cat trace
# tracer: nop
#
# entries-in-buffer/entries-written: 4/4   #P:8
#
#                                _-----=&gt; irqs-off
#                               / _----=&gt; need-resched
#                              | / _---=&gt; hardirq/softirq
#                              || / _--=&gt; preempt-depth
#                              ||| / _-=&gt; migrate-disable
#                              |||| /     delay
#           TASK-PID     CPU#  |||||  TIMESTAMP  FUNCTION
#              | |         |   |||||     |         |
         unshare-92014   [002] ..... 762950852559027: sys_unshare(unshare_flags: 10000000)
         unshare-92014   [002] ..... 762950852622321: sys_unshare -&gt; 0x0
         unshare-92019   [007] ..... 762975980681895: sys_unshare(unshare_flags: 10000000)
         unshare-92019   [007] ..... 762975980752033: sys_unshare -&gt; 0x0

</code></pre>
<p></p>
<p>unshare-92014 used 63294 cycles.<br />unshare-92019 used 70138 cycles.</p>
<p>We have a 6,844 (~10%) cycle penalty between the two measurements. Not bad!</p>
<p>These numbers are for a single syscall, and add up the more frequently the code is called. Unshare is typically called at task creation, and not repeatedly during normal execution of a program. Careful consideration and measurement is needed for your use case.</p>
<h2 id="outro">Outro</h2>
<p>We learned a bit about what LSM BPF is, how unshare is used to map a user to root, and how to solve a real-world problem by implementing a solution in eBPF. Tracking down the appropriate hook is not an easy task, and requires a bit of playing and a lot of kernel code. Fortunately, that’s the hard part. Because a policy is written in C, we can granularly tweak the policy to our problem. This means one may extend this policy with an allow-list to allow certain programs or users to continue to use an unprivileged unshare. Finally, we looked at the performance impact of this program, and saw the overhead is worth blocking the attack vector.</p>
<p>“Cannot allocate memory” is not a clear error message for denying permissions. We proposed a <a href="https://lore.kernel.org/all/20220608150942.776446-1-fred@cloudflare.com/">patch</a> to propagate error codes from the <em>cred_prepare</em> hook up the call stack. Ultimately we came to the conclusion that a new hook is better suited to this problem. Stay tuned!</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/deep-dive/" rel="tag">deep dive</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/security/" rel="tag">security</a></span></footer></article>
<article id="post-1170772" class="post-1170772 post type-post status-publish format-standard hentry tag-compiler tag-deep-dive tag-linux tag-programming tag-software">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2021/09/10/how-to-execute-an-object-file-part-3/" rel="bookmark">How to execute an object file: Part 3</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2021/09/10/how-to-execute-an-object-file-part-3/" rel="bookmark"><time class="entry-date" datetime="2021-09-10T15:58:20+03:00">2021-09-10</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/ignat-korchagin/" rel="author">Ignat Korchagin</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Ignat Korchagin">Ignat Korchagin</a> original <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-3/">https://blog.cloudflare.com/how-to-execute-an-object-file-part-3/</a></p>
<p></p>
<h2 id="dealingwithexternallibraries">Dealing with external libraries</h2>
<p><img src="https://blog.cloudflare.com/content/images/2021/09/image1.jpg" alt="How to execute an object file: Part 3"></p>
<p>In the <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-2/">part 2 of our series</a> we learned how to process relocations in object files in order to properly wire up internal dependencies in the code. In this post we will look into what happens if the code has external dependencies — that is, it tries to call functions from external libraries. As before, we will be building upon <a href="https://github.com/cloudflare/cloudflare-blog/tree/master/2021-03-obj-file/2">the code from part 2</a>. Let&#8217;s add another function to our toy object file:</p>
<p><em>obj.c</em>:</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;
 
...
 
void say_hello(void)
{
    puts(&quot;Hello, world!&quot;);
}
</code></pre>
<p>In the above scenario our <code>say_hello</code> function now depends on the <code>puts</code> <a href="https://man7.org/linux/man-pages/man3/puts.3.html">function from the C standard library</a>. To try it out we also need to modify our <code>loader</code> to import the new function and execute it:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void execute_funcs(void)
{
    /* pointers to imported functions */
    int (*add5)(int);
    int (*add10)(int);
    const char *(*get_hello)(void);
    int (*get_var)(void);
    void (*set_var)(int num);
    void (*say_hello)(void);
 
...
 
    say_hello = lookup_function(&quot;say_hello&quot;);
    if (!say_hello) {
        fputs(&quot;Failed to find say_hello function\n&quot;, stderr);
        exit(ENOENT);
    }
 
    puts(&quot;Executing say_hello...&quot;);
    say_hello();
}
...
</code></pre>
<p>Let&#8217;s run it:</p>
<pre><code class="language-bash">$ gcc -c obj.c
$ gcc -o loader loader.c
$ ./loader
No runtime base address for section
</code></pre>
<p>Seems something went wrong when the <code>loader</code> tried to process relocations, so let&#8217;s check the relocations table:</p>
<pre><code class="language-bash">$ readelf --relocs obj.o
 
Relocation section '.rela.text' at offset 0x3c8 contains 7 entries:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
000000000020  000a00000004 R_X86_64_PLT32    0000000000000000 add5 - 4
00000000002d  000a00000004 R_X86_64_PLT32    0000000000000000 add5 - 4
00000000003a  000500000002 R_X86_64_PC32     0000000000000000 .rodata - 4
000000000046  000300000002 R_X86_64_PC32     0000000000000000 .data - 4
000000000058  000300000002 R_X86_64_PC32     0000000000000000 .data - 4
000000000066  000500000002 R_X86_64_PC32     0000000000000000 .rodata - 4
00000000006b  001100000004 R_X86_64_PLT32    0000000000000000 puts - 4
...
</code></pre>
<p>The compiler generated a relocation for the <code>puts</code> invocation. The relocation type is <code>R_X86_64_PLT32</code> and our <code>loader</code> already knows how to process these, so the problem is elsewhere. The above entry shows that the relocation references 17th entry (<code>0x11</code> in hex) in the symbol table, so let&#8217;s check that:</p>
<pre><code class="language-bash">$ readelf --symbols obj.o
 
Symbol table '.symtab' contains 18 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS obj.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    3
     4: 0000000000000000     0 SECTION LOCAL  DEFAULT    4
     5: 0000000000000000     0 SECTION LOCAL  DEFAULT    5
     6: 0000000000000000     4 OBJECT  LOCAL  DEFAULT    3 var
     7: 0000000000000000     0 SECTION LOCAL  DEFAULT    7
     8: 0000000000000000     0 SECTION LOCAL  DEFAULT    8
     9: 0000000000000000     0 SECTION LOCAL  DEFAULT    6
    10: 0000000000000000    15 FUNC    GLOBAL DEFAULT    1 add5
    11: 000000000000000f    36 FUNC    GLOBAL DEFAULT    1 add10
    12: 0000000000000033    13 FUNC    GLOBAL DEFAULT    1 get_hello
    13: 0000000000000040    12 FUNC    GLOBAL DEFAULT    1 get_var
    14: 000000000000004c    19 FUNC    GLOBAL DEFAULT    1 set_var
    15: 000000000000005f    19 FUNC    GLOBAL DEFAULT    1 say_hello
    16: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND _GLOBAL_OFFSET_TABLE_
    17: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND puts
</code></pre>
<p>Oh! The section index for the <code>puts</code> function is <code>UND</code> (essentially <code>0</code> in the code), which makes total sense: unlike previous symbols, <code>puts</code> is an external dependency, and it is not implemented in our <code>obj.o</code> file. Therefore, it can&#8217;t be a part of any section within <code>obj.o</code>.<br />
So how do we resolve this relocation? We need to somehow point the code to jump to a <code>puts</code> implementation. Our <code>loader</code> actually already has access to the C library <code>puts</code> function (because it is written in C and we&#8217;ve used <code>puts</code> in the <code>loader</code> code itself already), but technically it doesn&#8217;t have to be the C library <code>puts</code>, just some <code>puts</code> implementation. For completeness, let&#8217;s implement our own custom <code>puts</code> function in the <code>loader</code>, which is just a decorator around the C library <code>puts</code>:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
/* external dependencies for obj.o */
static int my_puts(const char *s)
{
    puts(&quot;my_puts executed&quot;);
    return puts(s);
}
...
</code></pre>
<p>Now that we have a <code>puts</code> implementation (and thus its runtime address) we should just write logic in the <code>loader</code> to resolve the relocation by instructing the code to jump to the correct function. However, there is one complication: in <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-2/">part 2 of our series</a>, when we processed relocations for constants and global variables, we learned we&#8217;re mostly dealing with 32-bit relative relocations and that the code or data we&#8217;re referencing needs to be no more than 2147483647 (<code>0x7fffffff</code> in hex) bytes away from the relocation itself. <code>R_X86_64_PLT32</code> is also a 32-bit relative relocation, so it has the same requirements, but unfortunately we can&#8217;t reuse the trick from <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-2/">part 2</a> as our <code>my_puts</code> function is part of the <code>loader</code> itself and we don&#8217;t have control over where in the address space the operating system places the <code>loader</code> code.</p>
<p>Luckily, we don&#8217;t have to come up with any new solutions and can just borrow the approach used in shared libraries.</p>
<h3 id="exploringpltgot">Exploring PLT/GOT</h3>
<p>Real world ELF executables and shared libraries have the same problem: often executables have dependencies on shared libraries and shared libraries have dependencies on other shared libraries. And all of the different pieces of a complete runtime program may be mapped to random ranges in the process address space. When a shared library or an ELF executable is linked together, the linker enumerates all the external references and creates two or more additional sections (for a refresher on ELF sections check out the <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-1/">part 1 of our series</a>) in the ELF file. The two mandatory ones are <a href="https://refspecs.linuxfoundation.org/ELF/zSeries/lzsabi0_zSeries/x2251.html">the Procedure Linkage Table (PLT) and the Global Offset Table (GOT)</a>.</p>
<p>We will not deep-dive into specifics of the standard PLT/GOT implementation as there are many other great resources online, but in a nutshell PLT/GOT is just a jumptable for external code. At the linking stage the linker resolves all external 32-bit relative relocations with respect to a locally generated PLT/GOT table. It can do that, because this table would become part of the final ELF file itself, so it will be &quot;close&quot; to the main code, when the file is mapped into memory at runtime. Later, at runtime <a href="https://man7.org/linux/man-pages/man8/ld.so.8.html">the dynamic loader</a> populates PLT/GOT tables for every loaded ELF file (both the executable and the shared libraries) with the runtime addresses of all the dependencies. Eventually, when the program code calls some external library function, the CPU &quot;jumps&quot; through the local PLT/GOT table to the final code:</p>
<p><img src="https://blog.cloudflare.com/content/images/2021/09/image2-5.png" alt="How to execute an object file: Part 3"></p>
<p>Why do we need two ELF sections to implement one jumptable you may ask? Well, because real world PLT/GOT is a bit more complex than described above. Turns out resolving all external references at runtime may significantly slow down program startup time, so symbol resolution is implemented via a &quot;lazy approach&quot;: a reference is resolved by <a href="https://man7.org/linux/man-pages/man8/ld.so.8.html">the dynamic loader</a> only when the code actually tries to call a particular function. If the main application code never calls a library function, that reference will never be resolved.</p>
<h3 id="implementingasimplifiedpltgot">Implementing a simplified PLT/GOT</h3>
<p>For learning and demonstrative purposes though we will not be reimplementing a full-blown PLT/GOT with lazy resolution, but a simple jumptable, which resolves external references when the object file is loaded and parsed. First of all we need to know the size of the table: for ELF executables and shared libraries the linker will count the external references at link stage and create appropriately sized PLT and GOT sections. Because we are dealing with raw object files we would have to do another pass over the <code>.rela.text</code> section and count all the relocations, which point to an entry in the symbol table with undefined section index (or <code>0</code> in code). Let&#8217;s add a function for this and store the number of external references in a global variable:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
/* number of external symbols in the symbol table */
static int num_ext_symbols = 0;
...
static void count_external_symbols(void)
{
    const Elf64_Shdr *rela_text_hdr = lookup_section(&quot;.rela.text&quot;);
    if (!rela_text_hdr) {
        fputs(&quot;Failed to find .rela.text\n&quot;, stderr);
        exit(ENOEXEC);
    }
 
    int num_relocations = rela_text_hdr-&gt;sh_size / rela_text_hdr-&gt;sh_entsize;
    const Elf64_Rela *relocations = (Elf64_Rela *)(obj.base + rela_text_hdr-&gt;sh_offset);
 
    for (int i = 0; i &lt; num_relocations; i++) {
        int symbol_idx = ELF64_R_SYM(relocations[i].r_info);
 
        /* if there is no section associated with a symbol, it is probably
         * an external reference */
        if (symbols[symbol_idx].st_shndx == SHN_UNDEF)
            num_ext_symbols++;
    }
}
...
</code></pre>
<p>This function is very similar to our <code>do_text_relocations</code> function. Only instead of actually performing relocations it just counts the number of external symbol references.</p>
<p>Next we need to decide the actual size in bytes for our jumptable. <code>num_ext_symbols</code> has the number of external symbol references in the object file, but how many bytes per symbol to allocate? To figure this out we need to design our jumptable format. As we established above, in its simple form our jumptable should be just a collection of unconditional CPU jump instructions — one for each external symbol. However, unfortunately modern x64 CPU architecture <a href="https://www.felixcloutier.com/x86/jmp">does not provide a jump instruction</a>, where an address pointer can be a direct operand. Instead, the jump address needs to be stored in memory somewhere &quot;close&quot; — that is within 32-bit offset — and the offset is the actual operand. So, for each external symbol we need to store the jump address (64 bits or 8 bytes on a 64-bit CPU system) and the actual jump instruction with an offset operand (<a href="https://www.felixcloutier.com/x86/jmp">6 bytes for x64 architecture</a>). We can represent an entry in our jumptable with the following C structure:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
struct ext_jump {
    /* address to jump to */
    uint8_t *addr;
    /* unconditional x64 JMP instruction */
    /* should always be {0xff, 0x25, 0xf2, 0xff, 0xff, 0xff} */
    /* so it would jump to an address stored at addr above */
    uint8_t instr[6];
};
 
struct ext_jump *jumptable;
...
</code></pre>
<p>We&#8217;ve also added a global variable to store the base address of the jumptable, which will be allocated later. Notice that with the above approach the actual jump instruction will always be constant for every external symbol. Since we allocate a dedicated entry for each external symbol with this structure, the <code>addr</code> member would always be at the same offset from the end of the jump instruction in <code>instr</code>: <code>-14</code> bytes or <code>0xfffffff2</code> in hex for a 32-bit operand. So <code>instr</code> will always be <code>{0xff, 0x25, 0xf2, 0xff, 0xff, 0xff}</code>: <code>0xff</code> and <code>0x25</code> is the encoding of the x64 jump instruction and its modifier and <code>0xfffffff2</code> is the operand offset in little-endian format.</p>
<p>Now that we have defined the entry format for our jumptable, we can allocate and populate it when parsing the object file. First of all, let&#8217;s not forget to call our new <code>count_external_symbols</code> function from the <code>parse_obj</code> to populate <code>num_ext_symbols</code> (it has to be done before we allocate the jumptable):</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void parse_obj(void)
{
...
 
    count_external_symbols();
 
    /* allocate memory for `.text`, `.data` and `.rodata` copies rounding up each section to whole pages */
    text_runtime_base = mmap(NULL, page_align(text_hdr-&gt;sh_size)...
...
}
</code></pre>
<p>Next we need to allocate memory for the jumptable and store the pointer in the <code>jumptable</code> global variable for later use. Just a reminder that in order to resolve 32-bit relocations from the <code>.text</code> section to this table, it has to be &quot;close&quot; in memory to the main code. So we need to allocate it in the same <code>mmap</code> call as the rest of the object sections. Since we defined the table&#8217;s entry format in <code>struct ext_jump</code> and have <code>num_ext_symbols</code>, the size of the table would simply be <code>sizeof(struct ext_jump) * num_ext_symbols</code>:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void parse_obj(void)
{
...
 
    count_external_symbols();
 
    /* allocate memory for `.text`, `.data` and `.rodata` copies and the jumptable for external symbols, rounding up each section to whole pages */
    text_runtime_base = mmap(NULL, page_align(text_hdr-&gt;sh_size) + \
                                   page_align(data_hdr-&gt;sh_size) + \
                                   page_align(rodata_hdr-&gt;sh_size) + \
                                   page_align(sizeof(struct ext_jump) * num_ext_symbols),
                                   PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
    if (text_runtime_base == MAP_FAILED) {
        perror(&quot;Failed to allocate memory&quot;);
        exit(errno);
    }
 
...
    rodata_runtime_base = data_runtime_base + page_align(data_hdr-&gt;sh_size);
    /* jumptable will come after .rodata */
    jumptable = (struct ext_jump *)(rodata_runtime_base + page_align(rodata_hdr-&gt;sh_size));
 
...
}
...
</code></pre>
<p>Finally, because the CPU will actually be executing the jump instructions from our <code>instr</code> fields from the jumptable, we need to mark this memory readonly and executable (after <code>do_text_relocations</code> earlier in this function has completed):</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void parse_obj(void)
{
...
 
    do_text_relocations();
 
...
 
    /* make the jumptable readonly and executable */
    if (mprotect(jumptable, page_align(sizeof(struct ext_jump) * num_ext_symbols), PROT_READ | PROT_EXEC)) {
        perror(&quot;Failed to make the jumptable executable&quot;);
        exit(errno);
    }
}
...
</code></pre>
<p>At this stage we have our jumptable allocated and usable — all is left to do is to populate it properly. We’ll do this by improving the <code>do_text_relocations</code> implementation to handle the case of external symbols. The <code>No runtime base address for section</code> error from the beginning of this post is actually caused by this line in <code>do_text_relocations</code>:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void do_text_relocations(void)
{
...
    for (int i = 0; i &lt; num_relocations; i++) {
...
        /* symbol, with respect to which the relocation is performed */
        uint8_t *symbol_address = = section_runtime_base(&amp;sections[symbols[symbol_idx].st_shndx]) + symbols[symbol_idx].st_value;
...
}
...
</code></pre>
<p>Currently we try to determine the runtime symbol address for the relocation by looking up the symbol&#8217;s section runtime address and adding the symbol&#8217;s offset. But we have established above that external symbols do not have an associated section, so their handling needs to be a special case. Let&#8217;s update the implementation to reflect this:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void do_text_relocations(void)
{
...
    for (int i = 0; i &lt; num_relocations; i++) {
...
        /* symbol, with respect to which the relocation is performed */
        uint8_t *symbol_address;
        
        /* if this is an external symbol */
        if (symbols[symbol_idx].st_shndx == SHN_UNDEF) {
            static int curr_jmp_idx = 0;
 
            /* get external symbol/function address by name */
            jumptable[curr_jmp_idx].addr = lookup_ext_function(strtab +  symbols[symbol_idx].st_name);
 
            /* x64 unconditional JMP with address stored at -14 bytes offset */
            /* will use the address stored in addr above */
            jumptable[curr_jmp_idx].instr[0] = 0xff;
            jumptable[curr_jmp_idx].instr[1] = 0x25;
            jumptable[curr_jmp_idx].instr[2] = 0xf2;
            jumptable[curr_jmp_idx].instr[3] = 0xff;
            jumptable[curr_jmp_idx].instr[4] = 0xff;
            jumptable[curr_jmp_idx].instr[5] = 0xff;
 
            /* resolve the relocation with respect to this unconditional JMP */
            symbol_address = (uint8_t *)(&amp;jumptable[curr_jmp_idx].instr);
 
            curr_jmp_idx++;
        } else {
            symbol_address = section_runtime_base(&amp;sections[symbols[symbol_idx].st_shndx]) + symbols[symbol_idx].st_value;
        }
...
}
...
</code></pre>
<p>If a relocation symbol does not have an associated section, we consider it external and call a helper function to lookup the symbol&#8217;s runtime address by its name. We store this address in the next available jumptable entry, populate the x64 jump instruction with our fixed operand and store the address of the instruction in the <code>symbol_address</code> variable. Later, the existing code in <code>do_text_relocations</code> will resolve the <code>.text</code> relocation with respect to the address in <code>symbol_address</code> in the same way it does for local symbols in <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-2/">part 2 of our series</a>.</p>
<p>The only missing bit here now is the implementation of the newly introduced <code>lookup_ext_function</code> helper. Real world loaders may have complicated logic on how to find and resolve symbols in memory at runtime. But for the purposes of this article we&#8217;ll provide a simple naive implementation, which can only resolve the <code>puts</code> function:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
 
static void *lookup_ext_function(const char *name)
{
    size_t name_len = strlen(name);
 
    if (name_len == strlen(&quot;puts&quot;) &amp;&amp; !strcmp(name, &quot;puts&quot;))
        return my_puts;
 
    fprintf(stderr, &quot;No address for function %s\n&quot;, name);
    exit(ENOENT);
}
...
</code></pre>
<p>Notice though that because we control the <code>loader</code> logic we are free to implement resolution as we please. In the above case we actually &quot;divert&quot; the object file to use our own &quot;custom&quot; <code>my_puts</code> function instead of the C library one. Let&#8217;s recompile the <code>loader</code> and see if it works:</p>
<pre><code class="language-bash">$ gcc -o loader loader.c
$ ./loader
Executing add5...
add5(42) = 47
Executing add10...
add10(42) = 52
Executing get_hello...
get_hello() = Hello, world!
Executing get_var...
get_var() = 5
Executing set_var(42)...
Executing get_var again...
get_var() = 42
Executing say_hello...
my_puts executed
Hello, world!
</code></pre>
<p>Hooray! We not only fixed our <code>loader</code> to handle external references in object files — we have also learned how to &quot;hook&quot; any such external function call and divert the code to a custom implementation, which might be useful in some cases, like malware research.</p>
<p>As in the previous posts, the complete source code from this post is <a href="https://github.com/cloudflare/cloudflare-blog/tree/master/2021-03-obj-file/3">available on GitHub</a>.</p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/compiler/" rel="tag">Compiler</a><a href="https://noise.getoto.net/tag/deep-dive/" rel="tag">deep dive</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/software/" rel="tag">software</a></span></footer></article>
<article id="post-1121855" class="post-1121855 post type-post status-publish format-standard hentry tag-compiler tag-deep-dive tag-linux tag-programming tag-software">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2021/03/02/how-to-execute-an-object-file-part-1/" rel="bookmark">How to execute an object file: Part 1</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2021/03/02/how-to-execute-an-object-file-part-1/" rel="bookmark"><time class="entry-date" datetime="2021-03-02T14:00:00+02:00">2021-03-02</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/ignat-korchagin/" rel="author">Ignat Korchagin</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Ignat Korchagin">Ignat Korchagin</a> original <a href="https://blog.cloudflare.com/how-to-execute-an-object-file-part-1/">https://blog.cloudflare.com/how-to-execute-an-object-file-part-1/</a></p>
<p></p>
<h2 id="callingasimplefunctionwithoutlinking">Calling a simple function without linking</h2>
<p><img src="https://blog.cloudflare.com/content/images/2021/03/image3.png" alt="How to execute an object file: Part 1"></p>
<p>When we write software using a high-level compiled programming language, there are usually a number of steps involved in transforming our source code into the final executable binary:</p>
<p><img src="https://blog.cloudflare.com/content/images/2021/03/build.png" alt="How to execute an object file: Part 1"></p>
<p>First, our source files are compiled by a <em>compiler</em> translating the high-level programming language into machine code. The output of the compiler is a number of <em>object</em> files. If the project contains multiple source files, we usually get as many object files. The next step is the <em>linker</em>: since the code in different object files may reference each other, the linker is responsible for assembling all these object files into one big program and binding these references together. The output of the linker is usually our target executable, so only one file.</p>
<p>However, at this point, our executable might still be incomplete. These days, most executables on Linux are dynamically linked: the executable itself does not have all the code it needs to run a program. Instead it expects to &quot;borrow&quot; part of the code at runtime from <a href="https://en.wikipedia.org/wiki/Library_(computing)#Shared_libraries">shared libraries</a> for some of its functionality:</p>
<p><img src="https://blog.cloudflare.com/content/images/2021/03/runtime.png" alt="How to execute an object file: Part 1"></p>
<p>This process is called <em>runtime linking</em>: when our executable is being started, the operating system will invoke the <em>dynamic loader</em>, which should find all the needed libraries, copy/map their code into our target process address space, and resolve all the dependencies our code has on them.</p>
<p>One interesting thing to note about this overall process is that we get the executable machine code directly from step 1 (compiling the source code), but if any of the later steps fail, we still can&#8217;t execute our program. So, in this series of blog posts we will investigate if it is possible to execute machine code directly from object files skipping all the later steps.</p>
<h4 id="whywouldwewanttoexecuteanobjectfile">Why would we want to execute an object file?</h4>
<p>There may be many reasons. Perhaps we&#8217;re writing an open-source replacement for a proprietary Linux driver or an application, and want to compare if the behaviour of some code is the same. Or we have a piece of a rare, obscure program and we can&#8217;t link to it, because it was compiled with a rare, obscure compiler. Maybe we have a source file, but cannot create a full featured executable, because of the missing build time or runtime dependencies. Malware analysis, code from a different operating system etc &#8211; all these scenarios may put us in a position, where either linking is not possible or the runtime environment is not suitable.</p>
<h3 id="asimpletoyobjectfile">A simple toy object file</h3>
<p>For the purposes of this article, let&#8217;s create a simple toy object file, so we can use it in our experiments:</p>
<p><em>obj.c</em>:</p>
<pre><code class="language-C">int add5(int num)
{
    return num + 5;
}

int add10(int num)
{
    return num + 10;
}
</code></pre>
<p>Our source file contains only 2 functions, <code>add5</code> and <code>add10</code>, which adds 5 or 10 respectively to the only input parameter. It&#8217;s a small but fully functional piece of code, and we can easily compile it into an object file:</p>
<pre><code class="language-bash">$ gcc -c obj.c 
$ ls
obj.c  obj.o
</code></pre>
<h3 id="loadinganobjectfileintotheprocessmemory">Loading an object file into the process memory</h3>
<p>Now we will try to import the <code>add5</code> and <code>add10</code> functions from the object file and execute them. When we talk about executing an object file, we mean using an object file as some sort of a library. As we learned above, when we have an executable that utilises external shared libraries, the <em>dynamic loader</em> loads these libraries into the process address space for us. With object files, however, we have to do this manually, because ultimately we can&#8217;t execute machine code that doesn&#8217;t reside in the operating system&#8217;s RAM. So, to execute object files we still need some kind of a wrapper program:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

static void load_obj(void)
{
    /* load obj.o into memory */
}

static void parse_obj(void)
{
    /* parse an object file and find add5 and add10 functions */
}

static void execute_funcs(void)
{
    /* execute add5 and add10 with some inputs */
}

int main(void)
{
    load_obj();
    parse_obj();
    execute_funcs();

    return 0;
}
</code></pre>
<p>Above is a self-contained object loader program with some functions as placeholders. We will be implementing these functions (and adding more) in the course of this post.</p>
<p>First, as we established already, we need to load our object file into the process address space. We could just read the whole file into a buffer, but that would not be very efficient. Real-world object files might be big, but as we will see later, we don&#8217;t need all of the object&#8217;s file contents. So it is better to <a href="https://man7.org/linux/man-pages/man2/mmap.2.html"><code>mmap</code></a> the file instead: this way the operating system will lazily read the parts from the file we need at the time we need them. Let&#8217;s implement the <code>load_obj</code> function:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...
/* for open(2), fstat(2) */
#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
#include &lt;fcntl.h&gt;

/* for close(2), fstat(2) */
#include &lt;unistd.h&gt;

/* for mmap(2) */
#include &lt;sys/mman.h&gt;

/* parsing ELF files */
#include &lt;elf.h&gt;

/* for errno */
#include &lt;errno.h&gt;

typedef union {
    const Elf64_Ehdr *hdr;
    const uint8_t *base;
} objhdr;

/* obj.o memory address */
static objhdr obj;

static void load_obj(void)
{
    struct stat sb;

    int fd = open(&quot;obj.o&quot;, O_RDONLY);
    if (fd &lt;= 0) {
        perror(&quot;Cannot open obj.o&quot;);
        exit(errno);
    }

    /* we need obj.o size for mmap(2) */
    if (fstat(fd, &amp;sb)) {
        perror(&quot;Failed to get obj.o info&quot;);
        exit(errno);
    }

    /* mmap obj.o into memory */
    obj.base = mmap(NULL, sb.st_size, PROT_READ, MAP_PRIVATE, fd, 0);
    if (obj.base == MAP_FAILED) {
        perror(&quot;Maping obj.o failed&quot;);
        exit(errno);
    }
    close(fd);
}
...
</code></pre>
<p>If we don&#8217;t encounter any errors, after <code>load_obj</code> executes we should get the memory address, which points to the beginning of our <code>obj.o</code> in the <code>obj</code> global variable. It is worth noting we have created a special union type for the <code>obj</code> variable: we will be parsing <code>obj.o</code> later (and peeking ahead &#8211; object files are actually <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF files</a>), so will be referring to the address both as <code>Elf64_Ehdr</code> (ELF header structure in C) and a byte pointer (parsing ELF files involves calculations of byte offsets from the beginning of the file).</p>
<h3 id="apeekinsideanobjectfile">A peek inside an object file</h3>
<p>To use some code from an object file, we need to find it first. As I&#8217;ve leaked above, object files are actually <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF files</a> (the same format as Linux executables and shared libraries) and luckily they’re easy to parse on Linux with the help of the standard <code>elf.h</code> header, which includes many useful definitions related to the ELF file structure. But we actually need to know what we’re looking for, so a high-level understanding of an ELF file is needed.</p>
<h4 id="elfsegmentsandsections">ELF segments and sections</h4>
<p>Segments (also known as program headers) and sections are probably the main parts of an ELF file and usually a starting point of any ELF tutorial. However, there is often some confusion between the two. Different sections contain different types of ELF data: executable code (which we are most interested in in this post), constant data, global variables etc. Segments, on the other hand, do not contain any data themselves &#8211; they just describe to the operating system how to properly load sections into RAM for the executable to work correctly. Some tutorials say &quot;a segment may include 0 or more sections&quot;, which is not entirely accurate: segments do not contain sections, rather they just indicate to the OS where in memory a particular section should be loaded and what is the access pattern for this memory (read, write or execute):</p>
<p><img src="https://blog.cloudflare.com/content/images/2021/03/segments-sections.png" alt="How to execute an object file: Part 1"></p>
<p>Furthermore, object files do not contain any segments at all: an object file is not meant to be directly loaded by the OS. Instead, it is assumed it will be linked with some other code, so ELF segments are usually generated by the linker, not the compiler. We can check this by using the <a href="https://man7.org/linux/man-pages/man1/readelf.1.html">readelf command</a>:</p>
<pre><code class="language-bash">$ readelf --segments obj.o

There are no program headers in this file.
</code></pre>
<h4 id="objectfilesections">Object file sections</h4>
<p>The same <a href="https://man7.org/linux/man-pages/man1/readelf.1.html">readelf command</a> can be used to get all the sections from our object file:</p>
<pre><code class="language-bash">$ readelf --sections obj.o
There are 11 section headers, starting at offset 0x268:

Section Headers:
  [Nr] Name              Type             Address           Offset
       Size              EntSize          Flags  Link  Info  Align
  [ 0]                   NULL             0000000000000000  00000000
       0000000000000000  0000000000000000           0     0     0
  [ 1] .text             PROGBITS         0000000000000000  00000040
       000000000000001e  0000000000000000  AX       0     0     1
  [ 2] .data             PROGBITS         0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 3] .bss              NOBITS           0000000000000000  0000005e
       0000000000000000  0000000000000000  WA       0     0     1
  [ 4] .comment          PROGBITS         0000000000000000  0000005e
       000000000000001d  0000000000000001  MS       0     0     1
  [ 5] .note.GNU-stack   PROGBITS         0000000000000000  0000007b
       0000000000000000  0000000000000000           0     0     1
  [ 6] .eh_frame         PROGBITS         0000000000000000  00000080
       0000000000000058  0000000000000000   A       0     0     8
  [ 7] .rela.eh_frame    RELA             0000000000000000  000001e0
       0000000000000030  0000000000000018   I       8     6     8
  [ 8] .symtab           SYMTAB           0000000000000000  000000d8
       00000000000000f0  0000000000000018           9     8     8
  [ 9] .strtab           STRTAB           0000000000000000  000001c8
       0000000000000012  0000000000000000           0     0     1
  [10] .shstrtab         STRTAB           0000000000000000  00000210
       0000000000000054  0000000000000000           0     0     1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
  L (link order), O (extra OS processing required), G (group), T (TLS),
  C (compressed), x (unknown), o (OS specific), E (exclude),
  l (large), p (processor specific)
</code></pre>
<p>There are different tutorials online describing the most popular ELF sections in detail. Another great reference is the <a href="https://man7.org/linux/man-pages/man5/elf.5.html">Linux manpages project</a>. It is handy because it describes both sections’ purpose as well as C structure definitions from <code>elf.h</code>, which makes it a one-stop shop for parsing ELF files. However, for completeness, below is a short description of the most popular sections one may encounter in an ELF file:</p>
<ul>
<li><code>.text</code>: this section contains the executable code (the actual machine code, which was created by the compiler from our source code). This section is the primary area of interest for this post as it should contain the <code>add5</code> and <code>add10</code> functions we want to use.</li>
<li><code>.data</code> and <code>.bss</code>: these sections contain global and static local variables. The difference is: <code>.data</code> has variables with an initial value (defined like <code>int foo = 5;</code>) and <code>.bss</code> just reserves space for variables with no initial value (defined like <code>int bar;</code>).</li>
<li><code>.rodata</code>: this section contains constant data (mostly strings or byte arrays). For example, if we use a string literal in the code (for example, for <code>printf</code> or some error message), it will be stored here. Note, that <code>.rodata</code> is missing from the output above as we didn&#8217;t use any string literals or constant byte arrays in <code>obj.c</code>.</li>
<li><code>.symtab</code>: this section contains information about the symbols in the object file: functions, global variables, constants etc. It may also contain information about external symbols the object file needs, like needed functions from the external libraries.</li>
<li><code>.strtab</code> and <code>.shstrtab</code>: contain packed strings for the ELF file. Note, that these are not the strings we may define in our source code (those go to the <code>.rodata</code> section). These are the strings describing the names of other ELF structures, like symbols from <code>.symtab</code> or even section names from the table above. ELF binary format aims to make its structures compact and of a fixed size, so all strings are stored in one place and the respective data structures just reference them as an offset in either <code>.shstrtab</code> or <code>.strtab</code> sections instead of storing the full string locally.</li>
</ul>
<h4 id="thesymtabsection">The <code>.symtab</code> section</h4>
<p>At this point, we know that the code we want to import and execute is located in the <code>obj.o</code>&#8216;s <code>.text</code> section. But we have two functions, <code>add5</code> and <code>add10</code>, remember? At this level the <code>.text</code> section is just a byte blob &#8211; how do we know where each of these functions is located? This is where the <code>.symtab</code> (the &quot;symbol table&quot;) comes in handy. It is so important that it has its own dedicated parameter in <a href="https://man7.org/linux/man-pages/man1/readelf.1.html">readelf</a>:</p>
<pre><code class="language-bash">$ readelf --symbols obj.o

Symbol table '.symtab' contains 10 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS obj.c
     2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1
     3: 0000000000000000     0 SECTION LOCAL  DEFAULT    2
     4: 0000000000000000     0 SECTION LOCAL  DEFAULT    3
     5: 0000000000000000     0 SECTION LOCAL  DEFAULT    5
     6: 0000000000000000     0 SECTION LOCAL  DEFAULT    6
     7: 0000000000000000     0 SECTION LOCAL  DEFAULT    4
     8: 0000000000000000    15 FUNC    GLOBAL DEFAULT    1 add5
     9: 000000000000000f    15 FUNC    GLOBAL DEFAULT    1 add10
</code></pre>
<p>Let&#8217;s ignore the other entries for now and just focus on the last two lines, because they conveniently have <code>add5</code> and <code>add10</code> as their symbol names. And indeed, this is the info about our functions. Apart from the names, the symbol table provides us with some additional metadata:</p>
<ul>
<li>The <code>Ndx</code> column tells us the index of the section, where the symbol is located. We can cross-check it with the section table above and confirm that indeed these functions are located in <code>.text</code> (section with the index <code>1</code>).</li>
<li><code>Type</code> being set to <code>FUNC</code> confirms that these are indeed functions.</li>
<li><code>Size</code> tells us the size of each function, but this information is not very useful in our context. The same goes for <code>Bind</code> and <code>Vis</code>.</li>
<li>Probably the most useful piece of information is <code>Value</code>. The name is misleading, because it is actually an offset from the start of the containing section in this context. That is, the <code>add5</code> function starts just from the beginning of <code>.text</code> and <code>add10</code> is located from 15th byte and onwards.</li>
</ul>
<p>So now we have all the pieces on how to parse an ELF file and find the functions we need.</p>
<h3 id="findingandexecutingafunctionfromanobjectfile">Finding and executing a function from an object file</h3>
<p>Given what we have learned so far, let&#8217;s define a plan on how to proceed to import and execute a function from an object file:</p>
<ol>
<li>Find the ELF sections table and <code>.shstrtab</code> section (we need <code>.shstrtab</code> later to lookup sections in the section table by name).</li>
<li>Find the <code>.symtab</code> and <code>.strtab</code> sections (we need <code>.strtab</code> to lookup symbols by name in <code>.symtab</code>).</li>
<li>Find the <code>.text</code> section and copy it into RAM with executable permissions.</li>
<li>Find <code>add5</code> and <code>add10</code> function offsets from the <code>.symtab</code>.</li>
<li>Execute <code>add5</code> and <code>add10</code> functions.</li>
</ol>
<p>Let&#8217;s start by adding some more global variables and implementing the <code>parse_obj</code> function:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

/* sections table */
static const Elf64_Shdr *sections;
static const char *shstrtab = NULL;

/* symbols table */
static const Elf64_Sym *symbols;
/* number of entries in the symbols table */
static int num_symbols;
static const char *strtab = NULL;

...

static void parse_obj(void)
{
    /* the sections table offset is encoded in the ELF header */
    sections = (const Elf64_Shdr *)(obj.base + obj.hdr-&gt;e_shoff);
    /* the index of `.shstrtab` in the sections table is encoded in the ELF header
     * so we can find it without actually using a name lookup
     */
    shstrtab = (const char *)(obj.base + sections[obj.hdr-&gt;e_shstrndx].sh_offset);

...
}

...
</code></pre>
<p>Now that we have references to both the sections table and the <code>.shstrtab</code> section, we can lookup other sections by their name. Let&#8217;s create a helper function for that:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

static const Elf64_Shdr *lookup_section(const char *name)
{
    size_t name_len = strlen(name);

    /* number of entries in the sections table is encoded in the ELF header */
    for (Elf64_Half i = 0; i &lt; obj.hdr-&gt;e_shnum; i++) {
        /* sections table entry does not contain the string name of the section
         * instead, the `sh_name` parameter is an offset in the `.shstrtab`
         * section, which points to a string name
         */
        const char *section_name = shstrtab + sections[i].sh_name;
        size_t section_name_len = strlen(section_name);

        if (name_len == section_name_len &amp;&amp; !strcmp(name, section_name)) {
            /* we ignore sections with 0 size */
            if (sections[i].sh_size)
                return sections + i;
        }
    }

    return NULL;
}

...
</code></pre>
<p>Using our new helper function, we can now find the <code>.symtab</code> and <code>.strtab</code> sections:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

static void parse_obj(void)
{
...

    /* find the `.symtab` entry in the sections table */
    const Elf64_Shdr *symtab_hdr = lookup_section(&quot;.symtab&quot;);
    if (!symtab_hdr) {
        fputs(&quot;Failed to find .symtab\n&quot;, stderr);
        exit(ENOEXEC);
    }

    /* the symbols table */
    symbols = (const Elf64_Sym *)(obj.base + symtab_hdr-&gt;sh_offset);
    /* number of entries in the symbols table = table size / entry size */
    num_symbols = symtab_hdr-&gt;sh_size / symtab_hdr-&gt;sh_entsize;

    const Elf64_Shdr *strtab_hdr = lookup_section(&quot;.strtab&quot;);
    if (!strtab_hdr) {
        fputs(&quot;Failed to find .strtab\n&quot;, stderr);
        exit(ENOEXEC);
    }

    strtab = (const char *)(obj.base + strtab_hdr-&gt;sh_offset);
    
...
}

...
</code></pre>
<p>Next, let&#8217;s focus on the <code>.text</code> section. We noted earlier in our plan that it is not enough to just locate the <code>.text</code> section in the object file, like we did with other sections. We would need to copy it over to a different location in RAM with executable permissions. There are several reasons for that, but these are the main ones:</p>
<ul>
<li>Many CPU architectures either don&#8217;t allow execution of the machine code, which is <a href="https://en.wikipedia.org/wiki/Page_(computer_memory)">unaligned in memory</a> (4 kilobytes for x86 systems), or they execute it with a performance penalty. However, the <code>.text</code> section in an ELF file is not guaranteed to be positioned at a page aligned offset, because the on-disk version of the ELF file aims to be compact rather than convenient.</li>
<li>We may need to modify some bytes in the <code>.text</code> section to perform relocations (we don&#8217;t need to do it in this case, but will be dealing with relocations in future posts). If, for example, we forget to use the <code>MAP_PRIVATE</code> flag, when mapping the ELF file, our modifications may propagate to the underlying file and corrupt it.</li>
<li>Finally, different sections, which are needed at runtime, like <code>.text</code>, <code>.data</code>, <code>.bss</code> and <code>.rodata</code>, require different memory permission bits: the <code>.text</code> section memory needs to be both readable and executable, but not writable (it is considered a bad security practice to have memory both writable and executable). The <code>.data</code> and <code>.bss</code> sections need to be readable and writable to support global variables, but not executable. The <code>.rodata</code> section should be readonly, because its purpose is to hold constant data. To support this, each section must be allocated on a page boundary as we can only set memory permission bits on whole pages and not custom ranges. Therefore, we need to create new, page aligned memory ranges for these sections and copy the data there.</li>
</ul>
<p>To create a page aligned copy of the <code>.text</code> section, first we actually need to know the page size. Many programs usually just hardcode the page size to 4096 (4 kilobytes), but we shouldn&#8217;t rely on that. While it&#8217;s accurate for most x86 systems, other CPU architectures, like arm64, might have a different page size. So hard coding a page size may make our program non-portable. Let&#8217;s find the page size and store it in another global variable:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

static uint64_t page_size;

static inline uint64_t page_align(uint64_t n)
{
    return (n + (page_size - 1)) &amp; ~(page_size - 1);
}

...

static void parse_obj(void)
{
...

    /* get system page size */
    page_size = sysconf(_SC_PAGESIZE);

...
}

...
</code></pre>
<p>Notice, we have also added a convenience function <code>page_align</code>, which will round up the passed in number to the next page aligned boundary. Next, back to the <code>.text</code> section. As a reminder, we need to:</p>
<ol>
<li>Find the <code>.text</code> section metadata in the sections table.</li>
<li>Allocate a chunk of memory to hold the <code>.text</code> section copy.</li>
<li>Actually copy the <code>.text</code> section to the newly allocated memory.</li>
<li>Make the <code>.text</code> section executable, so we can later call functions from it.</li>
</ol>
<p>Here is the implementation of the above steps:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

/* runtime base address of the imported code */
static uint8_t *text_runtime_base;

...

static void parse_obj(void)
{
...

    /* find the `.text` entry in the sections table */
    const Elf64_Shdr *text_hdr = lookup_section(&quot;.text&quot;);
    if (!text_hdr) {
        fputs(&quot;Failed to find .text\n&quot;, stderr);
        exit(ENOEXEC);
    }

    /* allocate memory for `.text` copy rounding it up to whole pages */
    text_runtime_base = mmap(NULL, page_align(text_hdr-&gt;sh_size), PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
    if (text_runtime_base == MAP_FAILED) {
        perror(&quot;Failed to allocate memory for .text&quot;);
        exit(errno);
    }

    /* copy the contents of `.text` section from the ELF file */
    memcpy(text_runtime_base, obj.base + text_hdr-&gt;sh_offset, text_hdr-&gt;sh_size);

    /* make the `.text` copy readonly and executable */
    if (mprotect(text_runtime_base, page_align(text_hdr-&gt;sh_size), PROT_READ | PROT_EXEC)) {
        perror(&quot;Failed to make .text executable&quot;);
        exit(errno);
    }
}

...
</code></pre>
<p>Now we have all the pieces we need to locate the address of a function. Let&#8217;s write a helper for it:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

static void *lookup_function(const char *name)
{
    size_t name_len = strlen(name);

    /* loop through all the symbols in the symbol table */
    for (int i = 0; i &lt; num_symbols; i++) {
        /* consider only function symbols */
        if (ELF64_ST_TYPE(symbols[i].st_info) == STT_FUNC) {
            /* symbol table entry does not contain the string name of the symbol
             * instead, the `st_name` parameter is an offset in the `.strtab`
             * section, which points to a string name
             */
            const char *function_name = strtab + symbols[i].st_name;
            size_t function_name_len = strlen(function_name);

            if (name_len == function_name_len &amp;&amp; !strcmp(name, function_name)) {
                /* st_value is an offset in bytes of the function from the
                 * beginning of the `.text` section
                 */
                return text_runtime_base + symbols[i].st_value;
            }
        }
    }

    return NULL;
}

...
</code></pre>
<p>And finally we can implement the <code>execute_funcs</code> function to import and execute code from an object file:</p>
<p><em>loader.c</em>:</p>
<pre><code class="language-C">...

static void execute_funcs(void)
{
    /* pointers to imported add5 and add10 functions */
    int (*add5)(int);
    int (*add10)(int);

    add5 = lookup_function(&quot;add5&quot;);
    if (!add5) {
        fputs(&quot;Failed to find add5 function\n&quot;, stderr);
        exit(ENOENT);
    }

    puts(&quot;Executing add5...&quot;);
    printf(&quot;add5(%d) = %d\n&quot;, 42, add5(42));

    add10 = lookup_function(&quot;add10&quot;);
    if (!add10) {
        fputs(&quot;Failed to find add10 function\n&quot;, stderr);
        exit(ENOENT);
    }

    puts(&quot;Executing add10...&quot;);
    printf(&quot;add10(%d) = %d\n&quot;, 42, add10(42));
}

...
</code></pre>
<p>Let&#8217;s compile our loader and make sure it works as expected:</p>
<pre><code class="language-bash">$ gcc -o loader loader.c 
$ ./loader 
Executing add5...
add5(42) = 47
Executing add10...
add10(42) = 52
</code></pre>
<p>Voila! We have successfully imported code from <code>obj.o</code> and executed it. Of course, the example above is simplified: the code in the object file is self-contained, does not reference any global variables or constants, and does not have any external dependencies. In future posts we will look into more complex code and how to handle such cases.</p>
<h4 id="securityconsiderations">Security considerations</h4>
<p>Processing external inputs, like parsing an ELF file from the disk above, should be handled with care. The code from <em>loader.c</em> omits a lot of bounds checking and additional ELF integrity checks, when parsing the object file. The code is simplified for the purposes of this post, but most likely not production ready, as it can probably be exploited by specifically crafted malicious inputs. Use it only for educational purposes!</p>
<p>The complete source code from this post can be found <a href="https://github.com/cloudflare/cloudflare-blog/tree/master/2021-03-obj-file/1">here</a>.</p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/compiler/" rel="tag">Compiler</a><a href="https://noise.getoto.net/tag/deep-dive/" rel="tag">deep dive</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/software/" rel="tag">software</a></span></footer></article>
<article id="post-1115920" class="post-1115920 post type-post status-publish format-standard hentry tag-go tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2021/02/22/go-is-not-an-easy-language/" rel="bookmark">Go is not an easy language</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2021/02/22/go-is-not-an-easy-language/" rel="bookmark"><time class="entry-date" datetime="2021-02-22T02:00:00+02:00">2021-02-22</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/arp242-net/" rel="author">arp242.net</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by arp242.net">arp242.net</a> original <a href="https://www.arp242.net/go-easy.html">https://www.arp242.net/go-easy.html</a></p>
<p>Go is not an easy programming language. It <em>is</em> simple in many ways: the syntax<br />
is simple, most of the semantics are simple. But a language is more than just<br />
syntax; it’s about doing useful <em>stuff</em>. And doing useful stuff is not always<br />
easy in Go.</p>
<p>Turns out that combining all those simple features in a way to do something<br />
useful can be tricky. How do you remove an item from an array in Ruby?<br />
<code>list.delete_at(i)</code>. And remove entries by value? <code>list.delete(value)</code>. Pretty<br />
easy, yeah?</p>
<p>In Go it’s … less easy; to remove the index <code>i</code> you need to do:</p>
<div class="pre-wrap">
<pre><code>list = append(list[:i], list[i+1:]...)
</code></pre>
</div>
<p>And to remove the value <code>v</code> you’ll need to use a loop:</p>
<div class="pre-wrap">
<pre><code>n := 0
for _, l := range list {
    if l != v {
        list[n] = l
        n++
    }
}
list = list[:n]
</code></pre>
</div>
<p>Is this unacceptably hard? Not really; I think most programmers can figure out<br />
what the above does even without prior Go experience. But it’s not exactly<br />
<em>easy</em> either. I’m usually lazy and copy these kind of things from the <a href="https://github.com/golang/go/wiki/SliceTricks">Slice<br />
Tricks</a> page because I want to focus on actually solving the problem at<br />
hand, rather than plumbing like this.</p>
<p>It’s also easy to get it (subtly) wrong or suboptimal, especially for less<br />
experienced programmers. For example compare the above to copying to a new array<br />
and copying to a new pre-allocated array (<code>make([]string, 0, len(list))</code>):</p>
<div class="pre-wrap">
<pre class="ft-NONE"><code>InPlace             116 ns/op      0 B/op   0 allocs/op
NewArrayPreAlloc    525 ns/op    896 B/op   1 allocs/op
NewArray           1529 ns/op   2040 B/op   8 allocs/op
</code></pre>
</div>
<p>While 1529ns is still plenty fast enough for many use cases and isn’t something<br />
to excessively worry about, there are plenty of cases where these things <em>do</em><br />
matter and having the guarantee to always use the best possible algorithm with<br />
<code>list.delete(value)</code> has some value.</p>
<hr />
<p>Goroutines are another good example. “Look how is it is to start a goroutine!<br />
Just add <code>go</code> and you’re done!” Well, yes; you’re done until you have five<br />
million of those running at the same time and then you’re left wondering where<br />
all your memory went, and it’s not hard to “leak” goroutines by accident either.</p>
<p>There are a number of patterns to limit the number of goroutines, and none of<br />
them are exactly easy. A simple example might be something like:</p>
<div class="pre-wrap">
<pre><code>var (
	jobs    = 20                 // Run 20 jobs in total.
	running = make(chan bool, 3) // Limit concurrent jobs to 3.
	done    = make(chan bool)    // Signal that all jobs are done.
)

for i := 1; i &lt;= jobs; i++ {
	running &lt;- true // Fill running; this will block and wait if it's already full.

	// Start a job.
	go func(i int) {
		defer func() {
			&lt;-running      // Drain running so new jobs can be added.
			if i == jobs { // Last job, signal that we're done.
				done &lt;- true
			}
		}()

		// "do work"
		time.Sleep(1 * time.Second)
		fmt.Println(i)
	}(i)
}

&lt;-done // Wait until all jobs are done.
fmt.Println("done")
</code></pre>
</div>
<p>There’s a reason I annotated this with some comments: for people not intimately<br />
familiar with Go this may take some effort to understand. This also won’t ensure<br />
that the numbers are printed in order (which may or may not be a requirement).</p>
<p>Go’s concurrency primitives may be simple and easy to use, but combining them to<br />
solve common real-world scenarios is a lot less simple. The original version of<br />
the above example <a href="https://lobste.rs/s/ee6nsc/go_is_not_easy_language#c_gdnw5e">was actually incorrect</a>.</p>
<hr />
<p>In <a href="https://www.infoq.com/presentations/Simple-Made-Easy/">Simple Made Easy</a> Rich Hickey argues that we shouldn’t confuse “simple”<br />
with “it’s easy to write”: just because you can do something useful in one or<br />
two lines doesn’t mean the underlying concepts – and therefore the entire<br />
program – are “simple” as in “simple to understand”.</p>
<p>I feel there is some wisdom in this; in most cases we shouldn’t sacrifice<br />
“simple” for “easy”, but that doesn’t mean we can’t think at all about how to<br />
make things easier. Just because concepts are simple doesn’t mean they’re easy<br />
to use, can’t be misused, or can’t be used in ways that lead to (subtle) bugs.<br />
Pushing Hickey’s argument to the extreme we’d end up with something like<br />
<a href="https://en.wikipedia.org/wiki/Brainfuck">Brainfuck</a> and that would of course be silly.</p>
<p>Ideally a language should reduce the cognitive load required to reason about its<br />
behaviour; there are many ways to increase this cognitive load: complex<br />
intertwined language features is one of them, and getting “distracted” by<br />
implementing fairly basic things from those simple concepts is another: it’s<br />
another block of code I need to reason about. While I’m not overly concerned<br />
about code formatting or syntax choices, I do think it can matter to reduce this<br />
cognitive load when reading code.</p>
<p>The lack of generics probably plays some part here; implementing a <code>slices</code><br />
package which does these kind of things in a generic way is hard right now.<br />
Generics makes this possible and also makes things more complex (more language<br />
features are used), but they also make things easier and, arguably, less complex<br />
on other fronts.<sup id="fnref:g" role="doc-noteref"><a href="https://www.arp242.net/go-easy.html#fn:g" class="footnote">[1]</a></sup></p>
<hr />
<p>Are these insurmountable problems? No. I still use (and like) Go after all. But<br />
I also don’t think that Go is a language that you “could pick up in ~5-10<br />
minutes”, which was the comment that prompted this post; a sentiment I’ve seen<br />
expressed many times.</p>
<p>As a corollary to all of the above; learning the language isn’t just about<br />
learning the syntax to write your <code>if</code>s and <code>for</code>s; it’s about learning a way of<br />
thinking. I’ve seen many people coming from Python or C♯ try to shoehorn<br />
concepts or patterns from those languages in Go. Common ones include using<br />
struct embedding as inheritance, panics as exceptions, “pseudo-dynamic<br />
programming” with interface{}, and so forth. It rarely ends well, if ever.</p>
<p>I did this as well when I was writing my first Go program; it’s only natural.<br />
And when I started as a Ruby programmed I tried to write Python code in Ruby<br />
(although this works a bit better as the languages are more similar, but there<br />
are still plenty of odd things you can do such as using <code>for</code> loops).</p>
<p>This is why I don’t like it when people get redirected to the Tour of Go to<br />
“learn the language”, as it just teaches basic syntax and little more. It’s nice<br />
as a little, well, <em>tour</em> to get a bit of a feel of the language and see how it<br />
roughly works and what it can roughly do, but it’s ill-suited to actually learn<br />
the language.</p>
<div class="postscript" role="doc-endnotes"><strong>Footnotes</strong></p>
<ol>
<li id="fn:g" role="doc-endnote">
<p>Contrary to popular belief the <a href="https://research.swtch.com/generic">Go team was never “against” generics</a>;<br />
I’ve seen many comments to the effect of “the Go team doesn’t think<br />
generics are useful”, but this was never the case. <a href="https://www.arp242.net/go-easy.html#fnref:g" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
</li>
</ol>
</div>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/go/" rel="tag">Go</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-1069795" class="post-1069795 post type-post status-publish format-standard hentry tag-go tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/12/10/bitmasks-for-nicer-apis/" rel="bookmark">Bitmasks for nicer APIs</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/12/10/bitmasks-for-nicer-apis/" rel="bookmark"><time class="entry-date" datetime="2020-12-10T02:00:00+02:00">2020-12-10</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/arp242-net/" rel="author">arp242.net</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by arp242.net">arp242.net</a> original <a href="https://www.arp242.net/bitmask.html">https://www.arp242.net/bitmask.html</a></p>
<p>Bitmasks is one of those things where the basic idea is simple to understand:<br />
it’s just <code>0</code>s and <code>1</code>s being toggled on and off. But actually “having it click”<br />
to the point where it’s easy to work with can be a bit trickier. At least, it is<br />
(or rather, was) for me 😅</p>
<p>With a bitmask you hide (or “mask”) certain bits of a number, which can be<br />
useful for various things as we’ll see later on. There are two reasons one might<br />
use bitmasks: for efficiency or for nicer APIs. Efficiency is rarely an issue<br />
except for some embedded or specialized use cases, but everyone likes nice APIs,<br />
so this is about that.</p>
<hr />
<p>A while ago I added colouring support to my little <a href="https://github.com/zgoat/zli">zli</a> library. Adding<br />
colours to your terminal is not very hard as such, just print an escape code:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>fmt.Println("\x1b[34mRed text!\x1b[0m")
</code></pre>
</div>
<p>But a library makes this a bit easier. There’s already a bunch of libraries out<br />
there for Go specifically, the most popular being Fatih Arslan’s <a href="https://github.com/fatih/color"><code>color</code></a>:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>color.New(color.FgRed).Add(color.Bold).Add(color.BgCyan).Println("bold red")
</code></pre>
</div>
<p>This is stored as:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>type (
    Attribute int
    Color     struct { params  []Attribute }
)
</code></pre>
</div>
<p>I wanted a simple way to add some colouring, which looks a bit nicer than the<br />
method chain in the <code>color</code> library, and eventually figured out you don’t need a<br />
<code>[]int</code> to store all the different attributes but that a single <code>uint64</code> will do<br />
as well:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>zli.Colorf("bold red", zli.Red | zli.Bold | zli.Cyan.Bg())

// Or alternatively, use Color.String():
fmt.Printf("%sbold red%s\n", zli.Red|zli.Bold|zli.Cyan.Bg(), zli.Reset)
</code></pre>
</div>
<p>Which in my eyes looks a bit nicer than Fatih’s library, and also makes it<br />
easier to add 256 and true colour support.</p>
<p>All of the below can be used in any language by the way, and little of this is<br />
specific to Go. You will need Go 1.13 or newer for the binary literals to work.</p>
<hr />
<p>Here’s how <code>zli</code> stores all of this in a <code>uint64</code>:</p>
<div class="pre-wrap">
<pre class="full"><code>                                   fg true, 256, 16 color mode ─┬──┐
                                bg true, 256, 16 color mode ─┬─┐│  │
                                                             │ ││  │┌── parsing error
 ┌───── bg color ────────────┐ ┌───── fg color ────────────┐ │ ││  ││┌─ term attr
 v                           v v                           v v vv  vvv         v
 0000_0000 0000_0000 0000_0000 0000_0000 0000_0000 0000_0000 0000_0000 0000_0000
 ^         ^         ^         ^         ^         ^         ^         ^
64        56        48        40        32        24        16         8
</code></pre>
</div>
<p>I’ll go over it in detail later, but in short (from right to left):</p>
<ul>
<li>
<p>The first 9 bits are flags for the basic terminal attributes such as bold,<br />
italic, etc.</p>
</li>
<li>
<p>The next bit is to signal a parsing error for true colour codes (e.g. <code>#123123</code>).</p>
</li>
<li>
<p>There are 3 flags for the foreground and background colour each to signal that<br />
a colour should be applied, and how it should be interpreted (there are 3<br />
different ways to set the colour: 16-colour, 256-colour, and 24-bit “true<br />
colour”, which use different escape codes).</p>
</li>
<li>
<p>The colours for the foreground and background are stored separately, because<br />
you can apply both a foreground and background. These are 24-bit numbers.</p>
</li>
<li>
<p>A value of 0 is reset.</p>
</li>
</ul>
<p>With this, you can make any combination of the common text attributes, the above<br />
example:</p>
<div class="pre-wrap">
<pre><code>zli.Colorf("bold red", zli.Red | zli.Bold | zli.Cyan.Bg())
</code></pre>
</div>
<p>Would be the following in binary layout:</p>
<div class="pre-wrap">
<pre class="full">                                              fg 16 color mode ────┐
                                           bg 16 color mode ───┐   │
                                                               │   │        bold
                bg color ─┬──┐                fg color ─┬──┐   │   │           │
                          v  v                          v  v   v   v           v
 0000_0000 0000_0000 0000_0<b>1</b><b>1</b>0 0000_0000 0000_0000 0000_000<b>1</b> 00<b>1</b>0_0<b>1</b>00 0000_000<b>1</b>
 ^         ^         ^         ^         ^         ^         ^         ^
64        56        48        40        32        24        16         8
</pre>
</div>
<p></p>
<hr />
<p>We need to go through several steps to actually do something meaningful with<br />
this. First, we want to get all the flag values (the first 24 bits); a “flag” is<br />
a bit being set to true (<code>1</code>) or false (<code>0</code>).</p>
<div class="pre-wrap">
<pre class="ft-go"><code>const (
    Bold         = 0b0_0000_0001
    Faint        = 0b0_0000_0010
    Italic       = 0b0_0000_0100
    Underline    = 0b0_0000_1000
    BlinkSlow    = 0b0_0001_0000
    BlinkRapid   = 0b0_0010_0000
    ReverseVideo = 0b0_0100_0000
    Concealed    = 0b0_1000_0000
    CrossedOut   = 0b1_0000_0000
)

func applyColor(c uint64) {
    if c &amp; Bold != 0 {
        // Write escape code for bold
    }
    if c &amp; Faint != 0 {
        // Write escape code for faint
    }
    // etc.
}
</code></pre>
</div>
<p><code>&amp;</code> is the bitwise AND operator. It works just as the more familiar <code>&amp;&amp;</code> except<br />
that it operates on every individual bit where <code>0</code> is <code>false</code> and <code>1</code> is <code>true</code>.<br />
The end result will be <code>1</code> if both bits are “true” (<code>1</code>). An example with just<br />
four bits:</p>
<div class="pre-wrap">
<pre>00<b>1</b><b>1</b> &amp; 0<b>1</b>0<b>1</b> = 000<b>1</b>
</pre>
</div>
<p>This can be thought of as four separate operations (from left to right):</p>
<div class="pre-wrap">
<pre><code>0 AND 0 = 0      both false
0 AND 1 = 0      first value is false, so the end result is false
1 AND 0 = 0      second value is false
1 AND 1 = 1      both true
</code></pre>
</div>
<p>So what <code>if c &amp; Bold != 0</code> does is check if the “bold bit” is set:</p>
<div class="pre-wrap">
<pre>Only bold set:
0 0000 000<b>1</b> &amp; 0 0000 000<b>1</b> = 0 0000 000<b>1</b>

Underline bit set:
0 0000 <b>1</b>000 &amp; 0 0000 000<b>1</b> = 0 0000 0000      0 since there are no cases of "1 AND 1"

Bold and underline bits set:
0 0000 <b>1</b>00<b>1</b> &amp; 0 0000 000<b>1</b> = 0 0000 000<b>1</b>      Only "bold AND bold" is "1 AND 1"
</pre>
</div>
<p>As you can see, <code>c &amp; Bold != 0</code> could also be written as <code>c &amp; Bold == Bold</code>.</p>
<hr />
<p>The colours themselves are stored as a regular number like any other, except<br />
that they’re “offset” a number of bits. To get the actual number value we need<br />
to clear all the bits we don’t care about, and shift it all to the right:</p>
<div class="pre-wrap">
<pre class="full ft-go"><code>const (
    colorOffsetFg   = 16

    colorMode16Fg   = 0b0000_0100_0000_0000
    colorMode256Fg  = 0b0000_1000_0000_0000
    colorModeTrueFg = 0b0001_0000_0000_0000

    maskFg          = 0b00000000_00000000_00000000_11111111_11111111_11111111_00000000_00000000
)

func getColor(c uint64) {
    if c &amp; colorMode16Fg != 0  {
        cc := (c &amp; maskFg) &gt;&gt; colorOffsetFg
        // ..write escape code for this color..
    }
}
</code></pre>
</div>
<p>First we check if the “16 colour mode” flag is set using the same method as the<br />
terminal attributes, and then we AND it with <code>maskFg</code> to clear all the bits we<br />
don’t care about:</p>
<div class="pre-wrap">
<pre class="full">                                   fg true, 256, 16 color mode ─┬──┐
                                bg true, 256, 16 color mode ─┬─┐│  │
                                                             │ ││  │┌── parsing error
 ┌───── bg color ────────────┐ ┌───── fg color ────────────┐ │ ││  ││┌─ term attr
 v                           v v                           v v vv  vvv         v
 0000_0000 0000_0000 0000_0<b>1</b><b>1</b>0 0000_0000 0000_0000 0000_000<b>1</b> 00<b>1</b>0_0<b>1</b>00 0000_<b>1</b>00<b>1</b>
AND maskFg
 0000_0000_0000_0000_0000_0000_<b>1</b><b>1</b><b>1</b><b>1</b>_<b>1</b><b>1</b><b>1</b><b>1</b>_<b>1</b><b>1</b><b>1</b><b>1</b>_<b>1</b><b>1</b><b>1</b><b>1</b>_<b>1</b><b>1</b><b>1</b><b>1</b>_<b>1</b><b>1</b><b>1</b><b>1</b>_0000_0000_0000_0000
=
 0000_0000 0000_0000 0000_0000 0000_0000 0000_0000 0000_000<b>1</b> 0000_0000 0000_0000
 ^         ^         ^         ^         ^         ^         ^         ^
64        56        48        40        32        24        16         8
</pre>
</div>
<p>After the AND operation we’re left with just the 24 bits we care about, and<br />
everything else is set to <code>0</code>. To get a normal number from this we need to shift<br />
the bits to the right with <code>&gt;&gt;</code>:</p>
<div class="pre-wrap">
<pre><b>1</b>0<b>1</b>0 &gt;&gt; 1 = 0<b>1</b>0<b>1</b>    All bits shifted one position to the right.
<b>1</b>0<b>1</b>0 &gt;&gt; 2 = 00<b>1</b>0    Shift two, note that one bit gets discarded.
</pre>
</div>
<p>Instead of <code>&gt;&gt; 16</code> you can also subtract <code>65535</code> (a 16-bit number): <code>(c &amp;<br />
maskFg) - 65535</code>. The end result is the same, but bit shifts are much easier to<br />
reason about in this context.</p>
<p>We repeat this for the background colour (except that we shift everything 40<br />
bits to the right). The background is actually a bit easier since we don’t need<br />
to AND anything to clear bits, as all the bits to the right will just be<br />
discarded:</p>
<div class="pre-wrap">
<pre><code>cc := c &gt;&gt; ColorOffsetBg
</code></pre>
</div>
<p>For 256 and “true” 24-bit colours we do the same, except that we need to send<br />
different escape codes for them, which is a detail that doesn’t really matter<br />
for this explainer about bitmasks.</p>
<hr />
<p>To set the background colour we use the <code>Bg()</code> function to transforms a<br />
foreground colour to a background one. This avoids having to define <code>BgCyan</code><br />
constants like Fatih’s library, and makes working with 256 and true colour<br />
easier.</p>
<div class="pre-wrap">
<pre class="full ft-go"><code>const (
    colorMode16Fg   = 0b00000_0100_0000_0000
    colorMode16Bg   = 0b0010_0000_0000_0000

    maskFg          = 0b00000000_00000000_00000000_11111111_11111111_11111111_00000000_00000000
)

func Bg(c uint64) uint64 {
    if c &amp; colorMode16Fg != 0 {
        c = c ^ colorMode16Fg | colorMode16Bg
    }
    return (c &amp;^ maskFg) | (c &amp; maskFg &lt;&lt; 24)
}
</code></pre>
</div>
<p>First we check if the foreground colour flags is set; if it is then move that<br />
bit to the corresponding background flag.</p>
<p><code>|</code> is the OR operator; this works like <code>||</code> except on individual bits like in<br />
the above example for <code>&amp;</code>. Note that unlike <code>||</code> it won’t stop if the first<br />
condition is false/0: if any of the two values are <code>1</code> the end result will be<br />
<code>1</code>:</p>
<div class="pre-wrap">
<pre>0 OR 0 = 0      both false
0 OR 1 = 1      second value is true, so end result is true
1 OR 0 = 1      first value is true
1 OR 1 = 1      both true

00<b>1</b><b>1</b> | 0<b>1</b>0<b>1</b> = 0<b>1</b><b>1</b><b>1</b>
</pre>
</div>
<p><code>^</code> is the “exclusive or”, or XOR, operator. It’s similar to OR except that it<br />
only outputs <code>1</code> if exactly one value is <code>1</code>, and not if both are:</p>
<div class="pre-wrap">
<pre>0 XOR 0 = 0      both false
0 XOR 1 = 1      second value is true, so end result is true
1 XOR 0 = 1      first value is true
1 XOR 1 = 0      both true, so result is 0

00<b>1</b><b>1</b> ^ 0<b>1</b>0<b>1</b> = 0<b>1</b>0<b>1</b>
</pre>
</div>
<p>Putting both together, <code>c ^ colorMode16Fg</code> clears the foreground flag and <code>|<br />
colorMode16Bg</code> sets the background flag.</p>
<p>The last line moves the bits from the foreground colour to the background<br />
colour:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>return (c &amp;^ maskFg) | (c &amp; maskFg &lt;&lt; 24)
</code></pre>
</div>
<p><code>&amp;^</code> is “AND NOT”: these are two operations: first it will inverse the right<br />
side (“NOT”) and then ANDs the result. So in our example the <code>maskFg</code> value is<br />
inversed:</p>
<div class="pre-wrap">
<pre class="full"> 0000_0000_0000_0000_0000_0000_1111_1111_1111_1111_1111_1111_0000_0000_0000_0000
<b>NOT</b>
 1111_1111_1111_1111_1111_1111_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
</pre>
</div>
<p>We then used this inversed <code>maskFg</code> value to clear the foreground colour,<br />
leaving everything else intact:</p>
<div class="pre-wrap">
<pre class="full"> 1111_1111_1111_1111_1111_1111_0000_0000_0000_0000_0000_0000_1111_1111_1111_1111
<b>AND</b>
 0000_0000 0000_0000 0000_0<b>1</b><b>1</b>0 0000_0000 0000_0000 0000_000<b>1</b> 00<b>1</b>0_0<b>1</b>00 0000_<b>1</b>00<b>1</b>
<b>=</b>
 0000_0000 0000_0000 0000_0<b>1</b><b>1</b>0 0000_0000 0000_0000 0000_0000 00<b>1</b>0_0<b>1</b>00 0000_<b>1</b>00<b>1</b>
 ^         ^         ^         ^         ^         ^         ^         ^
64        56        48        40        32        24        16         8
</pre>
</div>
<p>C and most other languages don’t have this operator and have <code>~</code> for NOT (which<br />
Go doesn’t have), so the above would be <code>(c &amp; ~maskFg)</code> in most other languages.</p>
<p>Finally, we set the background colour by clearing all bits that are not part of<br />
the foreground colour, shifting them to the correct place, and ORing this to get<br />
the final result.</p>
<hr />
<p>I skipped a number of implementation details in the above example for clarity,<br />
especially for people not familiar with Go. <a href="https://github.com/zgoat/zli/blob/master/color.go">The full code is of course<br />
available</a>. Putting all of<br />
this together gives a fairly nice API IMHO in about 200 lines of code which<br />
mostly avoids boilerplateism.</p>
<p>I only showed the 16-bit colours in the examples, in reality most of this is<br />
duplicated for 256 and true colours as well. It’s all the same logic, just with<br />
different values. I also skipped over the details of terminal colour codes, as<br />
this article isn’t really about that.</p>
<p>In many of the above examples I used binary literals for the constants, and this<br />
seemed the best way to communicate how it all works for this article. This isn’t<br />
necessarily the best or easiest way to write things in actual code, especially<br />
not for such large numbers. In the actual code it looks like:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>const (
    ColorOffsetFg = 16
    ColorOffsetBg = 40
)

const (
    maskFg Color = (256*256*256 - 1) &lt;&lt; ColorOffsetFg
    maskBg Color = maskFg &lt;&lt; (ColorOffsetBg - ColorOffsetFg)
)

// Basic terminal attributes.
const (
    Reset Color = 0
    Bold  Color = 1 &lt;&lt; (iota - 1)
    Faint
    // ...
)
</code></pre>
</div>
<p>Figuring out how this works is left as an exercise for the reader 🙂</p>
<p>Another thing that might be useful is a little helper function to print a number<br />
as binary; it helps visualise things if you’re confused:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>func bin(c uint64) {
    reBin := regexp.MustCompile(`([01])([01])([01])([01])([01])([01])([01])([01])`)
    reverse := func(s string) string {
        runes := []rune(s)
        for i, j := 0, len(runes)-1; i &lt; j; i, j = i+1, j-1 {
            runes[i], runes[j] = runes[j], runes[i]
        }
        return string(runes)
    }
    fmt.Printf("%[2]s → %[1]d\n", c,
        reverse(reBin.ReplaceAllString(reverse(fmt.Sprintf("%064b", c)),
            `$1$2$3${4}_$5$6$7$8 `)))
}
</code></pre>
</div>
<p>I put a slighly more advanced version of this at<br />
<a href="https://pkg.go.dev/zgo.at/zstd/zfmt#Binary">zgo.at/zstd/zfmt.Binary</a>.</p>
<p>You can also write a little wrapper to make things a bit easier:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>type Bitflag64 uint64 uint64

func (f Bitflag64) Has(flag Bitflag64) bool { return f&amp;flag != 0 }
func (f *Bitflag64) Set(flag Bitflag64)     { *f = *f | flag }
func (f *Bitflag64) Clear(flag Bitflag64)   { *f = *f &amp;^ flag }
func (f *Bitflag64) Toggle(flag Bitflag64)  { *f = *f ^ flag }
</code></pre>
</div>
<p>If you need more than 64 bits then not all is lost; you can use <code>type thingy<br />
[2]uint64</code>.</p>
<hr />
<p>Here’s an example where I did it wrong:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>type APITokenPermissions struct {
    Count      bool 
    Export     bool 
    SiteRead   bool 
    SiteCreate bool 
    SiteUpdate bool 
}
</code></pre>
</div>
<p>This records the permissions for an API token the user creates. Looks nice, but<br />
how do you check that <em>only</em> <code>Count</code> is set?</p>
<div class="pre-wrap">
<pre class="ft-go"><code>if p.Count &amp;&amp; !p.Export &amp;&amp; !p.SiteRead &amp;&amp; !p.SiteCreate &amp;&amp; !p.SiteUpdate { .. }
</code></pre>
</div>
<p>Ugh; not very nice, and neither is checking if multiple permissions are set:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>if perm.Export &amp;&amp; perm.SiteRead &amp;&amp; perm.SiteCreate &amp;&amp; perm.SiteUpdate { .. }
</code></pre>
</div>
<p>Had I stored it as a bitmask instead, it would have been easier:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>if perm &amp; Count == 0 { .. }

const permSomething = perm.Export | perm.SiteRead | perm.SiteCreate | perm.SiteUpdate
if perm &amp; permEndpointSomething == 0 { .. }
</code></pre>
</div>
<p>No one likes functions with these kind of signatures either:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>f(false, false, true)
f(true, false, true)
</code></pre>
</div>
<p>But with a bitmask things can look a lot nicer:</p>
<div class="pre-wrap">
<pre class="ft-go"><code>const (
    AddWarpdrive   = 0b0001
    AddTractorBeam = 0b0010
    AddPhasers     = 0b0100
)

f(AddPhasers)
f(AddWarpdrive | AddPhasers)
</code></pre>
</div>
<style>b { color: red }</style>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/go/" rel="tag">Go</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-1069797" class="post-1069797 post type-post status-publish format-standard hentry tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/11/29/stupid-light-software/" rel="bookmark">Stupid light software</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/11/29/stupid-light-software/" rel="bookmark"><time class="entry-date" datetime="2020-11-29T02:00:00+02:00">2020-11-29</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/arp242-net/" rel="author">arp242.net</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by arp242.net">arp242.net</a> original <a href="https://www.arp242.net/stupid-light.html">https://www.arp242.net/stupid-light.html</a></p>
<p>The ultralight hiking community is – as you may gather from the name – very<br />
focused on ultralight equipment and minimalism. Turns out that saving a bit of<br />
weight ten times actually adds up to a significant weight savings, making hikes<br />
– especially longer ones of several days or weeks – a lot more comfortable.</p>
<p>There’s also the concept of <a href="https://andrewskurka.com/stupid-light-not-always-right-or-better/">stupid light</a>: when you save weight to the<br />
point of stupidity. You won’t be comfortable, you’ll miss stuff you need, your<br />
equipment will be too fragile.</p>
<p>In software, I try to avoid dependencies, needless features, and complexity to<br />
keep things reasonably lightweight. Software is already hard to start with, and<br />
the more of it you have the harder it gets. But you need to be careful not to<br />
make it stupid light.</p>
<p>It’s a good idea to avoid a database if you don’t need one; often flat text<br />
files or storing data in memory works just as well. But at the same time<br />
databases do offer some advantages: it’s structured and it deals with file<br />
locking and atomicity. A younger me would avoid databases at all costs and in<br />
hindsight that was just stupid light in some cases. You don’t need to<br />
immediately jump to PostgreSQL or MariaDB either, and there are many<br />
intermediate solutions, SQLite being the best known, but <a href="https://sqlite.org/whentouse.html">SQLite can also be<br />
stupid light</a> in some use cases.</p>
<p>Including a huge library may be overkill for what you need from it; you can<br />
perhaps just copy that one function out of there, or reimplement your own if<br />
it’s simple enough. But this only a good idea if you can do it <em>well</em> and ensure<br />
it’s actually correct (are you <em>sure</em> all edge cases are handled correctly?)<br />
Otherwise it just becomes stupid light.</p>
<p>I’ve seen several people write their own translation services. All of them were<br />
lighter than gettext. And they were also completely terrible and stupid light.</p>
<p>Adding features or API interfaces can come with significant costs in maintenance<br />
and complexity. But if you’re sacrificing UX and people need to work around the<br />
lack of features then you app or API just becomes stupid light.</p>
<p>It’s all about a certain amount of balance. Lightweight is good, bloated is bad,<br />
and stupid light is just as bad as bloated, or perhaps even worse since bloated<br />
software usually at least allowed you to accomplish the task whereas stupid<br />
light may prevent you from doing so.</p>
<hr />
<p>I won’t list any examples here as I don’t really want to call out people’s work<br />
as “stupid”, especially if they’re hobby projects people work on in their spare<br />
time. I can think of a few examples, but does adding them really add any value?<br />
I’m not so sure that it does. Arguably “stupid light” isn’t really the best<br />
wording here – the original usage in hiking context is mostly a self-deprecating<br />
one – and a different one without “stupid” would be better, but I couldn’t<br />
really think of anything better 🤷 And it does have a nice ring to it.</p>
<p>Stupid light isn’t something you can measure and define exactly, just like you<br />
can’t measure and exactly define “bloat”. It depends on a lot of factors. But<br />
just as it’s worth thinking about “do we really need this?” to avoid bloat, it’s<br />
also worth thinking about “can we really do without this?” to avoid stupid<br />
light.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-1069801" class="post-1069801 post type-post status-publish format-standard hentry tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/11/25/an-api-is-a-user-interface/" rel="bookmark">An API is a user interface</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/11/25/an-api-is-a-user-interface/" rel="bookmark"><time class="entry-date" datetime="2020-11-25T02:00:00+02:00">2020-11-25</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/arp242-net/" rel="author">arp242.net</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by arp242.net">arp242.net</a> original <a href="https://www.arp242.net/api-ux.html">https://www.arp242.net/api-ux.html</a></p>
<p>An API is a user interface for programmers and is essentially no different from<br />
a graphical user interface, command-line user interface, or any other interface<br />
a human (“user”) is expected to work with. Whenever you create a publicly<br />
callable function you’re creating a user interface. Programmers are users, too.</p>
<p>This applies for any API: libX11, libpng, Ruby on Rails (good UX is a major<br />
factor for Rails’ success), a REST API, etc.</p>
<p>A library exists of two parts: implementation and exposed API. The<br />
implementation is all about doing <em>stuff</em> and interacting with the computer,<br />
whereas the exposed API is about giving a human access to this, preferably in a<br />
convenient way that makes it easy to understand, and making it hard to get<br />
things wrong.</p>
<p>This may sound rather obvious, but in my experience this often seems forgotten.<br />
The world is full of badly documented clunky APIs that give confusing errors (or<br />
no errors!) to prove it.</p>
<p>Whenever I design a public package, module, or class I tend to start by writing<br />
a few basic usage examples and documenting it. This first draft won’t be perfect<br />
and while writing the implementation I keep updating the examples and<br />
documentation to iterate on what works and axe what doesn’t. This is kind of<br />
like TDD, except that it “tests” the UX rather than the implementation. Call it<br />
<em>Example Driven Development</em> if you will.</p>
<p>This is similar to sketching a basic mock UI for a GUI and avoids “oh, we need<br />
to be able to do that too” half-way through building your UI, leading to awkward<br />
clunky UI elements added willy-nilly as an afterthought.</p>
<p>In code reviews the first questions I usually have are things like “is this API<br />
easy to use?”, “Is it consistent?”, “can we extend it in the future so it won’t<br />
be ugly?”, “is it documented, and is the documentation comprehensible?”.<br />
Sometimes I’ll even go as far as trying to write a simple example to see if<br />
there are any problems and if it “feels” right. Only if this part is settled do<br />
I move on to reviewing the correctness of the actual implementation.</p>
<hr />
<p>I’m not going to list specific examples or tips here; it really depends on the<br />
environment, intended audience (kernel programmers are not Rails programmers),<br />
and most of all: what you’re doing.</p>
<p>Sometimes a single function with five parameters would be bad UX, whereas in<br />
other cases it might be a good option, if all five really are mandatory for<br />
example, or if you use Python and have named parameters. In other cases, it<br />
makes more sense to have five functions which accepts a single parameter.</p>
<p>There usually isn’t “one right way”. If everyone started treating APIs as user<br />
interfaces instead of “oh, it’s just for developers, they will figure it out”<br />
then we’ll be 90% there.</p>
<p>That being said, the most useful general piece of advice I know of is John<br />
Ousterhout’s concept of <em>deep modules</em>: modules that provide large functionality<br />
with simple interfaces. <a href="https://nakabonne.dev/posts/depth-of-module/">Depth of module</a> is a nice overview with goes in<br />
to some more details about this, and I won’t repeat it here.</p>
<div class="postscript"><strong>Related articles</strong></p>
<ul>
<li><a href="http://kevinmahoney.co.uk/articles/your-database-as-an-api/">Your Database as an API</a></li>
<li><a href="https://medium.com/@quikchange/ux-testing-for-code-e9ab157fb90f">UX Testing for Code</a></li>
<li><a href="https://www.drdobbs.com/windows/measuring-api-usability/184405654">Measuring API Usability</a></li>
<li><a href="https://tom.preston-werner.com/2010/08/23/readme-driven-development.html">Readme Driven Development</a></li>
</ul>
<div>
</div>
</div>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-1022389" class="post-1022389 post type-post status-publish format-standard hentry tag-deep-dive tag-linux tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/10/27/diving-into-proc-pid-mem/" rel="bookmark">Diving into /proc/[pid]/mem</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/10/27/diving-into-proc-pid-mem/" rel="bookmark"><time class="entry-date" datetime="2020-10-27T14:00:00+02:00">2020-10-27</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/lennart-espe/" rel="author">Lennart Espe</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Lennart Espe">Lennart Espe</a> original <a href="https://blog.cloudflare.com/diving-into-proc-pid-mem/">https://blog.cloudflare.com/diving-into-proc-pid-mem/</a></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2020/10/image3-25.png" class="kg-image" alt="Diving into /proc/[pid]/mem"></figure>
<p><img src="https://blog.cloudflare.com/content/images/2020/10/image2-27.png" alt="Diving into /proc/[pid]/mem"></p>
<p>A few months ago, after reading about <a href="https://blog.cloudflare.com/cloudflare-doubling-size-of-2020-summer-intern-class/">Cloudflare doubling its intern class size</a>, I quickly dusted off my CV and applied for an internship. Long story short: now, a couple of months later, I found myself staring into Linux kernel code and adding a pretty cool feature <a href="https://gvisor.dev/">to gVisor, a Linux container runtime</a>.</p>
<p>My internship was under the Emerging Technologies and Incubation group on a project involving gVisor. A co-worker contacted my team about not being able to read the debug symbols of stack traces inside the sandbox. For example, when the isolated process crashed, this is what we saw in the logs:</p>
<pre><code>*** Check failure stack trace: ***
    @     0x7ff5f69e50bd  (unknown)
    @     0x7ff5f69e9c9c  (unknown)
    @     0x7ff5f69e4dbd  (unknown)
    @     0x7ff5f69e55a9  (unknown)
    @     0x5564b27912da  (unknown)
    @     0x7ff5f650ecca  (unknown)
    @     0x5564b27910fa  (unknown)
</code></pre>
<p>Obviously, this wasn&#8217;t very useful. I eagerly volunteered to fix this stack unwinding code &#8211; how hard could it be?</p>
<p>After some debugging, we found that the logging library used in the project opened <code>/proc/self/mem</code> to look for ELF headers at the start of each memory-mapped region. This was necessary to calculate an offset to find the correct addresses for debug symbols.</p>
<p>It turns out this mechanism is rather common. The stack unwinding code is often run in weird contexts &#8211; like a SIGSEGV handler &#8211; so it would not be appropriate to dig over real memory addresses back and forth to read the ELF. This could trigger another SIGSEGV. And SIGSEGV inside a SIGSEGV handler means either termination via the default handler for a segfault or recursing into the same handler again and again (if one sets <code>SA_NODEFER</code>) leading to a stack overflow.</p>
<p>However, inside gVisor, each call of <code>open()</code> on <code>/proc/self/mem</code> resulted in <code>ENOENT</code>, because the entire <code>/proc/self/mem</code> file was missing. In order to provide a robust sandbox, gVisor has to carefully reimplement the Linux kernel interfaces. This particular <code>/proc</code> file was simply unimplemented in the virtual file system of Sentry, one of gVisor&#8217;s sandboxing components.<br />
<a href="https://blog.cloudflare.com/author/marek-majkowski/">Marek</a> asked the devs on the project chat and got confirmation &#8211; they would be happy to accept a patch implementing this file.<br />
<img src="https://blog.cloudflare.com/content/images/2020/10/image1-39.png" alt="Diving into /proc/[pid]/mem"></p>
<p>The easy way out would have been to make a small, local patch to the unwinder behavior, yet I found myself diving into the Linux kernel trying to figure how the <code>mem</code> file worked in an attempt to implement it in Sentry&#8217;s VFS.</p>
<h2 id="whatdoesprocpidmemdo">What does <code>/proc/[pid]/mem</code> do?</h2>
<p>The file itself is quite powerful, because it allows raw access to the virtual address space of a process. <a href="https://man7.org/linux/man-pages/man5/proc.5.html">According to manpages</a>, the documented file operations are <code>open()</code>, <code>read()</code> and <code>lseek()</code>. Typical use cases are debugging tasks or dumping process memory.</p>
<h2 id="openingthefile">Opening the file</h2>
<p>When a process wants to open the file, the kernel does the file permissions check, looks up the associated operations for <code>mem</code> and invokes a method called <code>proc_mem_open</code>. It retrieves the associated task and <a href="https://elixir.bootlin.com/linux/v5.9/source/include/linux/sched/mm.h#L119">calls a method named <code>mm_access</code></a>.</p>
<pre><code class="language-C">/*
 * Grab a reference to a task's mm, if it is not already going away
 * and ptrace_may_access with the mode parameter passed to it
 * succeeds.
 */
</code></pre>
<p>Seems relatively straightforward, right? The special thing about <code>mm_access</code> is that it verifies the permissions the current task has regarding the task to which the memory belongs. If the current task and target task do not share the same memory manager, the kernel <a href="https://elixir.bootlin.com/linux/v5.9/source/kernel/ptrace.c#L293">invokes a method named <code>__ptrace_may_access</code></a>.</p>
<pre><code class="language-C">/*
 * May we inspect the given task?
 * This check is used both for attaching with ptrace
 * and for allowing access to sensitive information in /proc.
 *
 * ptrace_attach denies several cases that /proc allows
 * because setting up the necessary parent/child relationship
 * or halting the specified task is impossible.
 *
 */
</code></pre>
<p><a href="https://man7.org/linux/man-pages/man5/proc.5.html">According to the manpages</a>, a process which would like to read from an unrelated <code>/proc/[pid]/mem</code> file should have access mode <a href="https://man7.org/linux/man-pages/man2/ptrace.2.html"><code>PTRACE_MODE_ATTACH_FSCREDS</code></a>. This check does not verify that a process is attached via <code>PTRACE_ATTACH</code>, but rather if it has the permission to attach with the specified credentials mode.</p>
<h2 id="accesschecks">Access checks</h2>
<p>After skimming through the function, you will see that a process is allowed access if the current task belongs to the same thread group as the target task, or denied access (depending on whether <code>PTRACE_MODE_FSCREDS</code> or <code>PTRACE_MODE_REALCREDS</code> is set, we will use either the file-system UID / GID, which is typically the same as the effective UID/GID, or the real UID / GID) if none of the following conditions are met:</p>
<ul>
<li>the current task&#8217;s credentials (UID, GID) match up with the credentials (real, effective and saved set-UID/GID) of the target process</li>
<li>the current task has <code>CAP_SYS_PTRACE</code> inside the user namespace of the target process</li>
</ul>
<p>In the next check, access is denied if the current task has neither <code>CAP_SYS_PTRACE</code> inside the user namespace of the target task, nor the target&#8217;s dumpable attribute is set to <code>SUID_DUMP_USER</code>. <a href="https://man7.org/linux/man-pages/man2/prctl.2.html">The dumpable attribute</a> is typically required to allow producing core dumps.</p>
<p>After these three checks, we also go through the commoncap Linux Security Module (and other LSMs) to verify our access mode is fine. LSMs you may know are SELinux and AppArmor. The commoncap LSM performs the checks on the basis of effective or permitted process capabilities (depending on the mode being <code>FSCREDS</code> or <code>REALCREDS</code>), allowing access if</p>
<ul>
<li>the capabilities of the current task are a superset of the capabilities of the target task, or</li>
<li>the current task has <code>CAP_SYS_PTRACE</code> in the target task&#8217;s user namespace</li>
</ul>
<p>In conclusion, one has access (with only commoncap LSM checks active) if:</p>
<ul>
<li>the current task is in the same task group as the target task, or</li>
<li>the current task has <code>CAP_SYS_PTRACE</code> in the target task&#8217;s user namespace, or</li>
<li>the credentials of the current and target task match up in the given credentials mode, the target task is dumpable, they run in the same user namespace and the target task&#8217;s capabilities are a subset of the current task&#8217;s capabilities</li>
</ul>
<p>I highly recommend reading through the <a href="https://www.man7.org/linux/man-pages/man2/ptrace.2.html">ptrace manpages</a> to dig deeper into the different modes, options and checks.</p>
<h2 id="readingfromthefile">Reading from the file</h2>
<p>Since all the access checks occur when opening the file, reading from it is quite straightforward. When one invokes <code>read()</code> on a <code>mem</code> file, <a href="https://elixir.bootlin.com/linux/v5.9/source/fs/proc/base.c#L835">it calls up <code>mem_rw</code></a> (which actually can do both reading and writing).</p>
<p>To avoid using lots of memory, <code>mem_rw</code> performs the copy in a loop and buffers the data in an intermediate page. <code>mem_rw</code> has a hidden superpower, that is, it uses <code>FOLL_FORCE</code> to avoid permission checks on user-owned pages (handling pages marked as non-readable/non-writable readable and writable).</p>
<p><code>mem_rw</code> has other specialties, such as its error handling. Some interesting cases are:</p>
<ul>
<li>if the target task has exited after opening the file descriptor, performing <code>read()</code> will always succeed with reading 0 bytes</li>
<li>if the initial copy from the target task&#8217;s memory to the intermediate page fails, it does not always return an error but only if no data has been read</li>
</ul>
<p>You can also perform <code>lseek</code> on the file excluding <code>SEEK_END</code>.</p>
<h2 id="howitworksingvisor">How it works in gVisor</h2>
<p>Luckily, gVisor already implemented <code>ptrace_may_access</code> as <code>kernel.task.CanTrace</code>, so one can avoid reimplementing all the ptrace access logic. However, <a href="https://cs.opensource.google/gvisor/gvisor/+/master:pkg/sentry/kernel/ptrace.go;l=105;bpv=0;bpt=1">the implementation in gVisor</a> is less complicated due to the lack of support for <code>PTRACE_MODE_FSCREDS</code> (which is <a href="https://gvisor.dev/issue/260">still an open issue</a>).</p>
<p>When a new file descriptor is <code>open()</code>ed, the <code>GetFile</code> method of the virtual Inode is invoked, therefore this is where the access check naturally happens. After a successful access check, the <a href="https://pkg.go.dev/gvisor.dev/gvisor/pkg/sentry/fs#File">method returns a <code>fs.File</code></a>. The <code>fs.File</code> implements all the file operations you would expect such as <code>Read()</code> and <code>Write()</code>. gVisor also provides tons of primitives for quickly building a working file structure so that one does not have to reimplement a generic <code>lseek()</code> for example.</p>
<p>In case a task invokes a <code>Read()</code> call onto the <code>fs.File</code>, the <code>Read</code> method retrieves the memory manager of the file’s Task.<br />
<a href="https://pkg.go.dev/gvisor.dev/gvisor/pkg/sentry/mm#MemoryManager">Accessing the task&#8217;s memory manager</a> is a breeze with comfortable <code>CopyIn</code> and <code>CopyOut</code> methods, with interfaces similar to <code>io.Writer</code> and <code>io.Reader</code>.</p>
<p>After implementing all of this, we finally got a useful stack trace.</p>
<pre><code>*** Check failure stack trace: ***
    @     0x7f190c9e70bd  google::LogMessage::Fail()
    @     0x7f190c9ebc9c  google::LogMessage::SendToLog()
    @     0x7f190c9e6dbd  google::LogMessage::Flush()
    @     0x7f190c9e75a9  google::LogMessageFatal::~LogMessageFatal()
    @     0x55d6f718c2da  main
    @     0x7f190c510cca  __libc_start_main
    @     0x55d6f718c0fa  _start
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>A comprehensive victory! The <code>/proc/&lt;pid&gt;/mem</code> file is an important mechanism that gives insight into contents of process memory. It is essential to stack unwinders to do their work in case of complicated and unforeseeable failures. Because the process memory contains highly-sensitive information, data access to the file is determined by a complex set of poorly documented rules. With a bit of effort, you can emulate <code>/proc/[PID]/mem</code> inside gVisor’s sandbox, where the process only has access to the subset of procfs that has been implemented by the gVisor authors and, as a result, you can have access to an easily readable stack trace in case of a crash.</p>
<p><a href="https://github.com/google/gvisor/pull/4060">Now I can&#8217;t wait to get the PR merged into gVisor.</a></p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/deep-dive/" rel="tag">deep dive</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-999533" class="post-999533 post type-post status-publish format-standard hentry tag-ebpf tag-linux tag-programming tag-udp">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/09/18/raking-the-floods-how-to-protect-udp-services-from-dos-attacks-with-ebpf/" rel="bookmark">Raking the floods: How to protect UDP services from DoS attacks with eBPF</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/09/18/raking-the-floods-how-to-protect-udp-services-from-dos-attacks-with-ebpf/" rel="bookmark"><time class="entry-date" datetime="2020-09-18T14:00:00+03:00">2020-09-18</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/jonas-otten/" rel="author">Jonas Otten</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Jonas Otten">Jonas Otten</a> original <a href="https://blog.cloudflare.com/building-rakelimit/">https://blog.cloudflare.com/building-rakelimit/</a></p>
<figure class="kg-card kg-image-card"><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/image3-9.png" class="kg-image" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></figure>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/raking-sandbox@2x.png" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></p>
<p>Cloudflare’s globally distributed network is not just designed to protect HTTP services but any kind of TCP or UDP traffic that passes through our edge. To this end, we’ve built a number of sophisticated DDoS mitigation systems, such as <a href="https://blog.cloudflare.com/meet-gatebot-a-bot-that-allows-us-to-sleep/">Gatebot</a>, which analyze world-wide traffic patterns. However, we’ve always employed defense-in-depth: in addition to global protection systems we also use off-the shelf mechanisms such as TCP <a href="https://blog.cloudflare.com/syn-packet-handling-in-the-wild/">SYN-cookies</a>, which protect individual servers locally from the very common SYN-flood. But there’s a catch: such a mechanism does not exist for UDP. UDP is a connectionless protocol and does not have similar context around packets, especially considering that Cloudflare powers services such as <a href="https://www.cloudflare.com/products/cloudflare-spectrum/">Spectrum</a> which are agnostic to the upper layer protocol (DNS, NTP, …), so my <a href="https://blog.cloudflare.com/cloudflare-doubling-size-of-2020-summer-intern-class/">2020 intern class</a> project was to come up with a different approach.</p>
<h3 id="protecting-udp-services">Protecting UDP services</h3>
<p>First of all, let&#8217;s discuss what it actually means to provide protection to UDP services. We want to ensure that an attacker cannot drown out legitimate traffic. To achieve this we want to identify floods and limit them while leaving legitimate traffic untouched.</p>
<p>The idea to mitigate such attacks is straight forward: first identify a group of packets that is related to an attack, and then apply a rate limit on this group. Such groups are determined based on the attributes available to us in the packet, such as addresses and ports.</p>
<p>We do not want to completely drop the flood of traffic, as legitimate traffic may still be part of it. We only want to drop as much traffic as necessary to comply with our set rate limit. Completely ignoring a set of packets just because it is slightly above the rate limit is not an option, as it may contain legitimate traffic.</p>
<p>This ensures both that our service stays responsive but also that legitimate packets experience as little impact as possible.</p>
<p>While rate limiting is a somewhat straightforward procedure, determining groups is a bit harder, for a number of reasons.</p>
<h3 id="finding-needles-in-the-haystack">Finding needles in the haystack</h3>
<p>The problem in determining groups in packets is that we have barely any context. We consider four things as useful attributes as attack signatures: the source address and port as well as the destination address and port. While that already is not a lot, it gets worse: the source address and port may not even be accurate. Packets can be spoofed, in which case an attacker hides their own address. That means only keeping a rate per source address may not provide much value, as it could simply be spoofed.</p>
<p>But there is another problem: keeping one rate per address does not scale. When bringing IPv6 into the equation and its <a href="https://www.ripe.net/about-us/press-centre/understanding-ip-addressing#:~:text=For%20IPv4%2C%20this%20pool%20is,basic%20unit%20for%20storing%20information.">whopping address space</a> it becomes clear it’s not going to work.</p>
<p>To solve these issues we turned to the academic world and found what we were looking for, the problem of <em>Heavy Hitters.</em> <em>Heavy Hitters </em>are elements of a datastream that appear frequently, and can be expressed relative to the overall elements of the stream. We can define for example that an element is considered to be a <em>Heavy Hitter</em> if its frequency exceeds, say, 10% of the overall count. To do so we naively could suggest to simply maintain a counter per element, but due to the space limitations this will not scale. Instead probabilistic algorithms such as a <a href="http://dimacs.rutgers.edu/~graham/pubs/papers/cm-full.pdf">CountMin sketch</a> or the <a href="https://www.cse.ust.hk/~raywong/comp5331/References/EfficientComputationOfFrequentAndTop-kElementsInDataStreams.pdf">SpaceSaving algorithm</a> can be used. These provide an estimated count instead of a precise one, but are capable of doing this with constant memory requirements, and in our case we will just save rates into the CountMin sketch instead of counts. So no matter how many unique elements we have to track, the memory consumption is the same.</p>
<p>We now have a way of finding the needle in the haystack, and it does have constant memory requirements, solving our problem. However, reality isn’t that simple. What if an attack is not just originating from a single port but many? Or what if a reflection attack is hitting our service, resulting in random source addresses but a single source port? Maybe a full /24 subnet is sending us a flood? We can not just keep a rate per combination we see, as it would ignore all these patterns.</p>
<h2 id="grouping-the-groups-how-to-organize-packets">Grouping the groups: How to organize packets</h2>
<p>Luckily the academic world has us covered again, with the concept of <em>Hierarchical Heavy Hitters.</em> It extends the <em>Heavy Hitter </em>concept by using the underlying hierarchy in the elements of the stream. For example, an IP address can be naturally grouped into several subnets:</p>
<figure class="kg-card kg-image-card"><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/image2-8.png" class="kg-image" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></figure>
<p>In this case we defined that we consider the fully-specified address, the /24 subnet and the /0 wildcard. We start at the left with the fully specified address, and each step walking towards the top we consider less information from it. We call these less-specific addresses generalisations, and measure how specific a generalisation is by assigning a level. In our example, the address 192.0.2.123 is at level 0, while 192.0.2.0/24 is at level 1, etc.</p>
<p>If we want to create a structure which can hold this information for every packet, it could look like this:</p>
<figure class="kg-card kg-image-card"><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/image5-6.png" class="kg-image" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></figure>
<p>We maintain a CountMin-sketch per subnet and then apply Heavy Hitters. When a new packet arrives and we need to determine if it is allowed to pass we simply check the rates of the corresponding elements in every node. If no rate exceeds the rate limit that we set, e.g. 25 packets per second (pps), it is allowed to pass.</p>
<p>The structure could now keep track of a single attribute, but we would waste a lot of context around packets! So instead of letting it go to waste, we use the two-dimensional approach for addresses proposed in the paper <a href="https://arxiv.org/abs/1102.5540">Hierarchical Heavy Hitters with SpaceSaving algorithm</a>, and extend it further to also incorporate ports into our structure. Ports do not have a natural hierarchy such as addresses, so they can only be in two states: either <em>specified</em> (e.g. 8080) or <em>wildcard</em>.</p>
<p>Now our structure looks like this:</p>
<figure class="kg-card kg-image-card"><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/image1-14.png" class="kg-image" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></figure>
<p>Now let’s talk about the algorithm we use to traverse the structure and determine if a packet should be allowed to pass. The paper <em>Hierarchical Heavy Hitters with SpaceSaving algorithm</em> provides two methods that can be used on the data structure: one that updates elements and increases their counters, and one that provides all elements that currently are <em>Heavy Hitters</em>. This is actually not necessary for our use-case, as we are only interested if the element, or packet, we are looking at right now would be a <em>Heavy Hitter</em> to decide if it can pass or not.</p>
<p>Secondly, our goal is to prevent any Heavy Hitters from passing, thus leaving the structure with no <em>Heavy Hitter</em>s whatsoever. This is a great property, as it allows us to simplify the algorithm substantially, and it looks like this:</p>
<figure class="kg-card kg-image-card"><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/09/image4-8.png" class="kg-image" alt="Raking the floods: How to protect UDP services from DoS attacks with eBPF"></figure>
<p>As you may notice, we update every node of a level and maintain the maximum rate we see. After each level we calculate a probability that determines if a packet should be passed to the next level, based on the maximum rate we saw on that level and a set rate limit. Each node essentially filters the traffic for the following, less specific level.</p>
<p>I actually left out a small detail: a packet is not dropped if any rate exceeds the limit, but instead is kept with the probability <em>rate limit</em>/<em>maximum rate seen</em>. The reason is that if we just drop all packets if the rates exceed the limit, we would drop the whole traffic, not just a subset to make it comply with our set rate limit.</p>
<p>Since we now still update more specific nodes even if a node reaches a rate limit, the rate limit will converge towards the underlying pattern of the attack as much as possible. That means other traffic will be impacted as minimally as possible, and that with no manual intervention whatsoever!</p>
<h3 id="bpf-to-the-rescue-building-a-go-library">BPF to the rescue: building a Go library</h3>
<p>As we want to use this algorithm to mitigate floods, we need to spend as little computation and overhead as possible before we decide if a packet should be dropped or not. As so often, we looked into the BPF toolbox and found what we need: <em>Socketfilters</em>. As our colleague Marek put it: <a href="https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/">“It seems, no matter the question &#8211; BPF is the answer.”</a>.</p>
<p><em>Socketfilters </em>are pieces of code that can be attached to a single socket and get executed before a packet will be passed from kernel to userspace. This is ideal for a number of reasons. First, when the kernel runs the socket filter code, it gives it all the information from the packet we need, and other mitigations such as firewalls have been executed. Second the code is executed <em>per socket</em>, so every application can activate it as needed, and also set appropriate rate limits. It may even use different rate limits for different sockets. The third reason is privileges: we do not need to be root to attach the code to a socket. We can execute code in the kernel as a normal user!</p>
<p>BPF also has a number of limitations which have been already covered on this blog in the past, so we will focus on one that’s specific to our project: floating-point numbers.</p>
<p>To calculate rates we need floating-point numbers to provide an accurate estimate. BPF, and the whole kernel for that matter, does not support these. Instead we implemented a fixed-point representation, which uses a part of the available bits for the fractional part of a rational number and the remaining bits for the integer part. This allows us to represent floats within a certain range, but there is a catch when doing arithmetic: while subtraction and addition of two fixed-points work well, multiplication and division requires double the number of bits to ensure there will not be any loss in precision. As we use 64 bits for our fixed-point values, there is no larger data type available to ensure this does not happen. Instead of calculating the result with exact precision, we convert one of the arguments into an integer. That results in the loss of the fractional part, but as we deal with large rates that does not pose any issue, and helps us to work around the bit limitation as intermediate results fit into the available 64 bits. Whenever fixed-point arithmetic is necessary the precision of intermediate results has to be carefully considered.</p>
<p>There are many more details to the implementation, but instead of covering every single detail in this blog post lets just look at the code.</p>
<p>We open sourced rakelimit over on Github at <a href="https://github.com/cloudflare/rakelimit">cloudflare/rakelimit</a>! It is a full-blown Go library that can be enabled on any UDP socket, and is easy to configure.</p>
<p>The development is still in early stages and this is a first prototype, but we are excited to continue and push the development with the community! And if you still can’t get enough, look at our talk from this year&#8217;s <a href="https://linuxplumbersconf.org/event/7/contributions/677/">Linux Plumbers Conference</a>.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/ebpf/" rel="tag">eBPF</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/udp/" rel="tag">udp</a></span></footer></article>
<article id="post-948091" class="post-948091 post type-post status-publish format-standard hentry tag-constructionism tag-education tag-mathematics tag-programming tag-research tag-research-seminar">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/06/12/mathematics-and-programming-exploring-the-links/" rel="bookmark">Mathematics and programming: exploring the links</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/06/12/mathematics-and-programming-exploring-the-links/" rel="bookmark"><time class="entry-date" datetime="2020-06-12T15:28:14+03:00">2020-06-12</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/sue-sentance/" rel="author">Sue Sentance</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Sue Sentance">Sue Sentance</a> original <a href="https://www.raspberrypi.org/blog/research-seminar-mathematics-programming-links/">https://www.raspberrypi.org/blog/research-seminar-mathematics-programming-links/</a></p>
<blockquote>
<p>“In my vision, the child programs the computer and, in doing so, both acquires a sense of mastery over a piece of the most modern and powerful technology and establishes an intimate contact with some of the deepest ideas from science, from mathematics, and from the art of intellectual model building.” – Seymour Papert, <em>Mindstorms: Children, Computers, And Powerful Ideas</em>, 1980</p>
</blockquote>
<p>We owe much of what we have learned about children learning to program to Seymour Papert (1928–2016), who not only was a great mathematician and computer scientist, but also an inspirational educationalist. He developed the theoretical approach to learning we now know as <em>constructionism</em>, which purports that learning takes place through building artefacts that have meaning and can be shared with others. Papert, together with others, developed the Logo programming language in 1967 to help children develop concepts in both mathematics and in programming. He believed that programming could give children tangible and concrete experiences to support their acquisition of mathematical concepts. Educational programming languages such as Logo were widely used in both primary and secondary education settings during the 1980s and 90s. Thus for many years the links between mathematics and programming have been evident, and we were very fortunate to be able to explore this topic with our research seminar guest speaker, Professor Dame Celia Hoyles of University College London.</p>
<div id="attachment_60213" style="width: 810px" class="wp-caption aligncenter"><img loading="lazy" aria-describedby="caption-attachment-60213" class="wp-image-60213 size-blog-entry" src="https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2-800x486.jpg" alt="Dame Celia Hoyles" width="800" height="486" srcset="https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2-800x486.jpg 800w, https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2-300x182.jpg 300w, https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2-500x304.jpg 500w, https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2-768x466.jpg 768w, https://www.raspberrypi.org/app/uploads/2020/06/celia-hoyles-2.jpg 1400w" sizes="(max-width: 800px) 100vw, 800px" /></p>
<p id="caption-attachment-60213" class="wp-caption-text">Professor Dame Celia Hoyles</p>
</div>
<p>Dame Celia Hoyles is a huge celebrity in the world of mathematical education and programming. As well as authoring literally hundreds of academic papers on mathematics education, including on Logo programming, she has received a number of prestigious awards and honours, and has served as the Chief Advisor to the UK government on mathematics in school. For all these reasons, we were delighted to hear her present at a Raspberry Pi Foundation computing education research seminar.</p>
<p>Mathematics is a subject we all need to understand the basics of — it underpins much of our other learning and empowers us in daily life. Yet some mathematical concepts can seem abstract and teachers have struggled over the years to help children to understand them. Since programming includes the design, building, and debugging of artefacts, it is a great approach for make such abstract concepts come to life. It also enables the development of both computational and mathematical thinking, as Celia described in her talk.</p>
<p><img loading="lazy" class="aligncenter wp-image-60214 size-blog-entry" src="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-800x393.png" alt="" width="800" height="393" srcset="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-800x393.png 800w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-300x147.png 300w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-500x245.png 500w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-768x377.png 768w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3-1536x754.png 1536w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-3.png 1909w" sizes="(max-width: 800px) 100vw, 800px" /></p>
<h2>Learning mathematics through Scratch programming</h2>
<p>Celia and a team* at University College London developed a curriculum initiative called ScratchMaths to teach carefully selected mathematical concepts through programming (funded by the Education Endowment Foundation in 2014–2018). ScratchMaths is for use in upper primary school (age 9–11) over a two-year period.</p>
<p><img loading="lazy" class="aligncenter wp-image-60216 size-blog-entry" src="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-800x354.png" alt="" width="800" height="354" srcset="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-800x354.png 800w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-300x133.png 300w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-500x221.png 500w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-768x340.png 768w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4-1536x680.png 1536w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-4.png 1912w" sizes="(max-width: 800px) 100vw, 800px" /></p>
<p>In the first year, pupils take three computational thinking modules, and in the second year, they move to three more mathematical thinking modules. All the ScratchMaths materials were designed around a pedagogical framework called the 5Es: explore, envisage, explain, exchange, and bridge. This enables teachers to understand the structure and sequencing of the materials as they use them in the classroom:</p>
<ul>
<li>Explore: Investigate, try things out yourself, debug in reaction to feedback</li>
<li>Envisage: Have a goal in mind, predict outcome of program before trying</li>
<li>Explain: Explain what you have done, articulate reasons behind your approach to others</li>
<li>Exchange: Collaborate &amp; share, try to see a problem from another’s perspective as well as defend your own approach and compare with others</li>
<li>bridgE: Make explicit links to the mathematics curriculum</li>
</ul>
<p>Teachers in the ScratchMaths project participated in professional development (two days per module) to enable them to understand the materials and the pedagogical approach.</p>
<p>At the end of the project, external evaluators measured the childrens’ learning and found a statistically significant increase in computational thinking skills after the first year, but no difference between an intervention group and a control group in the mathematical thinking outcomes in the second year (as measured by the national mathematics tests at that age).</p>
<p><img loading="lazy" class="aligncenter wp-image-60215 size-blog-entry" src="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-800x343.png" alt="" width="800" height="343" srcset="https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-800x343.png 800w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-300x129.png 300w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-500x214.png 500w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-768x329.png 768w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5-1536x659.png 1536w, https://www.raspberrypi.org/app/uploads/2020/06/screenshot-5.png 1910w" sizes="(max-width: 800px) 100vw, 800px" /></p>
<p>Celia discussed a number of reasons for these findings. She also drew out the positive perspective that children in the trial learned two subjects at the same time without any detriment to their learning of mathematics. Covering two subjects and drawing the links between them without detriment to the core learning is potentially a benefit to schools who need to fit many subjects into their teaching day.</p>
<p>Much more information about the programme and the materials, which are freely available for use, can be found on <a href="https://www.ucl.ac.uk/ioe/research/projects/scratchmaths" rel="noopener noreferrer">the ScratchMaths project’s website</a>, and you can also read <a href="https://link.springer.com/article/10.1007/s40751-017-0028-x" rel="noopener noreferrer">a research paper describing the project</a>.</p>
<p>As at all our research seminars, participants had many questions for our speaker. Although the project was designed for primary education, where it’s more common to learn subjects together across the curriculum, several questions revolved around the project’s suitability for secondary school. It’s interesting to reflect on how a programme like ScratchMaths might work at secondary level.</p>
<h2>Should computing be taught in conjunction or separately?</h2>
<p>Teaching programming through mathematics, or vice versa, is established practice in some countries. One example comes from Sweden, where <a href="https://www.skolverket.se/download/18.31c292d516e7445866a218f/1576654682907/pdf3984.pdf" rel="noopener noreferrer">computing and programming is taught across different subject areas</a>, including mathematics: “through teaching pupils should be given opportunities to develop knowledge in using digital tools and programming to explore problems and mathematical concepts, make calculations and to present and interpret data”. In England, conversely, we have a discrete computing curriculum, and an educational system that separates subjects out so that it is often difficult for children to see overlap and contiguity. However, having the focus on computing as a discrete subject gives enormous benefits too, as Celia outlined at the beginning of her talk, and it opens up the potential to give children an in-depth understanding of the whole subject area over their school careers. In an ideal world, perhaps we would teach programming in conjunction with a range of subjects, thus providing the concrete realisation of abstract concepts, while also having discrete computing and computer science in the curriculum.</p>
<p><img loading="lazy" class="aligncenter wp-image-54251 size-large" src="https://www.raspberrypi.org/app/uploads/2019/10/ISAAC_DISCO_IMAGES010719-597-500x295.jpg" alt="Woman teacher and female students at a computer" width="500" height="295" srcset="https://www.raspberrypi.org/app/uploads/2019/10/ISAAC_DISCO_IMAGES010719-597-500x295.jpg 500w, https://www.raspberrypi.org/app/uploads/2019/10/ISAAC_DISCO_IMAGES010719-597-300x177.jpg 300w, https://www.raspberrypi.org/app/uploads/2019/10/ISAAC_DISCO_IMAGES010719-597-768x452.jpg 768w, https://www.raspberrypi.org/app/uploads/2019/10/ISAAC_DISCO_IMAGES010719-597-1834x1080.jpg 1834w" sizes="(max-width: 500px) 100vw, 500px" /></p>
<p>In our current context of a global pandemic, we are continually seeing the importance of computing applications, for example computer modelling and simulation used in the analysis of data. This talk highlighted the importance of learning computing per se, as well as the mathematics one can learn through integrating these two subjects.</p>
<p>Celia is a member of the <a href="http://teachcomputing.org/" rel="noopener noreferrer">National Centre of Computing Education</a> (NCCE) Academic Board, made up of academics and experts who support the teaching and learning elements of the NCCE, and we enjoy our continued work with her in this capacity. Through the NCCE, the Raspberry Pi Foundation is reaching thousands of children and educators with free <a href="http://teachcomputing.org/resources" rel="noopener noreferrer">computing resources</a>, <a href="http://rpf.io/courses" rel="noopener noreferrer">online courses</a>, and <a href="https://isaaccomputerscience.org/" rel="noopener noreferrer">advanced-level computer science materials</a>. Our networks of <a href="http://codeclub.org/" rel="noopener noreferrer">Code Clubs</a> and <a href="http://coderdojo.org/" rel="noopener noreferrer">CoderDojos</a> also give children the space and freedom to experiment and play with programming and digital making in a way that is concordant with a constructionist approach.</p>
<h2>Next up in our seminar series</h2>
<p>If you missed the seminar, you can find Celia’s presentation slides and a recording of her talk on <a href="https://www.raspberrypi.org/computing-education-research-online-seminars/" rel="noopener noreferrer">our research seminars page</a>.</p>
<p>In our next seminar on Tuesday 16 June at 17:00–18:00 BST / 12:00–13:00 EDT / 9:00–10:00 PDT / 18:00–19:00 CEST, we’ll welcome Jane Waite, Teaching Fellow at Queen Mary University of London. Jane will be sharing insights about Semantic Waves and unplugged computing. To join the seminar, simply <a href="https://forms.gle/y2fzTffSCtNNM3767" rel="noopener noreferrer">sign up with your name and email address</a> and we’ll email you the link and instructions. If you attended Celia’s seminar, the link remains the same.</p>
<p>&nbsp;</p>
<p>*The ScratchMaths team are :</p>
<ul>
<li>Professor Dame Celia Hoyles (Mathematics) &amp; Professor Richard Noss (Mathematics) UCL Knowledge Lab</li>
<li>Professor Ivan Kalas, (Computing) Comenius University, Bratislava, Slovakia</li>
<li>Dr Laura Benton (Computing) &amp; Piers Saunders, (Mathematics) UCL Knowledge Lab</li>
<li>Professor Dave Pratt (Mathematics) UCL Institute of Education</li>
</ul>
<p>The post <a rel="nofollow" href="https://www.raspberrypi.org/blog/research-seminar-mathematics-programming-links/">Mathematics and programming: exploring the links</a> appeared first on <a rel="nofollow" href="https://www.raspberrypi.org/">Raspberry Pi</a>.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/constructionism/" rel="tag">constructionism</a><a href="https://noise.getoto.net/tag/education/" rel="tag">education</a><a href="https://noise.getoto.net/tag/mathematics/" rel="tag">mathematics</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/research/" rel="tag">research</a><a href="https://noise.getoto.net/tag/research-seminar/" rel="tag">research seminar</a></span></footer></article>
<article id="post-884658" class="post-884658 post type-post status-publish format-standard hentry tag-deep-dive tag-hardware tag-optimization tag-programming tag-tools">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/03/02/when-bloom-filters-dont-bloom/" rel="bookmark">When Bloom filters don&#8217;t bloom</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/03/02/when-bloom-filters-dont-bloom/" rel="bookmark"><time class="entry-date" datetime="2020-03-02T15:00:00+02:00">2020-03-02</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/marek-majkowski/" rel="author">Marek Majkowski</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Marek Majkowski">Marek Majkowski</a> original <a href="https://blog.cloudflare.com/when-bloom-filters-dont-bloom/">https://blog.cloudflare.com/when-bloom-filters-dont-bloom/</a></p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/02/bloom-filter@2x-1.png" alt="When Bloom filters don't bloom"></p>
<p></p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/02/bloom-filter@2x.png" alt="When Bloom filters don't bloom"></p>
<p></p>
<p>I&#8217;ve known about <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> (named after Burton Bloom) since university, but I haven&#8217;t had an opportunity to use them in anger. Last month this changed &#8211; I became fascinated with the promise of this data structure, but I quickly realized it had some drawbacks. This blog post is the tale of my brief love affair with Bloom filters.</p>
<p>While doing research about <a href="https://blog.cloudflare.com/the-root-cause-of-large-ddos-ip-spoofing/">IP spoofing</a>, I needed to examine whether the source IP addresses extracted from packets reaching our servers were legitimate, depending on the geographical location of our data centers. For example, source IPs belonging to a legitimate Italian ISP should not arrive in a Brazilian datacenter. This problem might sound simple, but in the ever-evolving landscape of the internet this is far from easy. Suffice it to say I ended up with many large text files with data like this:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Screenshot-from-2020-03-01-23-57-10.png" alt="When Bloom filters don't bloom"></p>
<p>This reads as: the IP 192.0.2.1 was recorded reaching Cloudflare data center number 107 with a legitimate request. This data came from many sources, including our active and passive probes, logs of certain domains we own (like cloudflare.com), public sources (like BGP table), etc. The same line would usually be repeated across multiple files.</p>
<p>I ended up with a gigantic collection of data of this kind. At some point I counted 1 billion lines across all the harvested sources. I usually write bash scripts to pre-process the inputs, but at this scale this approach wasn&#8217;t working. For example, removing duplicates from this tiny file of a meager 600MiB and 40M lines, took&#8230; about an eternity:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Screenshot-from-2020-03-01-23-25-19a.png" alt="When Bloom filters don't bloom"></p>
<p>Enough to say that deduplicating lines using the usual bash commands like &#8216;sort&#8217; in various configurations (see &#8216;&#8211;parallel&#8217;, &#8216;&#8211;buffer-size&#8217; and &#8216;&#8211;unique&#8217;) was not optimal for such a large data set.</p>
<p></p>
<h2 id="bloomfilterstotherescue">Bloom filters to the rescue</h2>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Bloom_filter.png" alt="When Bloom filters don't bloom"></p>
<p><center><small><a href="https://en.wikipedia.org/wiki/Bloom_filter#/media/File:Bloom_filter.svg">Image</a> by <a href="https://commons.wikimedia.org/wiki/User:David_Eppstein">David Eppstein</a> Public Domain</small></center></p>
<p>Then I had a brainwave &#8211; it&#8217;s not necessary to sort the lines! I just need to remove duplicated lines &#8211; using some kind of &quot;set&quot; data structure should be much faster. Furthermore, I roughly know the cardinality of the input file (number of unique lines), and I can live with some data points being lost &#8211; using a probabilistic data structure is fine!</p>
<p>Bloom-filters are a perfect fit!</p>
<p>While you should go and read <a href="https://en.wikipedia.org/wiki/Bloom_filter#Algorithm_description">Wikipedia on Bloom Filters</a>, here is how I look at this data structure.</p>
<p>How would you implement a &quot;<a href="https://en.wikipedia.org/wiki/Set_(abstract_data_type)">set</a>&quot;? Given a perfect hash function, and infinite memory, we could just create an infinite bit array and set a bit number &#8216;hash(item)&#8217; for each item we encounter. This would give us a perfect &quot;set&quot; data structure. Right? Trivial. Sadly, hash functions have collisions and infinite memory doesn&#8217;t exist, so we have to compromise in our reality. But we can calculate and manage the probability of collisions. For example, imagine we have a good hash function, and 128GiB of memory. We can calculate the probability of the second item added to the bit array colliding would be 1 in 1099511627776. The probability of collision when adding more items worsens as we fill up the bit array.</p>
<p>Furthermore, we could use more than one hash function, and end up with a denser bit array. This is exactly what Bloom filters optimize for. A Bloom filter is a bunch of math on top of the four variables:</p>
<ul>
<li>&#8216;n&#8217; &#8211; The number of input elements (cardinality)</li>
<li>&#8216;m&#8217; &#8211; Memory used by the bit-array</li>
<li>&#8216;k&#8217; &#8211; Number of hash functions counted for each input</li>
<li>&#8216;p&#8217; &#8211; Probability of a false positive match</li>
</ul>
<p>Given the &#8216;n&#8217; input cardinality and the &#8216;p&#8217; desired probability of false positive, the Bloom filter math returns the &#8216;m&#8217; memory required and &#8216;k&#8217; number of hash functions needed.</p>
<p>Check out this excellent visualization by Thomas Hurst showing how parameters influence each other:</p>
<ul>
<li><a href="https://hur.st/bloomfilter/">https://hur.st/bloomfilter/</a></li>
</ul>
<p></p>
<h2 id="mmuniqbloom">mmuniq-bloom</h2>
<p>Guided by this intuition, I set out on a journey to add a new tool to my toolbox &#8211; &#8216;mmuniq-bloom&#8217;, a probabilistic tool that, given input on STDIN, returns only unique lines on STDOUT, hopefully much faster than &#8216;sort&#8217; + &#8216;uniq&#8217; combo!</p>
<p>Here it is:</p>
<ul>
<li><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2020-02-mmuniq/mmuniq-bloom.c">&#8216;mmuniq-bloom.c&#8217;</a></li>
</ul>
<p>For simplicity and speed I designed &#8216;mmuniq-bloom&#8217; with a couple of assumptions. First, unless otherwise instructed, it uses 8 hash functions k=8. This seems to be a close to optimal number for the data sizes I&#8217;m working with, and the hash function can quickly output 8 decent hashes. Then we align &#8216;m&#8217;, number of bits in the bit array, to be a power of two. This is to avoid the pricey % modulo operation, which compiles down to slow assembly &#8216;div&#8217;. With power-of-two sizes we can just do bitwise AND. (For a fun read, see <a href="https://stackoverflow.com/questions/41183935/why-does-gcc-use-multiplication-by-a-strange-number-in-implementing-integer-divi">how compilers can optimize some divisions by using multiplication by a magic constant</a>.)</p>
<p>We can now run it against the same data file we used before:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image11.png" alt="When Bloom filters don't bloom"></p>
<p>Oh, this is so much better! 12 seconds is much more manageable than 2 minutes before. But hold on&#8230; The program is using an optimized data structure, relatively limited memory footprint, optimized line-parsing and good output buffering&#8230; 12 seconds is still eternity compared to &#8216;wc -l&#8217; tool:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image5.png" alt="When Bloom filters don't bloom"></p>
<p>What is going on? I understand that counting lines by &#8216;wc&#8217; is <em>easier</em> than figuring out unique lines, but is it really worth the 26x difference? Where does all the CPU in &#8216;mmuniq-bloom&#8217; go?</p>
<p>It must be my hash function. &#8216;wc&#8217; doesn&#8217;t need to spend all this CPU performing all this strange math for each of the 40M lines on input. I&#8217;m using a pretty non-trivial &#8216;siphash24&#8217; hash function, so it surely burns the CPU, right? Let&#8217;s check by running the code computing hash function but <em>not</em> doing any Bloom filter operations:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image2.png" alt="When Bloom filters don't bloom"></p>
<p>This is strange. Counting the hash function indeed costs about 2s, but the program took 12s in the previous run. The Bloom filter alone takes 10 seconds? How is that possible? It&#8217;s such a simple data structure&#8230;</p>
<p></p>
<h2 id="asecretweaponaprofiler">A secret weapon &#8211; a profiler</h2>
<p>It was time to use a proper tool for the task &#8211; let&#8217;s fire up a profiler and see where the CPU goes. First, let&#8217;s fire an &#8216;strace&#8217; to confirm we are not running any unexpected syscalls:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image14.png" alt="When Bloom filters don't bloom"></p>
<p>Everything looks good. The 10 calls to &#8216;mmap&#8217; each taking 4ms (3971 us) is intriguing, but it&#8217;s fine. We pre-populate memory up front with &#8216;MAP_POPULATE&#8217; to save on page faults later.</p>
<p>What is the next step? Of course Linux&#8217;s &#8216;perf&#8217;!</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image10.png" alt="When Bloom filters don't bloom"></p>
<p>Then we can see the results:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image6.png" alt="When Bloom filters don't bloom"></p>
<p>Right, so we indeed burn 87.2% of cycles in our hot code. Let&#8217;s see where exactly. Doing &#8216;perf annotate process_line &#8211;source&#8217; quickly shows something I didn&#8217;t expect.</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image3.png" alt="When Bloom filters don't bloom"></p>
<p>You can see 26.90% of CPU burned in the &#8216;mov&#8217;, but that&#8217;s not all of it! The compiler correctly inlined the function, and unrolled the loop 8-fold. Summed up that &#8216;mov&#8217; or &#8216;uint64_t v = *p&#8217; line adds up to a great majority of cycles!</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image4.png" alt="When Bloom filters don't bloom"></p>
<p>Clearly &#8216;perf&#8217; must be mistaken, how can such a simple line cost so much? We can repeat the benchmark with any other profiler and it will show us the same problem. For example, I like using &#8216;google-perftools&#8217; with kcachegrind since they emit eye-candy charts:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Screenshot-from-2020-03-02-00-08-23.png" alt="When Bloom filters don't bloom"></p>
<p>The rendered result looks like this:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image13.png" alt="When Bloom filters don't bloom"></p>
<p>Allow me to summarise what we found so far.</p>
<p>The generic &#8216;wc&#8217; tool takes 0.45s CPU time to process 600MiB file. Our optimized &#8216;mmuniq-bloom&#8217; tool takes 12 seconds. CPU is burned on one &#8216;mov&#8217; instruction, dereferencing memory&#8230;.</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/6784957048_4661ea7dfc_c.jpg" alt="When Bloom filters don't bloom"></p>
<p><center><small><a href="https://flickr.com/photos/jonicdao/6784957048">Image</a> by <a href="https://flickr.com/photos/jonicdao/">Jose Nicdao</a> CC BY/2.0</small></center></p>
<p>Oh! I how could I have forgotten. Random memory access <em>is</em> slow! It&#8217;s very, very, very slow!</p>
<p>According to the rule of thumb <a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html">&quot;latency numbers every programmer should know about&quot;</a>, one RAM fetch is about 100ns. Let&#8217;s do the math: 40 million lines, 8 hashes counted for each line. Since our Bloom filter is 128MiB, on <a href="https://blog.cloudflare.com/gen-x-performance-tuning/">our older hardware</a> it doesn&#8217;t fit into L3 cache! The hashes are uniformly distributed across the large memory range &#8211; each hash generates a memory miss. Adding it together that&#8217;s&#8230;</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Screenshot-from-2020-03-02-00-34-29.png" alt="When Bloom filters don't bloom"></p>
<p>That suggests 32 seconds burned just on memory fetches. The real program is faster, taking only 12s. This is because, although the Bloom filter data does not completely fit into L3 cache, it still gets some benefit from caching. It&#8217;s easy to see with &#8216;perf stat -d&#8217;:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image9.png" alt="When Bloom filters don't bloom"></p>
<p>Right, so we should have had at least 320M LLC-load-misses, but we had only 280M. This still doesn&#8217;t explain why the program was running only 12 seconds. But it doesn&#8217;t really matter. What matters is that the number of cache misses is a real problem and we can only fix it by reducing the number of memory accesses. Let&#8217;s try tuning Bloom filter to use only one hash function:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image12.png" alt="When Bloom filters don't bloom"></p>
<p>Ouch! That really hurt! The Bloom filter required 64 GiB of memory to get our desired false positive probability ratio of 1-error-per-10k-lines. This is terrible!</p>
<p>Also, it doesn&#8217;t seem like we improved much. It took the OS 22 seconds to prepare memory for us, but we still burned 11 seconds in userspace. I guess this time any benefits from hitting memory less often were offset by lower cache-hit probability due to drastically increased memory size. In previous runs we required only 128MiB for the Bloom filter!</p>
<p></p>
<h2 id="dumpingbloomfiltersaltogether">Dumping Bloom filters altogether</h2>
<p>This is getting ridiculous. To get the same false positive guarantees we either must use many hashes in Bloom filter (like 8) and therefore many memory operations, or we can have 1 hash function, but enormous memory requirements.</p>
<p>We aren&#8217;t really constrained by available memory, instead we want to optimize for reduced memory accesses. All we need is a data structure that requires at most 1 memory miss per item, and use less than 64 Gigs of RAM&#8230;</p>
<p>While we could think of more sophisticated data structures like <a href="https://en.wikipedia.org/wiki/Cuckoo_filter">Cuckoo filter</a>, maybe we can be simpler. How about a good old simple hash table with linear probing?</p>
<p></p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/linear-probing.png" alt="When Bloom filters don't bloom"><br />
<small><a href="https://www.sysadmins.lv/blog-en/array-search-hash-tables-behind-the-scenes.aspx">Image</a> by <a href="https://www.sysadmins.lv/about.aspx">Vadims Podāns</a></small></p>
<h2 id="welcomemmuniqhash">Welcome mmuniq-hash</h2>
<p>Here you can find a tweaked version of mmuniq-bloom, but using hash table:</p>
<ul>
<li><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2020-02-mmuniq/mmuniq-hash.c">&#8216;mmuniq-hash.c&#8217;</a></li>
</ul>
<p>Instead of storing bits as for the Bloom-filter, we are now storing 64-bit hashes from the <a href="https://idea.popcount.org/2013-01-24-siphash/">&#8216;siphash24&#8217; function</a>. This gives us much stronger probability guarantees, with probability of false positives much better than one error in 10k lines.</p>
<p>Let&#8217;s do the math. Adding a new item to a hash table containing, say 40M, entries has &#8217;40M/2^64&#8242; chances of hitting a hash collision. This is about one in 461 billion &#8211; a reasonably low probability. But we are not adding one item to a pre-filled set! Instead we are adding 40M lines to the initially empty set. As per <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> this has much higher chances of hitting a collision at some point. A decent approximation is &#8216;~n^2/2m&#8217;, which in our case is &#8216;~(40M^2)/(2*(2^64))&#8217;. This is a chance of one in 23000. In other words, assuming we are using good hash function, every one in 23 thousand random sets of 40M items, will have a hash collision. This practical chance of hitting a collision is non-negligible, but it&#8217;s still better than a Bloom filter and totally acceptable for my use case.</p>
<p>The hash table code runs faster, has better memory access patterns and better false positive probability than the Bloom filter approach.</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/image7.png" alt="When Bloom filters don't bloom"></p>
<p>Don&#8217;t be scared about the &quot;hash conflicts&quot; line, it just indicates how full the hash table was. We are using linear probing, so when a bucket is already used, we just pick up the next empty bucket. In our case we had to skip over 0.7 buckets on average to find an empty slot in the table. This is fine and, since we iterate over the buckets in linear order, we can expect the memory to be nicely prefetched.</p>
<p>From the previous exercise we know our hash function takes about 2 seconds of this. Therefore, it&#8217;s fair to say 40M memory hits take around 4 seconds.</p>
<p></p>
<h2 id="lessonslearned">Lessons learned</h2>
<p>Modern CPUs are really good at sequential memory access when it&#8217;s possible to predict memory fetch patterns (see <a href="https://en.wikipedia.org/wiki/Cache_prefetching#Methods_of_hardware_prefetching">Cache prefetching</a>). Random memory access on the other hand is very costly.</p>
<p>Advanced data structures are very interesting, but beware. Modern computers require cache-optimized algorithms. When working with large datasets, not fitting L3, prefer optimizing for reduced number loads, over optimizing the amount of memory used.</p>
<p>I guess it&#8217;s fair to say that Bloom filters are great, as long as they fit into the L3 cache. The moment this assumption is broken, they are terrible. This is not news, Bloom filters optimize for memory usage, not for memory access. For example, see <a href="https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf">the Cuckoo Filters paper</a>.</p>
<p>Another thing is the ever-lasting discussion about hash functions. Frankly &#8211; in most cases it doesn&#8217;t matter. The cost of counting even complex hash functions like &#8216;siphash24&#8217; is small compared to the cost of random memory access. In our case simplifying the hash function will bring only small benefits. The CPU time is simply spent somewhere else &#8211; waiting for memory!</p>
<p>One colleague often says: &quot;You can assume modern CPUs are infinitely fast. They run at infinite speed until they <a href="http://www.di-srv.unisa.it/~vitsca/SC-2011/DesignPrinciplesMulticoreProcessors/Wulf1995.pdf">hit the memory wall</a>&quot;.</p>
<p>Finally, don&#8217;t follow my mistakes &#8211; everyone should start profiling with &#8216;perf stat -d&#8217; and look at the &quot;Instructions per cycle&quot; (IPC) counter. If it&#8217;s below 1, it generally means the program is stuck on waiting for memory. Values above 2 would be great, it would mean the workload is mostly CPU-bound. Sadly, I&#8217;m yet to see high values in the workloads I&#8217;m dealing with&#8230;</p>
<p></p>
<h2 id="improvedmmuniq">Improved mmuniq</h2>
<p>With the help of my colleagues I&#8217;ve prepared a further improved version of the &#8216;mmuniq&#8217; hash table based tool. See the code:</p>
<ul>
<li><a href="https://github.com/cloudflare/cloudflare-blog/blob/master/2020-02-mmuniq/mmuniq.c">&#8216;mmuniq.c&#8217;</a></li>
</ul>
<p>It is able to dynamically resize the hash table, to support inputs of unknown cardinality. Then, by using batching, it can effectively use the &#8216;prefetch&#8217; CPU hint, speeding up the program by 35-40%. Beware, sprinkling the code with &#8216;prefetch&#8217; rarely works. Instead, I specifically changed the flow of algorithms to take advantage of this instruction. With all the improvements I got the run time down to 2.1 seconds:</p>
<p><img src="https://blog-cloudflare-com-assets.storage.googleapis.com/2020/03/Screenshot-from-2020-03-01-23-52-18.png" alt="When Bloom filters don't bloom"></p>
<p></p>
<h2 id="theend">The end</h2>
<p>Writing this basic tool which tries to be faster than &#8216;sort | uniq&#8217; combo revealed some hidden gems of modern computing. With a bit of work we were able to speed it up from more than two minutes to 2 seconds. During this journey we learned about random memory access latency, and the power of cache friendly data structures. Fancy data structures are exciting, but in practice reducing random memory loads often brings better results.</p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/deep-dive/" rel="tag">deep dive</a><a href="https://noise.getoto.net/tag/hardware/" rel="tag">hardware</a><a href="https://noise.getoto.net/tag/optimization/" rel="tag">Optimization</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/tools/" rel="tag">Tools</a></span></footer></article>
<article id="post-876336" class="post-876336 post type-post status-publish format-standard hentry tag-developer-tips tag-opinions tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2020/02/20/where-is-this-coming-from/" rel="bookmark">Where Is This Coming From?</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2020/02/20/where-is-this-coming-from/" rel="bookmark"><time class="entry-date" datetime="2020-02-20T10:55:24+02:00">2020-02-20</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/bozho/" rel="author">Bozho</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Bozho">Bozho</a> original <a href="https://techblog.bozho.net/where-is-this-coming-from/">https://techblog.bozho.net/where-is-this-coming-from/</a></p>
<p>In enterprise software the top one question you have to answer as a developer almost every day is &#8220;Where is this coming from?&#8221;. When trying to fix bugs, when developing new features, when refactoring. You have to be able to trace the code flow and to figure out where a certain value is coming from.</p>
<p>And the bigger the codebase is, the more complicated it is to figure out where something (some value or combination of values) is coming from. In theory it&#8217;s either from the user interface or from the database, but we all know it&#8217;s always more complicated. I learned that very early in my career when I had to navigate a huge telecom codebase in order to implement features and fix bugs that were in total a few dozens line of code.</p>
<p>Answering the question means navigating the code easily, debugging and tracing changes to the values passed around. And while that seems obvious, it isn&#8217;t so obvious in the grand scheme of things.</p>
<p>Frameworks, architectures, languages, coding styles and IDEs that obscure the answer to the question &#8220;where is this coming from?&#8221; make things much worse &#8211; for the individual developer and for the project in general. Let me give a few examples.</p>
<p><strong>Scala</strong>, for which <a href="https://techblog.bozho.net/scala-the-good-the-bad-and-the-very-ugly-presentation/">I have mixed feelings</a>, gives you a lot of cool features. And some awful ones, like implicits. An implicit is something like a global variable, except there are nested implicit scopes. When you need some of those global variables, so just add the &#8220;implicit&#8221; keyword and you get the value from the inner-most scope available that matches the type of the parameter you want to set. And in larger projects it&#8217;s not trivial to chase where has that implicit value been set. It can take hours of debugging to figure out why something has a particular value, only to figure out some unrelated part of the code has touched the relevant implicits. That makes it really hard to trace where stuff is coming from and therefore is bad for enterprise codebases, at least for me. </p>
<p>Another Scala feature is partially applied functions. You have a function <code>foo(a, b, c)</code> (that&#8217;s not the correct syntax, of course). You have one parameter known at some point, and the other two parameters known at a later point. So you can call the function partially and pass the resulting partially applied function to the next function, and so on until you have the other arguments available. So you can do <code>bar(foo(a))</code> which means that in <code>bar(..)</code> you can call <code>foo(b, c)</code>. Of course, at that point, answering the question &#8220;where did the value of a come from&#8221; is harder to answer. The feature is really cool if used properly (I&#8217;ve used it, and was proud about it), but it should be limited to smaller parts of the codebase. If you start tossing partially applied functions all over the place, it becomes a mess. And unfortunately, I&#8217;ve seen that as well.</p>
<p>Enough about Scala, the <strong>microservices architecture</strong> (which I also have mixed feeling about) also complicates the ability of a developer to trace what&#8217;s happening. If for a given request you invoke 3-4 external systems, which both return data and manipulate data, it becomes much harder to debug your application. Instead of putting a breakpoint or doing a call hierarchy, you have to track the parameters of each interaction with each microservice. It&#8217;s news to nobody that microservices are harder to debug but I just wanted to put that in the context of answering the &#8220;where is this coming from&#8221; question.</p>
<p><strong>Dynamic typing</strong> is another example. I&#8217;ve included that as part of my arguments <a href="https://techblog.bozho.net/static-typing-is-not-for-type-checking/">why I prefer static typing</a>. Java IDEs have &#8220;Call hierarchy&#8221;. Which is the single most useful IDE functionality for large enterprise software (for me even more important than the refactoring functionality). You really can trace every bit of possible code flow, not only in your codebase, but also in your dependencies, which often hide the important details (chances are, you&#8217;ll be putting breakpoints and inspecting 3rd party code rather often). Dynamic typing doesn&#8217;t give you the ability to do that properly. <code>doSomething</code> called on an unknown-at-compile-time type can be any method with that name. And tracing where stuff is coming from becomes much harder.</p>
<p><strong>Code generation</strong> is something that I&#8217;ve always avoided. It takes input from text files (in whatever language they are) and generates code, turning the question &#8220;where is this coming from&#8221; to &#8220;why has this been generated that way&#8221;.</p>
<p><strong>Message queues</strong> and <strong>async programming</strong> in general &#8211; message passing obscures the source and destination of a given piece of data; a message queue adds complexity to the communication between modules. With microservices you at least have API calls, with queues, you have multiple abstractions between the sender and recipient (exchanges, topics, queues). And that&#8217;s a general drawback of asynchrounous programming &#8211; that there&#8217;s something in between the program flow that does &#8220;async magic&#8221; and spits something on the other end &#8211; but is it transformed, is it delayed, is it lost and retried, is it still waiting? </p>
<p>By all these examples I&#8217;m not saying you should not use message queues, code generation, dynamic languages, microservices or Scala (though for some I&#8217;d really advice against). All of these things have their strengths, and they have been chosen exactly for those strengths. A message queue was probably chosen because you want to really decouple producer and consumer. Scala was chosen for its expressiveness. Microservices were chosen because a monolith had become really hard to manage with multiple teams and multiple languages. </p>
<p>But we should try to minimize the &#8220;damage&#8221; of not being able to easily trace the program flow and not being able to quickly answer &#8220;where is this coming from&#8221;. Impose a &#8220;no-implicits&#8221; rule on your scala code base. Use code-generation for simpler components (e.g. DTOs for protobuf). Use message queues with predictable message/queue/topic/exchange names and some slightly verbose debug logging. Make sure your microservices have corresponding SDKs with consistent naming and that they can be run locally without additional effort to ease debugging.</p>
<p>It is expected that the bigger and more complex a project is, the harder it will be to trace where stuff is going. But do try to make it as easy as possible, even if it costs a little extra effort in the design and coding phase. You&#8217;ll be designing and writing that feature for a week. And you (and others) will be supporting and expanding it for the next 10 years.</p>
<p>The post <a rel="nofollow" href="https://techblog.bozho.net/where-is-this-coming-from/">Where Is This Coming From?</a> appeared first on <a rel="nofollow" href="https://techblog.bozho.net/">Bozho&#039;s tech blog</a>.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/developer-tips/" rel="tag">Developer tips</a><a href="https://noise.getoto.net/tag/opinions/" rel="tag">Opinions</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-725738" class="post-725738 post type-post status-publish format-standard hentry tag-best-practices tag-developer-tips tag-opinions tag-programming">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/07/27/lets-annotate-our-methods-with-the-features-they-implement/" rel="bookmark">Let’s Annotate Our Methods With The Features They Implement</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/07/27/lets-annotate-our-methods-with-the-features-they-implement/" rel="bookmark"><time class="entry-date" datetime="2019-07-27T23:40:17+03:00">2019-07-27</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/bozho/" rel="author">Bozho</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Bozho">Bozho</a> original <a href="https://techblog.bozho.net/lets-annotate-our-methods-with-the-features-they-implement/">https://techblog.bozho.net/lets-annotate-our-methods-with-the-features-they-implement/</a></p>
<p>Writing software consists of very little actual &#8220;writing&#8221;, and much more thinking, designing, reading, &#8220;digging&#8221;, analyzing, debugging, refactoring, aligning and meeting others.</p>
<p>The reading and digging part is where you try to understand what has been implemented before, why it has been implemented, and how it works. In larger projects it becomes increasingly hard to find what is happening and why &#8211; there are so many classes that interfere, and so many methods participate in implementing a particular feature.</p>
<p>That&#8217;s probably because there is a mismatch between the programming units (classes, methods) and the business logic units (features). Product owners want a &#8220;password reset&#8221; feature, and they don&#8217;t care if it&#8217;s done using framework configuration, custom code split in three classes, or one monolithic controller method that does that job.</p>
<p>This mismatch is partially addressed by the so called BDD (behaviour driven development), as business people can define scenarios in a formalized language (although they rarely do, it&#8217;s still up to the QAs or developers to write the tests). But having your tests organized around features and behaviours doesn&#8217;t mean the code is, and BDD doesn&#8217;t help in making your way through the codebase in search of why and how something is implemented.</p>
<p>Another issue is linking a piece of code to the issue tracking system. Source control conventions and hooks allow for setting the issue tracker number as part of the commit, and then when browsing the code, you can annotate the file and see the issue number. However, due the the many changes, even a very strict team will end up methods that are related to multiple issues and you can&#8217;t easily tell which is the proper one.</p>
<p>Yet another issue with the lack of a &#8220;feature&#8221; unit in programming languages is that you can&#8217;t trivially reuse existing projects to start a new one. We&#8217;ve all been there &#8211; you have a similar project and you want to get a skeleton to get thing running faster. And while there are many tools to help that (Spring Boot, Spring Roo, and other scaffolding utilities), they can rarely deliver what you need &#8211; you always have to tweak something, delete something, customize some configuration, as defaults are almost never practical. </p>
<p>And I have a simple proposal that will help with the issues above. As with any complex problem, simple ideas don&#8217;t solve everything, but are at least a step forward. </p>
<p>The proposal is in the title &#8211; let&#8217;s annotate our methods with the features they implement. Let&#8217;s have <code>@Feature(name = "Forgotten password", issueTrackerCode="PROJ-123")</code>. A method can implement multiple features, but that is generally discouraged by best practices (e.g. the single responsibility principle). The granularity of &#8220;feature&#8221; is something that has to be determined by each team and is the tricky part &#8211; sometimes an epic describes a feature, sometimes individual stories or even subtasks do. A definition of a feature should be agreed upon and every new team member should be told what to do and how to interpret it.</p>
<p>There is of course a lot of complexity, e.g. for generic methods like DAO methods, utility methods, or methods that are reused in too many places. But they also represent features, it&#8217;s just that these features are horizontal. &#8220;Data access layer&#8221; is a feature &#8211; a more technical one indeed, but it counts, and maybe deserves a story in the issue tracker. </p>
<p>Your features can actually be listed in one or several enums, grouped by type &#8211; business, horizontal, performance, etc. That way you can even compose features &#8211; e.g. account creation contains the logic itself, database access, a security layer.</p>
<p>How does such a proposal help?</p>
<ul>
<li>Consciousnesses about the single responsibility of methods and that code should be readable</li>
<li>Provides a rationale for the existence of each method. <a href="https://techblog.bozho.net/my-most-frequent-code-review-comment/">Even if a proper comment is missing</a>, the annotation will put a method (or a class) in context</li>
<li>Helps navigating code and fixing issues (if you can see all places where a feature is implemented, you are more likely to spot an issue)</li>
<li>Allows tools to analyze your features &#8211; amount, complexity, how chaotic a feature is spread across the code base, test coverage per feature, etc.</li>
<li>Allows tools to use existing projects for scaffolding for new ones &#8211; you specify the features you want to have, and they are automatically copied</li>
</ul>
<p>At this point I&#8217;m supposed to give a link to a GitHub project for a feature annotation library. But it doesn&#8217;t make sense to have a single-annotation project. It can easily be part of guava or something similar Or can be manually created in each project. The complex part &#8211; the tools that will do the scanning and analysis, deserve separate projects, but unfortunately I don&#8217;t have time to write one.</p>
<p>But even without the tools, the concept of annotating methods with their high-level features is I think a useful one. Instead of trying to deduce why is this method here and what requirements does it have to implement (and were all necessary tests written at the time), such an annotation can come handy. </p>
<p>The post <a rel="nofollow" href="https://techblog.bozho.net/lets-annotate-our-methods-with-the-features-they-implement/">Let&#8217;s Annotate Our Methods With The Features They Implement</a> appeared first on <a rel="nofollow" href="https://techblog.bozho.net/">Bozho&#039;s tech blog</a>.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/best-practices/" rel="tag">Best practices</a><a href="https://noise.getoto.net/tag/developer-tips/" rel="tag">Developer tips</a><a href="https://noise.getoto.net/tag/opinions/" rel="tag">Opinions</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a></span></footer></article>
<article id="post-711431" class="post-711431 post type-post status-publish format-standard hentry tag-caching tag-open-source tag-programming tag-software-engineering tag-software-architecture">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/07/12/re-architecting-the-video-gatekeeper/" rel="bookmark">Re-Architecting the Video Gatekeeper</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/07/12/re-architecting-the-video-gatekeeper/" rel="bookmark"><time class="entry-date" datetime="2019-07-12T16:01:01+03:00">2019-07-12</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/netflix-technology-blog/" rel="author">Netflix Technology Blog</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Netflix Technology Blog">Netflix Technology Blog</a> original <a href="https://medium.com/netflix-techblog/re-architecting-the-video-gatekeeper-f7b0ac2f6b00?source=rss----2615bd06b42e---4">https://medium.com/netflix-techblog/re-architecting-the-video-gatekeeper-f7b0ac2f6b00?source=rss----2615bd06b42e---4</a></p>
<h4>By Drew Koszewnik</h4>
<p>This is the story about how the Content Setup Engineering team used Hollow, a Netflix OSS technology, to re-architect and simplify an essential component in our content pipeline — delivering a large amount of business value in the process.</p>
<h4>The Context</h4>
<p>Each movie and show on the Netflix service is carefully curated to ensure an optimal viewing experience. The team responsible for this curation is <em>Title Operations</em>. Title Operations will confirm, among other things:</p>
<ul>
<li>We are in compliance with the contracts — date ranges and places where we can show a video are set up correctly for each title</li>
<li>Video with captions, subtitles, and secondary audio “dub” assets are sourced, translated, and made available to the right populations around the world</li>
<li>Title name and synopsis are available and translated</li>
<li>The appropriate maturity ratings are available for each country</li>
</ul>
<p>When a title meets all of the minimum above requirements, then it is allowed to go live on the service. <em>Gatekeeper</em> is the system at Netflix responsible for evaluating the “liveness” of videos and assets on the site. A title doesn’t become visible to members until Gatekeeper approves it — and if it can’t validate the setup, then it will assist Title Operations by pointing out what’s missing from the baseline customer experience.</p>
<p>Gatekeeper accomplishes its prescribed task by aggregating data from multiple upstream systems, applying some business logic, then producing an output detailing the status of each video in each country.</p>
<h4>The Tech</h4>
<p><a href="http://hollow.how/">Hollow</a>, an <a href="https://github.com/Netflix/hollow">OSS</a> technology we <a href="https://medium.com/netflix-techblog/netflixoss-announcing-hollow-5f710eefca4b">released</a> a few years ago, has been best described as a <em>total high-density near cache</em>:</p>
<ul>
<li><strong>Total</strong>: The entire dataset is cached on each node — there is no eviction policy, and there are no cache misses.</li>
<li><strong>High-Density</strong>: encoding, bit-packing, and deduplication techniques are employed to optimize the memory footprint of the dataset.</li>
<li><strong>Near</strong>: the cache exists in RAM on any instance which requires access to the dataset.</li>
</ul>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/478/0*KaxWTFTt3V41iXSF" /></figure>
<p>One exciting thing about the <em>total</em> nature of this technology — because we don’t have to worry about swapping records in-and-out of memory, we can make assumptions and do some precomputation of the in-memory representation of the dataset which would not otherwise be possible. The net result is, for many datasets, vastly more efficient use of RAM. Whereas with a traditional partial-cache solution you may wonder whether you can get away with caching only 5% of the dataset, or if you need to reserve enough space for 10% in order to get an acceptable hit/miss ratio — with the same amount of memory Hollow may be able to cache 100% of your dataset and achieve a 100% hit rate.</p>
<p>And obviously, if you get a 100% hit rate, you eliminate all I/O required to access your data — and can achieve orders of magnitude more efficient data access, which opens up many possibilities.</p>
<h4>The Status-Quo</h4>
<p>Until very recently, Gatekeeper was a completely event-driven system. When a change for a video occurred in any one of its upstream systems, that system would send an event to Gatekeeper. Gatekeeper would react to that event by reaching into each of its upstream services, gathering the necessary input data to evaluate the liveness of the video and its associated assets. It would then produce a single-record output detailing the status of that single video.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/689/0*tCC6kWANBMJMgFdk" /><figcaption>Old Gatekeeper Architecture</figcaption></figure>
<p>This model had several problems associated with it:</p>
<ul>
<li>This process was completely I/O bound and put a lot of load on upstream systems.</li>
<li>Consequently, these events would queue up throughout the day and cause processing delays, which meant that titles may not actually go live on time.</li>
<li>Worse, events would occasionally get missed, meaning titles wouldn’t go live <em>at all</em> until someone from Title Operations realized there was a problem.</li>
</ul>
<p>The mitigation for these issues was to “sweep” the catalog so Videos matching specific criteria (e.g., scheduled to launch next week) would get events automatically injected into the processing queue. Unfortunately, this mitigation added many more events into the queue, which exacerbated the problem.</p>
<p>Clearly, a change in direction was necessary.</p>
<h4>The Idea</h4>
<p>We decided to employ a <em>total high-density near cache</em> (i.e., Hollow) to eliminate our I/O bottlenecks. For each of our upstream systems, we would create a Hollow dataset which encompasses all of the data necessary for Gatekeeper to perform its evaluation. Each upstream system would now be responsible for keeping its cache updated.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/607/0*AND6Rc68Zp-k4bu6" /><figcaption>New Gatekeeper Architecture</figcaption></figure>
<p>With this model, liveness evaluation is conceptually separated from the data retrieval from upstream systems. Instead of reacting to events, Gatekeeper would <em>continuously</em> process liveness for all assets in all videos across all countries in a repeating cycle. The cycle iterates over every video available at Netflix, calculating liveness details for each of them. At the end of each cycle, it produces a complete output (also a Hollow dataset) representing the liveness status details of all videos in all countries.</p>
<p>We expected that this <em>continuous processing</em> model was possible because a complete removal of our I/O bottlenecks would mean that we should be able to operate orders of magnitude more efficiently. We also expected that by moving to this model, we would realize many positive effects for the business.</p>
<ul>
<li>A definitive solution for the excess load on upstream systems generated by Gatekeeper</li>
<li>A complete elimination of liveness processing delays and missed go-live dates.</li>
<li>A reduction in the time the Content Setup Engineering team spends on performance-related issues.</li>
<li>Improved debuggability and visibility into liveness processing.</li>
</ul>
<h4>The Problem</h4>
<p>Hollow can also be thought of like a time machine. As a dataset changes over time, it communicates those changes to consumers by breaking the timeline down into a series of discrete data <em>states</em>. Each data state represents a snapshot of the entire dataset at a specific moment in time.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/554/0*ZkoW6RrX5f-GGlIf" /><figcaption>Hollow is like a time machine</figcaption></figure>
<p>Usually, consumers of a Hollow dataset are loading the latest data state and keeping their cache updated as new states are produced. However, they may instead point to a prior state — which will revert their view of the entire dataset to a point in the past.</p>
<p>The traditional method of producing data states is to maintain a single producer which runs a repeating <em>cycle</em>. During that <em>cycle</em>, the producer iterates over all records from the source of truth. As it iterates, it adds each record to the Hollow library. Hollow then calculates the differences between the data added during this cycle and the data added during the last cycle, then publishes the state to a location known to consumers.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/617/0*Fq2ekb75p_GPv6Lb" /><figcaption>Traditional Hollow usage</figcaption></figure>
<p>The problem with this total-source-of-truth iteration model is that it can take a long time. In the case of some of our upstream systems, this could take hours. This data-propagation latency was unacceptable — we can’t wait hours for liveness processing if, for example, Title Operations adds a rating to a movie that needs to go live imminently.</p>
<h4>The Improvement</h4>
<p>What we needed was a faster time machine — one which could produce states with a more frequent cadence, so that changes could be more quickly realized by consumers.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/555/0*lQ1R_pSHkk7l5JkK" /><figcaption>Incremental Hollow is like a faster time machine</figcaption></figure>
<p>To achieve this, we created an incremental Hollow infrastructure for Netflix, leveraging <a href="https://github.com/Netflix/hollow/pull/69">work</a> which had been done in the Hollow library earlier, and <a href="https://github.com/Netflix/hollow/pull/142">pioneered</a> in <a href="https://github.com/Netflix/hollow/pull/188">production</a> <a href="https://github.com/Netflix/hollow/pull/181">usage</a> by the Streaming Platform Team at Target (and is now a <a href="https://github.com/Netflix/hollow/pull/414">public non-beta API</a>).</p>
<p>With this infrastructure, each time a change is detected in a source application, the updated record is <a href="https://github.com/Netflix/hollow/pull/375">encoded</a> and emitted to a Kafka topic. A new component that is not part of the source application, the <em>Hollow Incremental Producer</em> service, performs a repeating cycle at a predefined cadence. During each cycle, it reads all messages which have been added to the topic since the last cycle and mutates the Hollow state engine to reflect the new state of the updated records.</p>
<p>If a message from the Kafka topic contains the exact same data as already reflected in the Hollow dataset, no action is taken.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/751/0*m2Dg_kSzZtp19aIN" /><figcaption>Hollow Incremental Producer Service</figcaption></figure>
<p>To mitigate issues arising from missed events, we implement a <em>sweep</em> mechanism that periodically iterates over an entire source dataset. As it iterates, it emits the content of each record to the Kafka topic. In this way, any updates which may have been missed will eventually be reflected in the Hollow dataset. Additionally, because this is not the primary mechanism by which updates are propagated to the Hollow dataset, this does not have to be run as quickly or frequently as a cycle must iterate the source in traditional Hollow usage.</p>
<p>The Hollow Incremental Producer is capable of reading a great many messages from the Kafka topic and mutating its Hollow state internally very quickly — so we can configure its cycle times to be very short (we are currently defaulting this to 30 seconds).</p>
<p>This is how we built a faster time machine. Now, if Title Operations adds a maturity rating to a movie, within 30 seconds, that data is available in the corresponding Hollow dataset.</p>
<h4>The Tangible Result</h4>
<p>With the data propagation latency issue solved, we were able to re-implement the Gatekeeper system to eliminate all I/O boundaries. With the prior implementation of Gatekeeper, re-evaluating all assets for all videos in all countries would have been unthinkable — it would tie up the entire content pipeline for more than a week (and we would then still be behind by a week since nothing else could be processed in the meantime). Now we re-evaluate everything in about 30 seconds — and we do that every minute.</p>
<p>There is no such thing as a missed or delayed liveness evaluation any longer, and the disablement of the prior Gatekeeper system reduced the load on our upstream systems — in some cases by up to 80%.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*HKPzBE_tMHd-gWEo" /><figcaption>Load reduction on one upstream system</figcaption></figure>
<p>In addition to these performance benefits, we also get a resiliency benefit. In the prior Gatekeeper system, if one of the upstream services went down, we were unable to evaluate liveness at all because we were unable to retrieve any data from that system. In the new implementation, if one of the upstream systems goes down then it does stop publishing — but we still gate <em>stale</em> data for its corresponding dataset while all others make progress. So for example, if the translated synopsis system goes down, we can still bring a movie on-site in a region if it was held back for, and then receives, the correct subtitles.</p>
<h4>The Intangible Result</h4>
<p>Perhaps even more beneficial than the performance gains has been the improvement in our development velocity in this system. We can now develop, validate, and release changes in minutes which might have before taken days or weeks — and we can do so with significantly increased release quality.</p>
<p>The time-machine aspect of Hollow means that every deterministic process which uses Hollow exclusively as input data is 100% reproducible. For Gatekeeper, this means that an exact replay of what happened at time X can be accomplished by reverting all of our input states to time X, then re-evaluating everything again.</p>
<p>We use this fact to iterate quickly on changes to the Gatekeeper business logic. We maintain a PREPROD Gatekeeper instance which “follows” our PROD Gatekeeper instance. PREPROD is also continuously evaluating liveness for the entire catalog, but publishing its output to a different Hollow dataset. At the beginning of each cycle, the PREPROD environment will gather the latest produced state from PROD, and set each of its input datasets to the exact same versions which were used to produce the PROD output.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/897/0*TyoJA01KCfat_6OY" /><figcaption>The PREPROD Gatekeeper instance “<em>follows”</em> the PROD instance</figcaption></figure>
<p>When we want to make a change to the Gatekeeper business logic, we do so and then publish it to our PREPROD cluster. The subsequent output state from PREPROD can be <a href="https://hollow.how/tooling/#diff-tool"><em>diffed</em></a> with its corresponding output state from PROD to view the precise effect that the logic change will cause. In this way, at a glance, we can validate that our changes have <em>precisely</em> the intended effect, and <em>zero</em> unintended consequences.</p>
<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*HR9Ea-8fKu05shFu" /><figcaption>A Hollow diff shows exactly what changes</figcaption></figure>
<p>This, coupled with some iteration on the deployment process, has resulted in the ability for our team to code, validate, and deploy impactful changes to Gatekeeper in literally minutes — at least an order of magnitude faster than in the prior system — and we can do so with a higher level of safety than was possible in the previous architecture.</p>
<h4>Conclusion</h4>
<p>This new implementation of the Gatekeeper system opens up opportunities to capture additional business value, which we plan to pursue over the coming quarters. Additionally, this is a pattern that can be replicated to other systems within the Content Engineering space and elsewhere at Netflix — already a couple of follow-up projects have been launched to formalize and capitalize on the benefits of this n-hollow-input, one-hollow-output architecture.</p>
<p>Content Setup Engineering is an exciting space right now, especially as we scale up our pipeline to produce more content with each passing quarter. We have many opportunities to solve real problems and provide massive value to the business — and to do so with a deep focus on computer science, using and often pioneering leading-edge technologies. If this kind of work sounds appealing to you, reach out to <a href="https://www.linkedin.com/in/ivanontiveros/">Ivan</a> to get the ball rolling.</p>
<p><img loading="lazy" src="https://medium.com/_/stat?event=post.clientViewed&#038;referrerSource=full_rss&#038;postId=f7b0ac2f6b00" width="1" height="1"></p>
<hr>
<p><a href="https://medium.com/netflix-techblog/re-architecting-the-video-gatekeeper-f7b0ac2f6b00">Re-Architecting the Video Gatekeeper</a> was originally published in <a href="https://medium.com/netflix-techblog">Netflix TechBlog</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/caching/" rel="tag">caching</a><a href="https://noise.getoto.net/tag/open-source/" rel="tag">open source</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/software-engineering/" rel="tag">software engineering</a><a href="https://noise.getoto.net/tag/software-architecture/" rel="tag">software-architecture</a></span></footer></article>
<article id="post-708038" class="post-708038 post type-post status-publish format-standard hentry tag-cloudflare-meetups tag-developers tag-events tag-javascript tag-meetup tag-programming tag-serverless tag-workers tag-workers-kv">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/06/24/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle-2/" rel="bookmark">Join Cloudflare &amp; Moz at our next meetup, Serverless in Seattle!</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/06/24/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle-2/" rel="bookmark"><time class="entry-date" datetime="2019-06-24T16:00:00+03:00">2019-06-24</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/giuliana-deangelis/" rel="author">Giuliana DeAngelis</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Giuliana DeAngelis">Giuliana DeAngelis</a> original <a href="https://blog.cloudflare.com/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/">https://blog.cloudflare.com/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/</a></p>
<p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1538097304804-2a1b932466a9?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" class="kg-image" alt="Join Cloudflare &#038; Moz at our next meetup, Serverless in Seattle!"><figcaption>Photo by <a href="https://unsplash.com/@jetcityninja?utm_source=ghost&#038;utm_medium=referral&#038;utm_campaign=api-credit">oakie</a> / <a href="https://unsplash.com/?utm_source=ghost&#038;utm_medium=referral&#038;utm_campaign=api-credit">Unsplash</a></figcaption></figure>
<p><img src="https://blog.cloudflare.com/content/images/2019/06/photo-1538097304804-2a1b932466a9.jpeg" alt="Join Cloudflare &#038; Moz at our next meetup, Serverless in Seattle!"></p>
<p>Cloudflare is organizing a <a href="https://www.cloudflare.com/events/seattle-customer-meetup-june2019/">meetup in Seattle</a> on Tuesday, June 25th and we hope you can join. We’ll be bringing together members of the developers community and Cloudflare users for an evening of discussion about serverless compute and the infinite number of use cases for deploying code at the edge. </p>
<p>To kick things off, our guest speaker <a href="https://moz.com/about/team/devin">Devin Ellis</a> will share how <a href="https://moz.com/"><strong>Moz</strong></a><strong> uses Cloudflare </strong><a href="https://www.cloudflare.com/products/cloudflare-workers/"><strong>Workers</strong></a><strong> to reduce time to first byte 30-70% by </strong><a href="https://www.cloudflare.com/learning/cdn/caching-static-and-dynamic-content/"><strong>caching dynamic content</strong></a><strong> at the edge. </strong>Kirk Schwenkler, Solutions Engineering Lead at Cloudflare, will facilitate this discussion and share his perspective on how to grow and secure businesses at scale. </p>
<p>Next up, Developer Advocate <a href="https://dev.to/signalnerve">Kristian Freeman</a> will take you through a live demo of Workers and highlight <a href="https://dev.to/cloudflareworkers/a-brief-guide-to-what-s-new-with-cloudflare-workers-di8">new features</a> of the platform. This will be an interactive session where you can try out Workers for free and develop your own applications using our new command-line tool.</p>
<p>Food and drinks will be served til close so grab your laptop and a friend and come on by!</p>
<p><a href="https://www.cloudflare.com/events/seattle-customer-meetup-june2019/"><strong>View Event Details &amp; Register Here</strong></a></p>
</p>
<p>Agenda:</p>
<p></p>
<p>
<font size="+1"></p>
<ul>
<li><strong>5:00 pm</strong> Doors open, food and drinks
</li>
<li><strong>5:30 pm</strong> Customer use case by Devin and Kirk
</li>
<li><strong>6:00 pm</strong> Workers deep dive with Kristian
</li>
<li><strong>6:30 &#8211; 8:30 pm</strong> Networking, food and drinks
</li>
</ul>
<p></font>
</p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/cloudflare-meetups/" rel="tag">Cloudflare Meetups</a><a href="https://noise.getoto.net/tag/developers/" rel="tag">Developers</a><a href="https://noise.getoto.net/tag/events/" rel="tag">Events</a><a href="https://noise.getoto.net/tag/javascript/" rel="tag">javascript</a><a href="https://noise.getoto.net/tag/meetup/" rel="tag">MeetUp</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/serverless/" rel="tag">serverless</a><a href="https://noise.getoto.net/tag/workers/" rel="tag">Workers</a><a href="https://noise.getoto.net/tag/workers-kv/" rel="tag">Workers KV</a></span></footer></article>
<article id="post-694649" class="post-694649 post type-post status-publish format-standard hentry tag-cloudflare-meetups tag-developers tag-events tag-javascript tag-meetup tag-programming tag-serverless tag-workers tag-workers-kv">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/06/24/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/" rel="bookmark">Join Cloudflare &amp; Moz at our next meetup, Serverless in Seattle!</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/06/24/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/" rel="bookmark"><time class="entry-date" datetime="2019-06-24T16:00:00+03:00">2019-06-24</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/giuliana-deangelis/" rel="author">Giuliana DeAngelis</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Giuliana DeAngelis">Giuliana DeAngelis</a> original <a href="https://blog.cloudflare.com/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/">https://blog.cloudflare.com/join-cloudflare-moz-at-our-next-meetup-serverless-in-seattle/</a></p>
<p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://images.unsplash.com/photo-1538097304804-2a1b932466a9?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" class="kg-image" alt="Join Cloudflare &#038; Moz at our next meetup, Serverless in Seattle!"><figcaption>Photo by <a href="https://unsplash.com/@jetcityninja?utm_source=ghost&#038;utm_medium=referral&#038;utm_campaign=api-credit">oakie</a> / <a href="https://unsplash.com/?utm_source=ghost&#038;utm_medium=referral&#038;utm_campaign=api-credit">Unsplash</a></figcaption></figure>
<p><img src="https://blog.cloudflare.com/content/images/2019/06/photo-1538097304804-2a1b932466a9.jpeg" alt="Join Cloudflare &#038; Moz at our next meetup, Serverless in Seattle!"></p>
<p>Cloudflare is organizing a <a href="https://www.cloudflare.com/events/seattle-customer-meetup-june2019/">meetup in Seattle</a> on Tuesday, June 25th and we hope you can join. We’ll be bringing together members of the developers community and Cloudflare users for an evening of discussion about serverless compute and the infinite number of use cases for deploying code at the edge. </p>
<p>To kick things off, our guest speaker <a href="https://moz.com/about/team/devin">Devin Ellis</a> will share how <a href="https://moz.com/"><strong>Moz</strong></a><strong> uses Cloudflare </strong><a href="https://www.cloudflare.com/products/cloudflare-workers/"><strong>Workers</strong></a><strong> to reduce time to first byte 30-70% by </strong><a href="https://www.cloudflare.com/learning/cdn/caching-static-and-dynamic-content/"><strong>caching dynamic content</strong></a><strong> at the edge. </strong>Kirk Schwenkler, Solutions Engineering Lead at Cloudflare, will facilitate this discussion and share his perspective on how to grow and secure businesses at scale. </p>
<p>Next up, Developer Advocate <a href="https://dev.to/signalnerve">Kristian Freeman</a> will take you through a live demo of Workers and highlight <a href="https://dev.to/cloudflareworkers/a-brief-guide-to-what-s-new-with-cloudflare-workers-di8">new features</a> of the platform. This will be an interactive session where you can try out Workers for free and develop your own applications using our new command-line tool.</p>
<p>Food and drinks will be served til close so grab your laptop and a friend and come on by!</p>
<p><a href="https://www.cloudflare.com/events/seattle-customer-meetup-june2019/"><strong>View Event Details &amp; Register Here</strong></a></p>
</p>
<p>Agenda:</p>
<p></p>
<p>
<font size="+1"></p>
<ul>
<li><strong>5:00 pm</strong> Doors open, food and drinks
</li>
<li><strong>5:30 pm</strong> Customer use case by Devin and Kirk
</li>
<li><strong>6:00 pm</strong> Workers deep dive with Kristian
</li>
<li><strong>6:30 &#8211; 8:30 pm</strong> Networking, food and drinks
</li>
</ul>
<p></font>
</p>
<p></p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/cloudflare-meetups/" rel="tag">Cloudflare Meetups</a><a href="https://noise.getoto.net/tag/developers/" rel="tag">Developers</a><a href="https://noise.getoto.net/tag/events/" rel="tag">Events</a><a href="https://noise.getoto.net/tag/javascript/" rel="tag">javascript</a><a href="https://noise.getoto.net/tag/meetup/" rel="tag">MeetUp</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/serverless/" rel="tag">serverless</a><a href="https://noise.getoto.net/tag/workers/" rel="tag">Workers</a><a href="https://noise.getoto.net/tag/workers-kv/" rel="tag">Workers KV</a></span></footer></article>
<article id="post-687052" class="post-687052 post type-post status-publish format-standard hentry tag-crypto tag-crypto-week tag-cryptography tag-entropy tag-programming tag-security">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/06/17/inside-the-entropy/" rel="bookmark">Inside the Entropy</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/06/17/inside-the-entropy/" rel="bookmark"><time class="entry-date" datetime="2019-06-17T16:00:00+03:00">2019-06-17</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/alex-davidson/" rel="author">Alex Davidson</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Alex Davidson">Alex Davidson</a> original <a href="https://blog.cloudflare.com/inside-the-entropy/">https://blog.cloudflare.com/inside-the-entropy/</a></p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/image8-3.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<blockquote><p>
<img src="https://blog.cloudflare.com/content/images/2019/06/image8-4.png" alt="Inside the Entropy"></p>
<p>Randomness, randomness everywhere;<br />
Nor any verifiable entropy.</p>
</blockquote>
<p></p>
<p>Generating random outcomes is an essential part of everyday life; from lottery drawings and constructing competitions, to performing deep cryptographic computations. To use randomness, we must have some way to &#8216;sample&#8217; it. This requires interpreting some natural phenomenon (such as a fair dice roll) as an event that generates some random output. From a computing perspective, we interpret random outputs as bytes that we can then use in algorithms (such as drawing a lottery) to achieve the functionality that we want.</p>
<p>The sampling of randomness securely and efficiently is a critical component of all modern computing systems. For example, nearly all public-key cryptography relies on the fact that algorithms can be seeded with bytes generated from genuinely random outcomes.</p>
<p>In scientific experiments, a random sampling of results is necessary to ensure that data collection measurements are not skewed. Until now, generating random outputs in a way that we can verify that they are indeed random has been very difficult; typically involving taking a variety of statistical measurements.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/image9-2.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>During Crypto week, Cloudflare is releasing a new <a href="https://blog.cloudflare.com/league-of-entropy">public randomness beacon</a> as part of the launch of the <a href="https://leagueofentropy.com/">League of Entropy</a>. The League of Entropy is a network of beacons that produces <em>distributed</em>, <em>publicly verifiable</em> random outputs for use in applications where the nature of the randomness must be publicly audited. The underlying cryptographic architecture is based on the <a href="https://github.com/dedis/drand">drand project</a>.</p>
<p></p>
<p>Verifiable randomness is essential for ensuring trust in various institutional decision-making processes such as <a href="https://blog.cloudflare.com/league-of-entropy">elections and lotteries</a>. There are also cryptographic applications that require verifiable randomness. In the land of decentralized consensus mechanisms, the <a href="https://dfinity.org/static/dfinity-consensus-0325c35128c72b42df7dd30c22c41208.pdf">DFINITY approach</a> uses random seeds to decide the outcome of leadership elections. In this setting, it is essential that the randomness is publicly verifiable so that the outcome of the leadership election is trustworthy. Such a situation arises more generally in <a href="https://en.wikipedia.org/wiki/Sortition">Sortitions</a>: an election where leaders are selected as a random individual (or subset of individuals) from a larger set.</p>
<p></p>
<p>In this blog post, we will give a technical overview behind the cryptography used in the distributed randomness beacon, and how it can be used to generate publicly verifiable randomness. We believe that distributed randomness beacons have a huge amount of utility in realizing the <a href="https://blog.cloudflare.com/welcome-to-crypto-week-2019/">Internet of the Future</a>; where we will be able to rely on distributed, decentralized solutions to problems of a global-scale.</p>
<p></p>
<h2 id="randomness-entropy">Randomness &amp; entropy</h2>
<p></p>
<p>A source of randomness is measured in terms of the amount of <em>entropy</em> it provides. Think about the entropy provided by a random output as a score to indicate how “random” the output actually is. The notion of information entropy was concretised by the famous scientist Claude Shannon in his paper <a href="https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication">A Mathematical Theory of Communication</a>, and is sometimes known as <em><a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">Shannon Entropy</a></em>.</p>
<p></p>
<p>A common way to think about random outputs is: a sequence of bits derived from some random outcome. For the sake of an argument, consider a fair 8-sided dice roll with sides marked 0-7. The outputs of the dice can be written as the bit-strings <code>000,001,010,...,111</code>. Since the dice is fair, any of these outputs is equally likely. This is means that each of the bits is equally likely to be <code>0</code> or <code>1</code>. Consequently, interpreting the output of the dice roll as a random output then derives randomness with <code>3</code> bits of entropy.</p>
<p></p>
<p>More generally, if a perfect source of randomness guarantees strings with <code>n</code> bits of entropy, then it generates bit-strings where each bit is equally likely to be <code>0</code> or <code>1</code>. This allows us to predict the value of any bit with maximum probability <code>1/2</code>. If the outputs are sampled from such a perfect source, we consider them <em>uniformly distributed</em>. If we sample the outputs from a source where one bit is predictable with higher probability, then the string has <code>n-1</code> bits of entropy. To go back to the dice analogy, rolling a 6-sided dice provides less than <code>3</code> bits of entropy because the possible outputs are <code>000,001,010,011,100,101</code> and so the 2nd and 3rd bits are more likely to be to set to <code>0</code> than to <code>1</code>.</p>
<p>It is possible to mix entropy sources using specifically designed mixing functions to retrieve something with even greater entropy. The maximum resulting entropy is the sum of the entropy taken from the number of entropic sources used as input.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/combined-entropy-@2x.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<h4 id="sampling-randomness">Sampling randomness</h4>
<p>To sample randomness, let’s first identify the appropriate sources. There are many natural phenomena that one can use:</p>
<ul>
<li>atmospheric noise;</li>
<li>radioactive decay;</li>
<li>turbulent motion; like that generated in Cloudflare’s wall of <a href="https://blog.cloudflare.com/lavarand-in-production-the-nitty-gritty-technical-details/">lava lamps(!)</a>.</li>
</ul>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/pasted-image-0--1-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>Unfortunately, these phenomena require very specific measuring tools, which are prohibitively expensive to install in mainstream consumer electronics. As such, most personal computing devices usually use external usage characteristics for seeding specific generator functions that output randomness as and when the system requires it. These characteristics include keyboard typing patterns and speed and mouse movement – since such usage patterns are based on the human user, it is assumed they provide sufficient entropy as a randomness source. An example of a random number generator that takes entropy from these characteristics is the Linux-based <a href="https://en.wikipedia.org/wiki/RdRand">RDRAND</a> function.</p>
<p>Naturally, it is difficult to tell whether a system is <em>actually</em> returning random outputs by only inspecting the outputs. There are statistical tests that detect whether a series of outputs is not uniformly distributed, but these tests cannot ensure that they are unpredictable. This means that it is hard to detect if a given system has had its randomness generation compromised.</p>
<h2 id="distributed-randomness">Distributed randomness</h2>
<p>It’s clear we need alternative methods for sampling randomness so that we can provide guarantees that trusted mechanisms, such as elections and lotteries, take place in secure tamper-resistant environments. The <a href="https://github.com/dedis/drand/">drand</a> project was started by researchers at <a href="https://www.epfl.ch/about/">EPFL</a> to address this problem. The drand charter is to provide an easily configurable randomness beacon running at geographically distributed locations around the world. The intention is for each of these beacons to generate portions of randomness that can be combined into a single random string that is publicly verifiable.</p>
<p>This functionality is achieved using <em>threshold cryptography</em>. Threshold cryptography seeks to derive solutions for standard cryptographic problems by combining information from multiple distributed entities. The notion of the threshold means that if there are <code>n</code> entities, then any <code>t</code> of the entities can combine to construct some cryptographic object (like a ciphertext, or a digital signature). These threshold systems are characterised by a setup phase, where each entity learns a <em>share</em> of data. They will later use this share of data to create a combined cryptographic object with a subset of the other entities.</p>
<h3 id="threshold-randomness">Threshold randomness</h3>
<p>In the case of a distributed randomness protocol, there are <code>n</code> <em>randomness beacons</em> that broadcast random values sampled from their initial data share, and the current state of the system. This data share is created during a trusted setup phase, and also takes in some internal random value that is generated by the beacon itself.</p>
<p>When a user needs randomness, they send requests to some number <code>t</code> of beacons, where <code>t &lt; n</code>, and combine these values using a specific procedure. The result is a random value that can be verified and used for public auditing mechanisms.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/pasted-image-0--2-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>Consider what happens if some proportion <code>c/n</code> of the randomness beacons are <em>corrupted</em> at any one time. The nature of a threshold cryptographic system is that, as long as <code>c &lt; t</code>, then the end result still remains random.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/pasted-image-0--3-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>If <code>c</code> exceeds <code>t</code> then the random values produced by the system become predictable and the notion of randomness is lost. In summary, the distributed randomness procedure provides verifiably random outputs with sufficient entropy only when <code>c &lt; t</code>.</p>
<p>By distributing the beacons independent of each other and in geographically disparate locations, the probability that <code>t</code> locations can be corrupted at any one time is extremely low. The minimum choice of <code>t</code> is equal to <code>n/2</code>.</p>
<h2 id="how-does-it-actually-work">How does it actually work?</h2>
<p>What we described above sounds a bit like magic&lt;sup&gt;tm&lt;/sup&gt;. Even if <code>c = t-1</code>, then we can ensure that the output is indeed random and unpredictable! To make it clearer how this works, let’s dive a bit deeper into the underlying cryptography.</p>
<p>Two core components of drand are: a <em>distributed key generation</em> (DKG) procedure, and a <em>threshold signature scheme</em>. These core components are used in setup and randomness generation procedures, respectively. In just a bit, we’ll outline how drand uses these components (without navigating too deeply into the onerous mathematics).</p>
<h3 id="distributed-key-generation">Distributed key generation</h3>
<p>At a high-level, the DKG procedure creates a distributed secret key that is formed of <code>n</code> different key pairs <code>(vk_i, sk_i)</code>, each one being held by the entity <code>i</code> in the system. These key pairs will eventually be used to instantiate a <code>(t,n)</code>-threshold signature scheme (we will discuss this more later). In essence, <code>t</code> of the entities will be able to combine to construct a valid signature on any message.</p>
<p>To think about how this might work, consider a distributed key generation scheme that creates <code>n</code> distributed keys that are going to be represented by pizzas. Each pizza is split into <code>n</code> slices and one slice from each is secretly passed to one of the participants. Each entity receives one slice from each of the different pizzas (<code>n</code> in total) and combines these slices to form their own pizza. Each combined pizza is unique and secret for each entity, representing their own key pair.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://lh3.googleusercontent.com/ggviF6qzgC5ENm8dYhK88NzMpyA2yHIP9OCDCL0TsO2ajFUhNnre8lpK3EeWGKsAGJiEPrCI_-d5G9-xsqmO9RdEJNN9t-o-OxvrSlTnRT_QJj7OVamtAoGrZF_DrpYkBcy9kAvJ" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://lh5.googleusercontent.com/dKBnrDjJh_fPKm2bkI9O2Rrw2LMfVAOpOc78wZBOKXhGjGJ4whqNT4ZZOQScfYGTW6Pj3JYljx5SCBZ9RsGNnmTCP0hhQL7A9uF2rYdB2yqghaFu6JAVGmBUmvVFtdomOQ50Cb3i" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<h4 id="mathematical-intuition">Mathematical intuition</h4>
<p>Mathematically speaking, and rather than thinking about pizzas, we can describe the underlying phenomenon by reconstructing lines or curves on a graph. We can take two coordinates on a <code>(x,y)</code> plane and immediately (and uniquely) define a line with the equation <code>y = ax+b</code>. For example, the points <code>(2,3)</code> and <code>(4,7)</code> immediately define a line with gradient <code>(7-3)/(4/2) = 2</code> so <code>a=2</code>. You can then derive the <code>b</code> coefficient as <code>-1</code> by evaluating either of the coordinates in the equation <code>y = 2x + b</code>. By <em>uniquely</em>, we mean that only the line <code>y = 2x -1</code> satisfies the two coordinates that are chosen; no other choice of <code>a</code> or <code>b</code> fits.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/line2-2-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>The curve <code>ax+b</code> has degree <code>1</code>, where the degree of the equation refers to the highest order multiplication of unknown variables in the equation. That might seem like mathematical jargon, but the equation above contains only one term <code>ax</code>, which depends on the unknown variable <code>x</code>. In this specific term, the  <em>exponent</em> (or <em>power</em>) of <code>x</code> is <code>1</code>, and so the degree of the entire equation is also <code>1</code>.</p>
<p>Likewise, by taking three sets of coordinates pairs in the same plane, we uniquely define a quadratic curve with an equation that approximately takes the form <code>y = ax^2 + bx + c</code> with the coefficients <code>a,b,c</code> uniquely defined by the chosen coordinates. The process is a bit more involved than the above case, but it essentially starts in the same way using three coordinate pairs <code>(x_1, y_1)</code>, <code>(x_2, y_2)</code> and <code>(x_3, y_3)</code>.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/line3.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>By a quadratic curve, we mean a curve of degree <code>2</code>. We can see that this curve has degree <code>2</code> because it contains two terms <code>ax^2</code> and <code>bx</code> that depend on <code>x</code>. The highest order term is the <code>ax^2</code> term with an exponent of <code>2</code>, so this curve has degree <code>2</code> (ignore the term <code>bx</code> which has a smaller power).</p>
<p>What we are ultimately trying to show is that this approach scales for curves of degree <code>n</code> (of the form <code>y = a_n x^n + … a_1 x + a_0</code>). So, if we take <code>n+1</code> coordinates on the <code>(x,y)</code> plane, then we can uniquely reconstruct the curve of this form entirely. Such degree <code>n</code> equations are also known as <em>polynomials</em> of degree <code>n</code>.</p>
<p>In order to generalise the approach to general degrees we need some kind of formula. This formula should take <code>n+1</code> pairs of coordinates and return a polynomial of degree <code>n</code>. Fortunately, such a formula exists without us having to derive it ourselves, it is known as the <a href="https://en.wikipedia.org/wiki/Lagrange_polynomial#Definition"><em>Lagrange interpolation polynomial</em></a>. Using the formula in the link, we can reconstruct any <code>n</code> degree polynomial using <code>n+1</code> unique pairs of coordinates.</p>
<p>Going back to pizzas temporarily, it will become clear in the next section how this Lagrange interpolation procedure essentially describes the dissemination of one slice (corresponding to <code>(x,y)</code> coordinates) taken from a single pizza (the entire <code>n-1</code> degree polynomial) among <code>n</code> participants. Running this procedure <code>n</code> times in parallel allows each entity to construct their entire pizza (or the eventual key pair).</p>
<h4 id="back-to-key-generation">Back to key generation</h4>
<p>Intuitively, in the DKG procedure we want to distribute <code>n</code> key pairs among <code>n</code> participants. This effectively means running <code>n</code> parallel instances of a <code>t</code>-out-of-<code>n</code> <a href="https://en.wikipedia.org/wiki/Shamir's_Secret_Sharing">Shamir Secret Sharing</a> scheme. This secret sharing scheme is built entirely upon the polynomial interpolation technique that we described above.</p>
<p>In a single instance, we take the secret key to be the first coefficient of a polynomial of degree <code>t-1</code> and the public key is a published value that depends on this secret key, but does not reveal the actual coefficient. Think of RSA, where we have a number <code>N = pq</code> for secret large prime numbers <code>p,q</code>, where <code>N</code> is public but does not reveal the actual factorisation. Notice that if the polynomial is reconstructed using the interpolation technique above, then we immediately learn the secret key, because the first coefficient will be made explicit.</p>
<p>Each secret sharing scheme publishes shares, where each share is a different evaluation of the polynomial (dependent on the entity <code>i</code> receiving the key share). These evaluations are essentially coordinates on the <code>(x,y)</code> plane.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://lh6.googleusercontent.com/sXyVqw9ZGXOODiMiLN7e11JyzO6KZMq_r04xnOH-N_Wdqndau2CUUHmNG0RB1XJMG8YiCeT6Hddy0g4MuwsqvKyHQRQcchyydXTTT89s346jgmwoql8drJ1dWPRQWctKKoN8ZVRW" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>By running <code>n</code> parallel instances of the secret sharing scheme, each entity receives <code>n</code> shares and then combines all of these to form their overall key pair <code>(vk_i, sk_i)</code>.</p>
<p>The DKG procedure uses <code>n</code> parallel secret sharing procedures along with <a href="https://link.springer.com/chapter/10.1007/3-540-46766-1_9">Pedersen commitments</a> to distribute the key pairs. We explain in the next section how this procedure is part of the procedure for provisioning randomness beacons.</p>
<p>In summary, it is important to remember that <strong>each party</strong> in the DKG protocol generates a random secret key from the <code>n</code> shares that they receive, and they compute the corresponding public key from this. We will now explain how each entity uses this key pair to perform the cryptographic procedure that is used by the drand protocol.</p>
<h3 id="threshold-signature-scheme">Threshold signature scheme</h3>
<p>Remember: a standard signature scheme considers a key-pair <code>(vk,sk)</code>, where <code>vk</code> is a public verification key and <code>sk</code> is a private signing key. So, messages <code>m</code> signed with <code>sk</code> can be verified with <code>vk</code>. The security of the scheme ensures that it is difficult for anybody who does not hold <code>sk</code> to compute a valid signature for any message <code>m</code>.</p>
<p>A <em>threshold signature scheme</em> allows a set of users holding distributed key-pairs <code>(vk_i,sk_i)</code> to compute intermediate signatures <code>u_i</code> on a given message <code>m</code>.</p>
<p>Given knowledge of some number <code>t</code> of intermediate signatures <code>u_i</code>, a valid signature <code>u</code> on the message <code>m</code> can be reconstructed under the combined secret key <code>sk</code>. The public key <code>vk</code> can also be inferred using knowledge of the public keys <code>vk_i</code>, and then this public key can be used to verify <code>u</code>.</p>
<p>Again, think back to reconstructing the degree <code>t-1</code> curves on graphs with <code>t</code> known coordinates. In this case, the coordinates correspond to the intermediate signatures <code>u_i</code>, and the signature <code>u</code> corresponds to the entire curve. For the actual signature schemes, the mathematics are much more involved than in the DKG procedure, but the principal is the same.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/threshold-sig-3-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<h3 id="drand-protocol">drand protocol</h3>
<p>The <code>n</code> beacons that will take part in the drand project are identified. In the trusted setup phase, the DKG protocol from above is run, and each beacon effectively creates a key pair <code>(vk_i, sk_i)</code> for a threshold signature scheme. In other words, this key pair will be able to generate intermediate signatures that can be combined to create an entire signature for the system.</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/06/DKG-6-.png" class="kg-image" alt="Inside the Entropy"></figure>
<p></p>
<p>For each round (occurring once a minute, for example), the beacons agree on a signature <code>u</code> evaluated over a message containing the previous round’s signature and the current round’s number. This signature <code>u</code> is the result of combining the intermediate signatures <code>u_i</code> over the same message. Each intermediate signature <code>u_i</code> is created by each of the beacons using their secret <code>sk_i</code>.</p>
<p>Once this aggregation completes, each beacon displays the signature for the current round, along with the previous signature and round number. This allows any client to publicly verify the signature over this data to verify that the beacons honestly aggregate. This provides a chain of verifiable signatures, extending back to the first round of output. In addition, there are threshold signature schemes that output signatures that are indistinguishable from random sequences of bytes. Therefore, these signatures can be used directly as verifiable randomness for the applications we discussed previously.</p>
<h3 id="what-does-drand-use">What does drand use?</h3>
<p>To instantiate the required threshold signature scheme, drand uses the <code>(t,n)</code>&#8211;<a href="https://www.iacr.org/archive/pkc2003/25670031/25670031.pdf">BLS signature scheme</a> of Boneh, Lynn and Shacham. In particular, we can instantiate this scheme in the elliptic curve setting using  <a href="https://github.com/dfinity/bn">Barreto-Naehrig</a> curves. Moreover, the BLS signature scheme outputs sufficiently large signatures that are randomly distributed, giving them enough entropy to be sources of randomness. Specifically the signatures are randomly distributed over 64 bytes.</p>
<p>BLS signatures use a specific form of mathematical operation known as a <em>cryptographic pairing</em>. Pairings can be computed in certain elliptic curves, including the Barreto-Naehrig curve configurations. A detailed description of pairing operations is beyond the scope of this blog post; though it is important to remember that these operations are integral to how BLS signatures work.</p>
<p>Concretely speaking, all drand cryptographic operations are carried out using a library built on top of Cloudflare&#8217;s implementation of the <a href="https://github.com/cloudflare/bn256/tree/lattices">bn256 curve</a>. The Pedersen DKG protocol follows the design of <a href="https://link.springer.com/article/10.1007/s00145-006-0347-3">Gennaro et al.</a>.</p>
<h3 id="how-does-it-work">How does it work?</h3>
<p>The randomness beacons are synchronised in rounds. At each round, a beacon produces a new signature <code>u_i</code> using its private key <code>sk_i</code> on the previous signature generated and the round ID. These signatures are usually broadcast on the URL <code>drand.&lt;host&gt;.com/api/public</code>. These signatures can be verified using the keys <code>vk_i</code> and over the same data that is signed. By signing the previous signature and the current round identifier, this establishes a chain of trust for the randomness beacon that can be traced back to the original signature value.</p>
<p>The randomness can be retrieved by combining the signatures from each of the beacons using the threshold property of the scheme. This reconstruction of the signature <code>u</code> from each intermediate signature <code>u_i</code> is done internally by the League of Entropy nodes. Each beacon broadcasts the entire signature <code>u</code>, that can be accessed over the HTTP endpoint above.</p>
<h2 id="cloudflare-s-drand-beacon">Cloudflare&#8217;s drand beacon</h2>
<p>As we mentioned at the start of this blog post, Cloudflare has launched our <a href="https://blog.cloudflare.com/league-of-entropy">distributed randomness beacon</a>. This beacon is part of a network of beacons from different institutions around the globe that form the <a href="https://leagueofentropy.com/">League of  Entropy</a>.</p>
<p>The Cloudflare beacon uses <a href="https://blog.cloudflare.com/lavarand-in-production-the-nitty-gritty-technical-details/">LavaRand</a> as its internal source of randomness for the DKG. Other League of Entropy drand beacons have their own sources of randomness.</p>
<h3 id="give-me-randomness-">Give me randomness!</h3>
<p>The Cloudflare randomness beacon allows you to retrieve the latest random value from the League of Entropy using a simple HTTP request:</p>
<p></p>
<pre><code class="language-bash">curl https://drand.cloudflare.com/api/public
</code></pre>
<p></p>
<p>The response is a JSON blob of the form:</p>
<p></p>
<pre><code class="language-json">{
    &quot;round&quot;: 7,
    &quot;previous&quot;: &lt;hex-encoded-previous-signature&gt;,
    &quot;randomness&quot;: {
        &quot;gid&quot;: 21,
        &quot;point&quot;: &lt;hex-encoded-new-signature&gt;
    }
}
</code></pre>
<p></p>
<p>where, <code>randomness.point</code> is the signature <code>u</code> aggregated among the entire set of beacons.</p>
<p>The signature is computed as an evaluation of the message, and is comprised of the signature of the previous round, <code>previous</code>, the current round number, <code>round</code>, and the aggregated secret key of the system. This signature can be verified using the entire public key <code>vk</code> of the Cloudflare beacon, learned using another HTTP request:</p>
<p></p>
<pre><code class="language-bash">curl https://drand.cloudflare.com/api/public
</code></pre>
<p></p>
<p>There are eight collaborators in the League of Entropy. You can learn the current round of randomness (or the system’s public key) by querying these beacons on the HTTP endpoints listed above.</p>
<ul>
<li><a href="https://drand.cloudflare.com/">https://drand.cloudflare.com:443</a></li>
<li><a href="https://random.uchile.cl:8080/">https://random.uchile.cl:8080</a></li>
<li><a href="https://drand.cothority.net:7003/">https://drand.cothority.net:7003</a></li>
<li><a href="https://drand.kudelskisecurity.com/">https://drand.kudelskisecurity.com:443</a></li>
<li><a href="https://drand.lbarman.ch/">https://drand.lbarman.ch:443</a></li>
<li><a href="https://drand.nikkolasg.xyz:8888/">https://drand.nikkolasg.xyz:8888</a></li>
<li><a href="https://drand.protocol.ai:8080/">https://drand.protocol.ai:8080</a></li>
<li><a href="https://drand.zerobyte.io:8888/">https://drand.zerobyte.io:8888</a></li>
</ul>
<h2 id="randomness-the-future">Randomness &amp; the future</h2>
<p>Cloudflare will continue to take an active role in the drand project, both as a contributor and by running a randomness beacon with the League of Entropy. The League of Entropy is a worldwide joint effort of individuals and academic institutions. We at Cloudflare believe it can help us realize the mission of helping Build a Better Internet. For more information on Cloudflare&#8217;s participation in the League of Entropy, visit <a href="https://cloudflare.com/drand">https://cloudflare.com/drand</a> or read <a href="https://blog.cloudflare.com/league-of-entropy">Dina&#8217;s blog post</a>.</p>
<p>Cloudflare would like to thank all of their collaborators in the League of Entropy; from EPFL, UChile, Kudelski Security and Protocol Labs. This work would not have been possible without the work of those who contributed to the <a href="https://github.com/dedis/drand">open-source drand project</a>. We would also like to thank and appreciate the work of Gabbi Fisher, Brendan McMillion, and Mahrud Sayrafi in launching the Cloudflare randomness beacon.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/crypto/" rel="tag">crypto</a><a href="https://noise.getoto.net/tag/crypto-week/" rel="tag">Crypto Week</a><a href="https://noise.getoto.net/tag/cryptography/" rel="tag">Cryptography</a><a href="https://noise.getoto.net/tag/entropy/" rel="tag">Entropy</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/security/" rel="tag">security</a></span></footer></article>
<article id="post-659060" class="post-659060 post type-post status-publish format-standard hentry tag-javascript tag-programming tag-serverless tag-workers tag-workers-kv">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/05/21/building-a-to-do-list-with-workers-and-kv/" rel="bookmark">Building a To-Do List with Workers and KV</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/05/21/building-a-to-do-list-with-workers-and-kv/" rel="bookmark"><time class="entry-date" datetime="2019-05-21T16:53:41+03:00">2019-05-21</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/kristian-freeman/" rel="author">Kristian Freeman</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Kristian Freeman">Kristian Freeman</a> original <a href="https://blog.cloudflare.com/building-a-to-do-list-with-workers-and-kv/">https://blog.cloudflare.com/building-a-to-do-list-with-workers-and-kv/</a></p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/workers-KV-dark-back@2x.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p><img src="https://blog.cloudflare.com/content/images/2019/05/workers-KV-dark-back@2x-1.png" alt="Building a To-Do List with Workers and KV"></p>
<p>In this tutorial, we’ll build a todo list application in HTML, CSS and JavaScript, with a twist: all the data should be stored inside of the newly-launched Workers KV, and the application itself should be served directly from Cloudflare’s edge network, using <a href="https://www.cloudflare.com/products/cloudflare-workers/">Cloudflare Workers</a>.</p>
<p>To start, let’s break this project down into a couple different discrete steps. In particular, it can help to focus on the constraint of working with Workers KV, as handling data is generally the most complex part of building an application:</p>
<ol>
<li>Build a todos data structure</li>
<li>Write the todos into Workers KV</li>
<li>Retrieve the todos from Workers KV</li>
<li>Return an HTML page to the client, including the todos (if they exist)</li>
<li>Allow creation of new todos in the UI</li>
<li>Allow completion of todos in the UI</li>
<li>Handle todo updates</li>
</ol>
<p>This task order is pretty convenient, because it’s almost perfectly split into two parts: first, understanding the Cloudflare/API-level things we need to know about Workers <em>and</em> KV, and second, actually building up a user interface to work with the data.</p>
<h3 id="understanding-workers">Understanding Workers</h3>
<p>In terms of implementation, a great deal of this project is centered around KV &#8211; although that may be the case, it’s useful to break down <em>what</em> Workers are exactly.</p>
<p>Service Workers are background scripts that run in your browser, alongside your application. Cloudflare Workers are the same concept, but super-powered: your Worker scripts run on Cloudflare’s edge network, in-between your application and the client’s browser. This opens up a huge amount of opportunity for interesting integrations, especially considering the network’s massive scale around the world. Here’s some of the use-cases that I think are the most interesting:</p>
<ol>
<li>Custom security/filter rules to block bad actors before they ever reach the origin</li>
<li>Replacing/augmenting your website’s content based on the request content (i.e. user agents and other headers)</li>
<li>Caching requests to improve performance, or using Cloudflare KV to optimize high-read tasks in your application</li>
<li>Building an application <em>directly</em> on the edge, removing the dependence on origin servers entirely</li>
</ol>
<p>For this project, we’ll lean heavily towards the latter end of that list, building an application that clients communicate with, served on Cloudflare’s edge network. This means that it’ll be globally available, with low-latency, while still allowing the ease-of-use in building applications directly in JavaScript.</p>
<h3 id="setting-up-a-canvas">Setting up a canvas</h3>
<p>To start, I wanted to approach this project from the bare minimum: no frameworks, JS utilities, or anything like that. In particular, I was most interested in writing a project from scratch and serving it directly from the edge. Normally, I would deploy a site to something like <a href="https://pages.github.com/">GitHub Pages</a>, but avoiding the need for an origin server altogether seems like a really powerful (and performant idea) &#8211; let’s try it!</p>
<p>I also considered using <a href="https://todomvc.com/">TodoMVC</a> as the blueprint for building the functionality for the application, but even the <a href="http://todomvc.com/examples/vanillajs/#/">Vanilla JS</a> version is a pretty impressive amount of <a href="https://github.com/tastejs/todomvc/tree/gh-pages/examples/vanillajs">code</a>, including a number of Node packages &#8211; it wasn’t exactly a concise chunk of code to just dump into the Worker itself.</p>
<p>Instead, I decided to approach the beginnings of this project by building a simple, blank HTML page, and including it inside of the Worker. To start, we’ll sketch something out locally, like this:</p>
</p>
<p></p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot;&gt;
    &lt;title&gt;Todos&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Todos&lt;/h1&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p></p>
<p>Hold on to this code &#8211; we’ll add it later, inside of the Workers script. For the purposes of the tutorial, I’ll be serving up this project at todo.kristianfreeman.com,. My personal website was already hosted on Cloudflare, and since I’ll be serving , it was time to create my first Worker.</p>
<h3 id="creating-a-worker">Creating a worker</h3>
<p>Inside of my Cloudflare account, I hopped into the Workers tab and launched the Workers editor.</p>
<p>This is one of my favorite features of the editor &#8211; working with your actual website, understanding <em>how</em> the worker will interface with your existing project.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image4-2.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<p>The process of writing a Worker should be familiar to anyone who’s used the fetch library before. In short, the default code for a Worker hooks into the <code>fetch</code> event, passing the request of that event into a custom function, <code>handleRequest</code>:</p>
</p>
<p></p>
<pre><code class="language-javascript">addEventListener('fetch', event =&gt; {
  event.respondWith(handleRequest(event.request))
})
</code></pre>
<p></p>
<p>Within <code>handleRequest</code>, we make the actual request, using <code>fetch</code>, and return the response to the client. In short, we have a place to intercept the response body, but by default, we let it pass-through:</p>
</p>
<p></p>
<pre><code class="language-javascript">async function handleRequest(request) {
  console.log('Got request', request)
  const response = await fetch(request)
  console.log('Got response', response)
  return response
}
</code></pre>
<p></p>
<p>So, given this, where do we begin actually <em>doing stuff</em> with our worker?</p>
<p>Unlike the default code given to you in the Workers interface, we want to skip fetching the incoming request: instead, we’ll construct a new <code>Response</code>, and serve it directly from the edge:</p>
</p>
<p></p>
<pre><code class="language-javascript">async function handleRequest(request) {
  const response = new Response(&quot;Hello!&quot;)
  return response
}
</code></pre>
<p></p>
<p>Given that very small functionality we’ve added to the worker, let’s deploy it. Moving into the “Routes” tab of the Worker editor, I added the route <code>https://todo.kristianfreeman.com/*</code> and attached it to the cloudflare-worker-todos script.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image5.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<p>Once attached, I deployed the worker, and voila! Visiting todo.kristianfreeman.com in-browser gives me my simple “Hello!” response back.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/Screen-Shot-2019-05-15-at-10.12.04-AM.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<h3 id="writing-data-to-kv">Writing data to KV</h3>
<p>The next step is to populate our todo list with actual data. To do this, we’ll make use of Cloudflare’s Workers KV &#8211; it’s a simple key-value store that you can access inside of your Worker script to read (and write, although it’s less common) data.</p>
<p>To get started with KV, we need to set up a “namespace”. All of our cached data will be stored inside that namespace, and given just a bit of configuration, we can access that namespace inside the script with a predefined variable.</p>
<p>I’ll create a new namespace called <code>KRISTIAN_TODOS</code>, and in the Worker editor, I’ll expose the namespace by binding it to the variable <code>KRISTIAN_TODOS</code>.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image1-6.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<p>Given the presence of <code>KRISTIAN_TODOS</code> in my script, it’s time to understand the KV API. At time of writing, a KV namespace has three primary methods you can use to interface with your cache: <code>get</code>, <code>put</code>, and <code>delete</code>. Pretty straightforward!</p>
<p>Let’s start storing data by defining an initial set of data, which we’ll put inside of the cache using the put method. I’ve opted to define an object, <code>defaultData</code>, instead of a simple array of todos: we may want to store metadata and other information inside of this cache object later on. Given that data object, I’ll use <code>JSON.stringify</code> to put a simple string into the cache:</p>
</p>
<p></p>
<pre><code class="language-javascript">async function handleRequest(request) {
  // ...previous code
  
  const defaultData = { 
    todos: [
      {
        id: 1,
        name: 'Finish the Cloudflare Workers blog post',
          completed: false
      }
    ] 
  }
  KRISTIAN_TODOS.put(&quot;data&quot;, JSON.stringify(defaultData))
}

</code></pre>
<p></p>
<p>The Worker KV data store is <em>eventually</em> consistent: writing to the cache means that it will become available <em>eventually</em>, but it’s possible to attempt to read a value back from the cache immediately after writing it, only to find that the cache hasn’t been updated yet.</p>
<p>Given the presence of data in the cache, and the assumption that our cache is eventually consistent, we should adjust this code slightly: first, we should actually read from the cache, parsing the value back out, and using it as the data source if exists. If it doesn’t, we’ll refer to <code>defaultData</code>, setting it as the data source <em>for now</em> (remember, it should be set in the future… <em>eventually</em>), while also setting it in the cache for future use. After breaking out the code into a few functions for simplicity, the result looks like this:</p>
</p>
<p></p>
<pre><code class="language-javascript">const defaultData = { 
  todos: [
    {
      id: 1,
      name: 'Finish the Cloudflare Workers blog post',
      completed: false
    }
  ] 
}

const setCache = data =&gt; KRISTIAN_TODOS.put(&quot;data&quot;, data)
const getCache = () =&gt; KRISTIAN_TODOS.get(&quot;data&quot;)

async function getTodos(request) {
  // ... previous code
  
  let data;
  const cache = await getCache()
  if (!cache) {
    await setCache(JSON.stringify(defaultData))
    data = defaultData
  } else {
    data = JSON.parse(cache)
  }
}
</code></pre>
<p></p>
<h3 id="rendering-data-from-kv">Rendering data from KV</h3>
<p>Given the presence of data in our code, which is the cached data object for our application, we should actually take this data and make it available on screen.</p>
<p>In our Workers script, we’ll make a new variable, <code>html</code>, and use it to build up a static HTML template that we can serve to the client. In <code>handleRequest</code>, we can construct a new <code>Response</code> (with a <code>Content-Type</code> header of <code>text/html</code>), and serve it to the client:</p>
</p>
<p></p>
<pre><code class="language-javascript">const html = `
&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot;&gt;
    &lt;title&gt;Todos&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Todos&lt;/h1&gt;
  &lt;/body&gt;
&lt;/html&gt;
`

async function handleRequest(request) {
  const response = new Response(html, {
    headers: { 'Content-Type': 'text/html' }
  })
  return response
}

</code></pre>
<p></p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/Screen-Shot-2019-05-15-at-10.06.57-AM.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<p>We have a static HTML site being rendered, and now we can begin populating it with data! In the body, we’ll add a <code>ul</code> tag with an id of <code>todos</code>:</p>
</p>
<p></p>
<pre><code class="language-html">&lt;body&gt;
  &lt;h1&gt;Todos&lt;/h1&gt;
  &lt;ul id=&quot;todos&quot;&gt;&lt;/ul&gt;
&lt;/body&gt;
</code></pre>
<p></p>
<p>Given that body, we can also add a script <em>after</em> the body that takes a todos array, loops through it, and for each todo in the array, creates a <code>li</code> element and appends it to the todos list:</p>
</p>
<p></p>
<pre><code class="language-html">&lt;script&gt;
  window.todos = [];
  var todoContainer = document.querySelector(&quot;#todos&quot;);
  window.todos.forEach(todo =&gt; {
    var el = document.createElement(&quot;li&quot;);
    el.innerText = todo.name;
    todoContainer.appendChild(el);
  });
&lt;/script&gt;

</code></pre>
<p></p>
<p>Our static page can take in <code>window.todos</code>, and render HTML based on it, but we haven’t actually passed in any data from KV. To do this, we’ll need to make a couple changes.</p>
<p>First, our <code>html</code> <em>variable</em> will change to a <em>function</em>. The function will take in an argument, <code>todos</code>, which will populate the <code>window.todos</code> variable in the above code sample:</p>
</p>
<p></p>
<pre><code class="language-javascript">const html = todos =&gt; `
&lt;!doctype html&gt;
&lt;html&gt;
  &lt;!-- ... --&gt;
  &lt;script&gt;
    window.todos = ${todos || []}
    var todoContainer = document.querySelector(&quot;#todos&quot;);
    // ...
  &lt;script&gt;
&lt;/html&gt;
`
</code></pre>
<p></p>
<p>In <code>handleRequest</code>, we can use the retrieved KV data to call the <code>html</code> function, and generate a <code>Response</code> based on it:</p>
</p>
<p></p>
<pre><code class="language-javascript">async function handleRequest(request) {
  let data;
  
  // Set data using cache or defaultData from previous section...
  
  const body = html(JSON.stringify(data.todos))
  const response = new Response(body, {
    headers: { 'Content-Type': 'text/html' }
  })
  return response
}
</code></pre>
<p></p>
<p>The finished product looks something like this:</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image3-3.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<h3 id="adding-todos-from-the-ui">Adding todos from the UI</h3>
<p>At this point, we’ve built a Cloudflare Worker that takes data from Cloudflare KV and renders a static page based on it. That static page reads the data, and generates a todo list based on that data. Of course, the piece we’re missing is <em>creating</em> todos, from inside the UI. We know that we can add todos using the KV API &#8211; we could simply update the cache by saying <code>KRISTIAN_TODOS.put(newData)</code>, but how do we update it from inside the UI?</p>
<p>It’s worth noting here that Cloudflare’s Workers documentation suggests that any writes to your KV namespace happen via their API &#8211; that is, at its simplest form, a cURL statement:</p>
</p>
<p></p>
<pre><code class="language-javascript">curl &quot;&lt;https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/storage/kv/namespaces/$NAMESPACE_ID/values/first-key&gt;&quot; \
  -X PUT \
  -H &quot;X-Auth-Email: $CLOUDFLARE_EMAIL&quot; \
  -H &quot;X-Auth-Key: $CLOUDFLARE_AUTH_KEY&quot; \
  --data 'My first value!'
</code></pre>
<p></p>
<p>We’ll implement something similar by handling a second route in our worker, designed to watch for <code>PUT</code> requests to <code>/</code>. When a body is received at that URL, the worker will send the new todo data to our KV store.</p>
<p>I’ll add this new functionality to my worker, and in <code>handleRequest</code>, if the request method is a <code>PUT</code>, it will take the request body and update the cache:</p>
</p>
<p></p>
<pre><code class="language-javascript">addEventListener('fetch', event =&gt; {
  event.respondWith(handleRequest(event.request))
})

const putInCache = body =&gt; {
  const accountId = &quot;$accountId&quot;
  const namespaceId = &quot;$namespaceId&quot;
  const key = &quot;data&quot;
  return fetch(
    `https://api.cloudflare.com/client/v4/accounts/${accountId}/storage/kv/namespaces/${namespaceId}/values/${key}`,
    { 
      method: &quot;PUT&quot;,
      body,
      headers: { 
        'X-Auth-Email': '$accountEmail',
        'X-Auth-Key': &quot;$authKey&quot;
      }
    }
  )
}

async function updateTodos(request) {
  const body = await request.text()
  const ip = request.headers.get(&quot;CF-Connecting-IP&quot;)
  const cacheKey = `data-${ip}`;
  try {
    JSON.parse(body)
    await putInCache(cacheKey, body)
    return new Response(body, { status: 200 })
  } catch (err) {
    return new Response(err, { status: 500 })
  }
}

async function handleRequest(request) {
  if (request.method === &quot;PUT&quot;) {
    return updateTodos(request);
  } else {
    // Defined in previous code block
    return getTodos(request);
  }
}
</code></pre>
<p></p>
<p>The script is pretty straightforward &#8211; we check that the request is a <code>PUT</code>, and wrap the remainder of the code in a <code>try/catch</code> block. First, we parse the body of the request coming in, ensuring that it is JSON, before we update the cache with the new data, and return it to the user. If anything goes wrong, we simply return a 500. If the route is hit with an HTTP method <em>other</em> than <code>PUT</code> &#8211; that is, <code>GET</code>, <code>DELETE</code>, or anything else &#8211; we return a 404.</p>
<p>With this script, we can now add some “dynamic” functionality to our HTML page to actually hit this route.</p>
<p>First, we’ll create an input for our todo “name”, and a button for “submitting” the todo.</p>
</p>
<p></p>
<pre><code class="language-html">&lt;div&gt;
  &lt;input type=&quot;text&quot; name=&quot;name&quot; placeholder=&quot;A new todo&quot;&gt;&lt;/input&gt;
  &lt;button id=&quot;create&quot;&gt;Create&lt;/button&gt;
&lt;/div&gt;
</code></pre>
<p></p>
<p>Given that input and button, we can add a corresponding JavaScript function to watch for clicks on the button &#8211; once the button is clicked, the browser will <code>PUT</code> to <code>/</code> and submit the todo.</p>
</p>
<p></p>
<pre><code class="language-javascript">var createTodo = function() {
  var input = document.querySelector(&quot;input[name=name]&quot;);
  if (input.value.length) {
    fetch(&quot;/&quot;, { 
      method: 'PUT', 
      body: JSON.stringify({ todos: todos }) 
    });
  }
};

document.querySelector(&quot;#create&quot;)
  .addEventListener('click', createTodo);
</code></pre>
<p></p>
<p>This code updates the cache, but what about our local UI? Remember that the KV cache is <em>eventually consistent</em> &#8211; even if we were to update our worker to read from the cache and return it, we have no guarantees it’ll actually be up-to-date. Instead, let’s just update the list of todos locally, by taking our original code for rendering the todo list, making it a re-usable function called <code>populateTodos</code>, and calling it when the page loads <em>and</em> when the cache request has finished:</p>
</p>
<p></p>
<pre><code class="language-javascript">var populateTodos = function() {
  var todoContainer = document.querySelector(&quot;#todos&quot;);
  todoContainer.innerHTML = null;
  window.todos.forEach(todo =&gt; {
    var el = document.createElement(&quot;li&quot;);
    el.innerText = todo.name;
    todoContainer.appendChild(el);
  });
};

populateTodos();

var createTodo = function() {
  var input = document.querySelector(&quot;input[name=name]&quot;);
  if (input.value.length) {
    todos = [].concat(todos, { 
      id: todos.length + 1, 
      name: input.value,
      completed: false,
    });
    fetch(&quot;/&quot;, { 
      method: 'PUT', 
      body: JSON.stringify({ todos: todos }) 
    });
    populateTodos();
    input.value = &quot;&quot;;
  }
};

document.querySelector(&quot;#create&quot;)
  .addEventListener('click', createTodo);
</code></pre>
<p></p>
<p>With the client-side code in place, deploying the new Worker should put all these pieces together. The result is an actual dynamic todo list!</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image7.gif" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<h3 id="updating-todos-from-the-ui">Updating todos from the UI</h3>
<p>For the final piece of our (very) basic todo list, we need to be able to update todos &#8211; specifically, marking them as completed.</p>
<p>Luckily, a great deal of the infrastructure for this work is already in place. We can currently update the todo list data in our cache, as evidenced by our <code>createTodo</code> function. Performing updates on a todo, in fact, is much more of a client-side task than a Worker-side one!</p>
<p>To start, let’s update the client-side code for generating a todo. Instead of a <code>ul</code>-based list, we’ll migrate the todo container <em>and</em> the todos themselves into using <code>div</code>s:</p>
</p>
<p></p>
<pre><code class="language-html">&lt;!-- &lt;ul id=&quot;todos&quot;&gt;&lt;/ul&gt; becomes... --&gt;
&lt;div id=&quot;todos&quot;&gt;&lt;/div&gt;
</code></pre>
<p></p>
<p>The <code>populateTodos</code> function can be updated to generate a <code>div</code> for each todo. In addition, we’ll move the name of the todo into a child element of that <code>div</code>:</p>
</p>
<p></p>
<pre><code class="language-javascript">var populateTodos = function() {
  var todoContainer = document.querySelector(&quot;#todos&quot;);
  todoContainer.innerHTML = null;
  window.todos.forEach(todo =&gt; {
    var el = document.createElement(&quot;div&quot;);
    var name = document.createElement(&quot;span&quot;);
    name.innerText = todo.name;
    el.appendChild(name);
    todoContainer.appendChild(el);
  });
}
</code></pre>
<p></p>
<p>So far, we’ve designed the client-side part of this code to take an array of todos in, and given that array, render out a list of simple HTML elements. There’s a number of things that we’ve been doing that we haven’t quite had a use for, yet: specifically, the inclusion of IDs, and updating the completed value on a todo. Luckily, these things work well together, in order to support actually updating todos in the UI.</p>
<p>To start, it would be useful to signify the ID of each todo in the HTML. By doing this, we can then refer to the element later, in order to correspond it to the todo in the JavaScript part of our code. <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/dataset"><em>Data attributes</em></a>, and the corresponding dataset method in JavaScript, are a perfect way to implement this. When we generate our <code>div</code> element for each todo, we can simply attach a data attribute called <code>todo</code> to each <code>div</code>:</p>
</p>
<p></p>
<pre><code class="language-javascript">window.todos.forEach(todo =&gt; {
  var el = document.createElement(&quot;div&quot;);
  el.dataset.todo = todo.id
  // ... more setup

  todoContainer.appendChild(el);
});
</code></pre>
<p></p>
<p>Inside our HTML, each <code>div</code> for a todo now has an attached data attribute, which looks like:</p>
</p>
<p></p>
<pre><code class="language-html">&lt;div data-todo=&quot;1&quot;&gt;&lt;/div&gt;
&lt;div data-todo=&quot;2&quot;&gt;&lt;/div&gt;
</code></pre>
<p></p>
<p>Now we can generate a checkbox for each todo element. This checkbox will default to unchecked for new todos, of course, but we can mark it as checked as the element is rendered in the window:</p>
</p>
<p></p>
<pre><code class="language-javascript">window.todos.forEach(todo =&gt; {
  var el = document.createElement(&quot;div&quot;);
  el.dataset.todo = todo.id
  
  var name = document.createElement(&quot;span&quot;);
  name.innerText = todo.name;
  
  var checkbox = document.createElement(&quot;input&quot;)
  checkbox.type = &quot;checkbox&quot;
  checkbox.checked = todo.completed ? 1 : 0;

  el.appendChild(checkbox);
  el.appendChild(name);
  todoContainer.appendChild(el);
})
</code></pre>
<p></p>
<p>The checkbox is set up to correctly reflect the value of completed on each todo, but it doesn’t yet update when we actually check the box! To do this, we’ll add an event listener on the <code>click</code> event, calling <code>completeTodo</code>. Inside the function, we’ll inspect the checkbox element, finding its parent (the todo <code>div</code>), and using the <code>todo</code> data attribute on it to find the corresponding todo in our data. Given that todo, we can toggle the value of completed, update our data, and re-render the UI:</p>
</p>
<p></p>
<pre><code class="language-javascript">var completeTodo = function(evt) {
  var checkbox = evt.target;
  var todoElement = checkbox.parentNode;
  
  var newTodoSet = [].concat(window.todos)
  var todo = newTodoSet.find(t =&gt; 
    t.id == todoElement.dataset.todo
  );
  todo.completed = !todo.completed;
  todos = newTodoSet;
  updateTodos()
}
</code></pre>
<p></p>
<p>The final result of our code is a system that simply checks the <code>todos</code> variable, updates our Cloudflare KV cache with that value, and then does a straightforward re-render of the UI based on the data it has locally.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image8-1.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<h3 id="conclusions-and-next-steps">Conclusions and next steps</h3>
<p>With this, we’ve created a pretty remarkable project: an almost entirely static HTML/JS application, transparently powered by Cloudflare KV and Workers, served at the edge. There’s a number of additions to be made to this application, whether you want to implement a better design (I’ll leave this as an exercise for readers to implement &#8211; you can see my version at <a href="https://todo.kristianfreeman.com/">todo.kristianfreeman.com</a>), security, speed, etc.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image2-1.png" class="kg-image" alt="Building a To-Do List with Workers and KV"></figure>
<p></p>
<p>One interesting and fairly trivial addition is implementing per-user caching. Of course, right now, the cache key is simply “data”: anyone visiting the site will share a todo list with any other user. Because we have the request information inside of our worker, it’s easy to make this data user-specific. For instance, implementing per-user caching by generating the cache key based on the requesting IP:</p>
</p>
<p></p>
<pre><code class="language-javascript">const ip = request.headers.get(&quot;CF-Connecting-IP&quot;)
const cacheKey = `data-${ip}`;
const getCache = key =&gt; KRISTIAN_TODOS.get(key)
getCache(cacheKey)
</code></pre>
<p></p>
<p>One more deploy of our Workers project, and we have a full todo list application, with per-user functionality, served at the edge!</p>
<p>The final version of our Workers script looks like this:</p>
</p>
<p></p>
<pre><code class="language-javascript">const html = todos =&gt; `
&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot;&gt;
    &lt;title&gt;Todos&lt;/title&gt;
    &lt;link href=&quot;https://cdn.jsdelivr.net/npm/tailwindcss/dist/tailwind.min.css&quot; rel=&quot;stylesheet&quot;&gt;&lt;/link&gt;
  &lt;/head&gt;

  &lt;body class=&quot;bg-blue-100&quot;&gt;
    &lt;div class=&quot;w-full h-full flex content-center justify-center mt-8&quot;&gt;
      &lt;div class=&quot;bg-white shadow-md rounded px-8 pt-6 py-8 mb-4&quot;&gt;
        &lt;h1 class=&quot;block text-grey-800 text-md font-bold mb-2&quot;&gt;Todos&lt;/h1&gt;
        &lt;div class=&quot;flex&quot;&gt;
          &lt;input class=&quot;shadow appearance-none border rounded w-full py-2 px-3 text-grey-800 leading-tight focus:outline-none focus:shadow-outline&quot; type=&quot;text&quot; name=&quot;name&quot; placeholder=&quot;A new todo&quot;&gt;&lt;/input&gt;
          &lt;button class=&quot;bg-blue-500 hover:bg-blue-800 text-white font-bold ml-2 py-2 px-4 rounded focus:outline-none focus:shadow-outline&quot; id=&quot;create&quot; type=&quot;submit&quot;&gt;Create&lt;/button&gt;
        &lt;/div&gt;
        &lt;div class=&quot;mt-4&quot; id=&quot;todos&quot;&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;

  &lt;script&gt;
    window.todos = ${todos || []}

    var updateTodos = function() {
      fetch(&quot;/&quot;, { method: 'PUT', body: JSON.stringify({ todos: window.todos }) })
      populateTodos()
    }

    var completeTodo = function(evt) {
      var checkbox = evt.target
      var todoElement = checkbox.parentNode
      var newTodoSet = [].concat(window.todos)
      var todo = newTodoSet.find(t =&gt; t.id == todoElement.dataset.todo)
      todo.completed = !todo.completed
      window.todos = newTodoSet
      updateTodos()
    }

    var populateTodos = function() {
      var todoContainer = document.querySelector(&quot;#todos&quot;)
      todoContainer.innerHTML = null

      window.todos.forEach(todo =&gt; {
        var el = document.createElement(&quot;div&quot;)
        el.className = &quot;border-t py-4&quot;
        el.dataset.todo = todo.id

        var name = document.createElement(&quot;span&quot;)
        name.className = todo.completed ? &quot;line-through&quot; : &quot;&quot;
        name.innerText = todo.name

        var checkbox = document.createElement(&quot;input&quot;)
        checkbox.className = &quot;mx-4&quot;
        checkbox.type = &quot;checkbox&quot;
        checkbox.checked = todo.completed ? 1 : 0
        checkbox.addEventListener('click', completeTodo)

        el.appendChild(checkbox)
        el.appendChild(name)
        todoContainer.appendChild(el)
      })
    }

    populateTodos()

    var createTodo = function() {
      var input = document.querySelector(&quot;input[name=name]&quot;)
      if (input.value.length) {
        window.todos = [].concat(todos, { id: window.todos.length + 1, name: input.value, completed: false })
        input.value = &quot;&quot;
        updateTodos()
      }
    }

    document.querySelector(&quot;#create&quot;).addEventListener('click', createTodo)
  &lt;/script&gt;
&lt;/html&gt;
`

const defaultData = { todos: [] }

const setCache = (key, data) =&gt; KRISTIAN_TODOS.put(key, data)
const getCache = key =&gt; KRISTIAN_TODOS.get(key)

async function getTodos(request) {
  const ip = request.headers.get('CF-Connecting-IP')
  const cacheKey = `data-${ip}`
  let data
  const cache = await getCache(cacheKey)
  if (!cache) {
    await setCache(cacheKey, JSON.stringify(defaultData))
    data = defaultData
  } else {
    data = JSON.parse(cache)
  }
  const body = html(JSON.stringify(data.todos || []))
  return new Response(body, {
    headers: { 'Content-Type': 'text/html' },
  })
}

const putInCache = (cacheKey, body) =&gt; {
  const accountId = '$accountId'
  const namespaceId = '$namespaceId'
  return fetch(
    `https://api.cloudflare.com/client/v4/accounts/${accountId}/storage/kv/namespaces/${namespaceId}/values/${cacheKey}`,
    {
      method: 'PUT',
      body,
      headers: {
        'X-Auth-Email': '$cloudflareEmail',
        'X-Auth-Key': '$cloudflareApiKey',
      },
    },
  )
}

async function updateTodos(request) {
  const body = await request.text()
  const ip = request.headers.get('CF-Connecting-IP')
  const cacheKey = `data-${ip}`
  try {
    JSON.parse(body)
    await putInCache(cacheKey, body)
    return new Response(body, { status: 200 })
  } catch (err) {
    return new Response(err, { status: 500 })
  }
}

async function handleRequest(request) {
  if (request.method === 'PUT') {
    return updateTodos(request)
  } else {
    return getTodos(request)
  }
}

addEventListener('fetch', event =&gt; {
  event.respondWith(handleRequest(event.request))
})
</code></pre>
<p></p>
<p>You can find the source code for this project, as well as a README with deployment instructions, on <a href="https://github.com/signalnerve/cloudflare-workers-todos">GitHub</a>.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/javascript/" rel="tag">javascript</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/serverless/" rel="tag">serverless</a><a href="https://noise.getoto.net/tag/workers/" rel="tag">Workers</a><a href="https://noise.getoto.net/tag/workers-kv/" rel="tag">Workers KV</a></span></footer></article>
<article id="post-659016" class="post-659016 post type-post status-publish format-standard hentry tag-bash tag-javascript tag-product-news tag-programming tag-serverless tag-workers tag-workers-kv">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/05/21/get-ready-to-write-workers-kv-is-now-in-ga/" rel="bookmark">Get ready to write — Workers KV is now in GA!</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/05/21/get-ready-to-write-workers-kv-is-now-in-ga/" rel="bookmark"><time class="entry-date" datetime="2019-05-21T16:00:00+03:00">2019-05-21</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/ashcon-partovi/" rel="author">Ashcon Partovi</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Ashcon Partovi">Ashcon Partovi</a> original <a href="https://blog.cloudflare.com/workers-kv-is-ga/">https://blog.cloudflare.com/workers-kv-is-ga/</a></p>
<p><img src="https://blog.cloudflare.com/content/images/2019/05/Workers-KV-GA@2x-1.png" alt="Get ready to write — Workers KV is now in GA!"></p>
<p>Today, we’re excited to announce Workers KV is entering general availability and is ready for production use!</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/Workers-KV-GA@2x.png" class="kg-image" alt="Get ready to write — Workers KV is now in GA!"></figure>
<p></p>
<h3 id="what-is-workers-kv">What is Workers KV?</h3>
<p><a href="https://www.cloudflare.com/products/workers-kv/">Workers KV</a> is a highly distributed, eventually consistent, key-value store that spans Cloudflare&#8217;s global edge. It allows you to store billions of key-value pairs and read them with ultra-low latency anywhere in the world. Now you can build entire applications with the performance of a CDN static cache.</p>
<h3 id="why-did-we-build-it">Why did we build it?</h3>
<p><a href="https://www.cloudflare.com/products/cloudflare-workers/">Workers</a> is a platform that lets you run JavaScript on Cloudflare&#8217;s global edge of 175+ data centers. With only a few lines of code, you can route HTTP requests, modify responses, or even create new responses without an origin server.</p>
</p>
<p></p>
<pre><code class="language-javascript">// A Worker that handles a single redirect,
// such a humble beginning...
addEventListener(&quot;fetch&quot;, event =&gt; {
  event.respondWith(handleOneRedirect(event.request))
})

async function handleOneRedirect(request) {
  let url = new URL(request.url)
  let device = request.headers.get(&quot;CF-Device-Type&quot;)
  // If the device is mobile, add a prefix to the hostname.
  // (eg. example.com becomes mobile.example.com)
  if (device === &quot;mobile&quot;) {
    url.hostname = &quot;mobile.&quot; + url.hostname
    return Response.redirect(url, 302)
  }
  // Otherwise, send request to the original hostname.
  return await fetch(request)
}
</code></pre>
<p></p>
<p>Customers quickly came to us with use cases that required a way to store persistent data. Following our example above, it&#8217;s easy to handle a single redirect, but what if you want to handle <strong><strong>billions</strong></strong> of them? You would have to hard-code them into your Workers script, fit it all in under 1 MB, and re-deploy it every time you wanted to make a change — yikes! That’s why we built Workers KV.</p>
</p>
<p></p>
<pre><code class="language-javascript">// A Worker that can handle billions of redirects,
// now that's more like it!
addEventListener(&quot;fetch&quot;, event =&gt; {
  event.respondWith(handleBillionsOfRedirects(event.request))
})

async function handleBillionsOfRedirects(request) {
  let prefix = &quot;/redirect&quot;
  let url = new URL(request.url)
  // Check if the URL is a special redirect.
  // (eg. example.com/redirect/&lt;random-hash&gt;)
  if (url.pathname.startsWith(prefix)) {
    // REDIRECTS is a custom variable that you define,
    // it binds to a Workers KV &quot;namespace.&quot; (aka. a storage bucket)
    let redirect = await REDIRECTS.get(url.pathname.replace(prefix, &quot;&quot;))
    if (redirect) {
      url.pathname = redirect
      return Response.redirect(url, 302)
    }
  }
  // Otherwise, send request to the original path.
  return await fetch(request)
}
</code></pre>
<p></p>
<p>With only a few changes from our previous example, we scaled from one redirect to billions − that&#8217;s just a taste of what you can build with Workers KV.</p>
<h3 id="how-does-it-work">How does it work?</h3>
<p>Distributed data stores are often modeled using the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP Theorem</a>, which states that distributed systems can only pick between <strong><strong>2 out of the 3</strong> </strong>following guarantees:</p>
<ul>
<li><strong><strong>C</strong></strong>onsistency &#8211; is my data the same everywhere?</li>
<li><strong><strong>A</strong></strong>vailability &#8211; is my data accessible all the time?</li>
<li><strong><strong>P</strong></strong>artition tolerance &#8211; is my data stored in multiple locations?</li>
</ul>
<p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cloudflare.com/content/images/2019/05/workers-kv-venn-diagram@2x.png" class="kg-image" alt="Get ready to write — Workers KV is now in GA!"><figcaption>Diagram of the choices and tradeoffs of the CAP Theorem.</figcaption></figure>
<p></p>
<p>Workers KV chooses to guarantee <strong><strong>A</strong></strong>vailability and <strong><strong>P</strong></strong>artition tolerance. This combination is known as <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a>, which presents Workers KV with two unique competitive advantages:</p>
<ul>
<li>Reads are ultra fast (median of 12 ms) since its powered by our caching technology.</li>
<li>Data is available across 175+ edge data centers and resilient to regional outages.</li>
</ul>
<p>Although, there are tradeoffs to eventual consistency. If two clients write different values to the same key at the same time, the last client to write <em><em>eventually</em> </em>&#8220;wins&#8221; and its value becomes globally consistent. This also means that if a client writes to a key and that same client reads that same key, the values may be inconsistent for a short amount of time.</p>
<p>To help visualize this scenario, here&#8217;s a real-life example amongst three friends:</p>
<ul>
<li>Suppose Matthew, Michelle, and Lee are planning their weekly lunch.</li>
<li>Matthew decides they&#8217;re going out for sushi.</li>
<li>Matthew tells Michelle their sushi plans, Michelle agrees.</li>
<li>Lee, not knowing the plans, tells Michelle they&#8217;re actually having pizza.</li>
</ul>
<p>An hour later, Michelle and Lee are waiting at the pizza parlor while Matthew is sitting alone at the sushi restaurant — what went wrong? We can chalk this up to eventual consistency, because after waiting for a few minutes, Matthew looks at his updated calendar and <em><em>eventually</em></em> finds the new truth, they&#8217;re going out for pizza instead.</p>
<p>While it may take minutes in real-life, Workers KV is much faster. It can achieve global consistency in less than 60 seconds. Additionally, when a Worker writes to a key, then <em><em>immediately</em></em> reads that same key, it can expect the values to be consistent if both operations came from the same location.</p>
<h3 id="when-should-i-use-it">When should I use it?</h3>
<p>Now that you understand the benefits and tradeoffs of using eventual consistency, how do you determine if it&#8217;s the right storage solution for your application? Simply put, if you want global availability with ultra-fast reads, Workers KV is right for you.</p>
<p>However, if your application is<strong><strong> frequently</strong></strong> writing to the <strong><strong>same</strong></strong> key, there is an additional consideration. We call it &#8220;the Matthew question&#8221;: Are you okay with the Matthews of the world <em><em>occasionally</em></em> going to the wrong restaurant?</p>
<p>You can imagine use cases (like our redirect Worker example) where this doesn&#8217;t make any material difference. But if you decide to keep track of a user’s bank account balance, you would not want the possibility of two balances existing at once, since they could purchase something with money they’ve already spent.</p>
<h3 id="what-can-i-build-with-it">What can I build with it?</h3>
<p>Here are a few examples of applications that have been built with KV:</p>
<ul>
<li>Mass redirects &#8211; handle billions of HTTP redirects.</li>
<li>User authentication &#8211; validate user requests to your API.</li>
<li>Translation keys &#8211; dynamically localize your web pages.</li>
<li>Configuration data &#8211; manage who can access your origin.</li>
<li>Step functions &#8211; sync state data between multiple APIs functions.</li>
<li>Edge file store &#8211; host large amounts of small files.</li>
</ul>
<p>We’ve highlighted several of those use cases in our previous <a href="https://blog.cloudflare.com/building-with-workers-kv/">blog post</a>. We also have some more in-depth code walkthroughs, including a recently published blog post on how to build an online <a href="https://blog.cloudflare.com/p/e0dc6485-1d00-45fd-8a20-ec255a66c6aa/">To-do list with Workers KV.</a></p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://i.imgur.com/GQ4hrfQ.png" class="kg-image" alt="Get ready to write — Workers KV is now in GA!"></figure>
<p></p>
<h3 id="what-s-new-since-beta">What&#8217;s new since beta?</h3>
<p>By far, our most common request was to make it easier to write data to Workers KV. That&#8217;s why we&#8217;re releasing three new ways to make that experience even better:</p>
<h4 id="1-bulk-writes">1. Bulk Writes</h4>
<p>If you want to import your existing data into Workers KV, you don&#8217;t want to go through the hassle of sending an HTTP request for <em><em>every</em></em> key-value pair. That&#8217;s why we added a <a href="https://api.cloudflare.com/#workers-kv-namespace-write-multiple-key-value-pairs">bulk endpoint</a> to the Cloudflare API. Now you can upload up to 10,000 pairs (up to 100 MB of data) in a single PUT request.</p>
</p>
<p></p>
<pre><code class="language-bash">curl &quot;https://api.cloudflare.com/client/v4/accounts/ \
     $ACCOUNT_ID/storage/kv/namespaces/$NAMESPACE_ID/bulk&quot; \
  -X PUT \
  -H &quot;X-Auth-Key: $CLOUDFLARE_AUTH_KEY&quot; \
  -H &quot;X-Auth-Email: $CLOUDFLARE_AUTH_EMAIL&quot; \
  -d '[
    {&quot;key&quot;: &quot;built_by&quot;,    value: &quot;kyle, alex, charlie, andrew, and brett&quot;},
    {&quot;key&quot;: &quot;reviewed_by&quot;, value: &quot;joaquin&quot;},
    {&quot;key&quot;: &quot;approved_by&quot;, value: &quot;steve&quot;}
  ]'
</code></pre>
<p></p>
<p>Let&#8217;s walk through an example use case: you want to off-load your website translation to Workers. Since you&#8217;re reading translation keys frequently and only occasionally updating them, this application works well with the eventual consistency model of Workers KV.</p>
<p>In this example, we hook into <a href="https://crowdin.com/">Crowdin</a>, a popular platform to manage translation data. This Worker responds to a <code>/translate</code> endpoint, downloads all your translation keys, and bulk writes them to Workers KV so you can read it later on our edge:</p>
</p>
<p></p>
<pre><code class="language-js">addEventListener(&quot;fetch&quot;, event =&gt; {
  if (event.request.url.pathname === &quot;/translate&quot;) {
    event.respondWith(uploadTranslations())
  }
})

async function uploadTranslations() {
  // Ask crowdin for all of our translations.
  var response = await fetch(
    &quot;https://api.crowdin.com/api/project&quot; +
    &quot;/:ci_project_id/download/all.zip?key=:ci_secret_key&quot;)
  // If crowdin is responding, parse the response into
  // a single json with all of our translations.
  if (response.ok) {
    var translations = await zipToJson(response)
    return await bulkWrite(translations)
  }
  // Return the errored response from crowdin.
  return response
}

async function bulkWrite(keyValuePairs) {
  return fetch(
    &quot;https://api.cloudflare.com/client/v4/accounts&quot; +
    &quot;/:cf_account_id/storage/kv/namespaces/:cf_namespace_id/bulk&quot;,
    {
      method: &quot;PUT&quot;,
      headers: {
        &quot;Content-Type&quot;: &quot;application/json&quot;,
        &quot;X-Auth-Key&quot;: &quot;:cf_auth_key&quot;,
        &quot;X-Auth-Email&quot;: &quot;:cf_email&quot;
      },
      body: JSON.stringify(keyValuePairs)
    }
  )
}

async function zipToJson(response) {
  // ... omitted for brevity ...
  // (eg. https://stuk.github.io/jszip)
  return [
    {key: &quot;hello.EN&quot;, value: &quot;Hello World&quot;},
    {key: &quot;hello.ES&quot;, value: &quot;Hola Mundo&quot;}
  ]
}
</code></pre>
<p></p>
<p>Now, when you want to translate a page, all you have to do is read from Workers KV:</p>
</p>
<p></p>
<pre><code class="language-javascript">async function translate(keys, lang) {
  // You bind your translations namespace to the TRANSLATIONS variable.
  return Promise.all(keys.map(key =&gt; TRANSLATIONS.get(key + &quot;.&quot; + lang)))
}
</code></pre>
<p></p>
<h4 id="2-expiring-keys">2. Expiring Keys</h4>
<p>By default, key-value pairs stored in Workers KV last forever. However, sometimes you want your data to auto-delete after a certain amount of time. That&#8217;s why we&#8217;re introducing the <code>expiration</code> and <code>expirationTtl</code>options for write operations.</p>
</p>
<p></p>
<pre><code class="language-javascript">// Key expires 60 seconds from now.
NAMESPACE.put(&quot;myKey&quot;, &quot;myValue&quot;, {expirationTtl: 60})

// Key expires if the UNIX epoch is in the past.
NAMESPACE.put(&quot;myKey&quot;, &quot;myValue&quot;, {expiration: 1247788800})
</code></pre>
<p></p>
<p></p>
<pre><code class="language-bash"># You can also set keys to expire from the Cloudflare API.
curl &quot;https://api.cloudflare.com/client/v4/accounts/ \
     $ACCOUNT_ID/storage/kv/namespaces/$NAMESPACE_ID/ \
     values/$KEY?expiration_ttl=$EXPIRATION_IN_SECONDS&quot;
  -X PUT \
  -H &quot;X-Auth-Key: $CLOUDFLARE_AUTH_KEY&quot; \
  -H &quot;X-Auth-Email: $CLOUDFLARE_AUTH_EMAIL&quot; \
  -d &quot;$VALUE&quot;
</code></pre>
<p></p>
<p>Let&#8217;s say you want to block users that have been flagged as inappropriate from your website, but only for a week. With an expiring key, you can set the expire time and not have to worry about deleting it later.</p>
<p>In this example, we assume users and IP addresses are one of the same. If your application has authentication, you could use access tokens as the key identifier.</p>
</p>
<p></p>
<pre><code class="language-javascript">addEventListener(&quot;fetch&quot;, event =&gt; {
  var url = new URL(event.request.url)
  // An internal API that blocks a new user IP.
  // (eg. example.com/block/1.2.3.4)
  if (url.pathname.startsWith(&quot;/block&quot;)) {
    var ip = url.pathname.split(&quot;/&quot;).pop()
    event.respondWith(blockIp(ip))
  } else {
    // Other requests check if the IP is blocked.
   event.respondWith(handleRequest(event.request))
  }
})

async function blockIp(ip) {
  // Values are allowed to be empty in KV,
  // we don't need to store any extra information anyway.
  await BLOCKED.put(ip, &quot;&quot;, {expirationTtl: 60*60*24*7})
  return new Response(&quot;ok&quot;)
}

async function handleRequest(request) {
  var ip = request.headers.get(&quot;CF-Connecting-IP&quot;)
  if (ip) {
    var blocked = await BLOCKED.get(ip)
    // If we detect an IP and its blocked, respond with a 403 error.
    if (blocked) {
      return new Response({status: 403, statusText: &quot;You are blocked!&quot;})
    }
  }
  // Otherwise, passthrough the original request.
  return fetch(request)
}
</code></pre>
<p></p>
<h4 id="3-larger-values">3. Larger Values</h4>
<p>We&#8217;ve increased our size limit on values from <code>64 kB</code> to <code>2 MB</code>. This is quite useful if you need to store buffer-based or file data in Workers KV.</p>
</p>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/workers-kc-file-size-update@2x.png" class="kg-image" alt="Get ready to write — Workers KV is now in GA!"></figure>
<p></p>
<p>Consider this scenario: you want to let your users upload their favorite GIF to their profile without having to store these GIFs as binaries in your database or managing <em><em>another</em></em> cloud storage bucket.</p>
<p>Workers KV is a great fit for this use case! You can create a Workers KV namespace for your users’ GIFs that is fast and reliable wherever your customers are located.</p>
<p>In this example, users upload a link to their favorite GIF, then a Worker downloads it and stores it to Workers KV.</p>
</p>
<p></p>
<pre><code class="language-javascript">addEventListener(&quot;fetch&quot;, event =&gt; {
  var url = event.request.url
  var arg = request.url.split(&quot;/&quot;).pop()
  // User sends a URI encoded link to the GIF they wish to upload.
  // (eg. example.com/api/upload_gif/&lt;encoded-uri&gt;)
  if (url.pathname.startsWith(&quot;/api/upload_gif&quot;)) {
    event.respondWith(uploadGif(arg))
    // Profile contains link to view the GIF.
    // (eg. example.com/api/view_gif/&lt;username&gt;)
  } else if (url.pathname.startsWith(&quot;/api/view_gif&quot;)) {
    event.respondWith(getGif(arg))
  }
})

async function uploadGif(url) {
  // Fetch the GIF from the Internet.
  var gif = await fetch(decodeURIComponent(url))
  var buffer = await gif.arrayBuffer()
  // Upload the GIF as a buffer to Workers KV.
  await GIFS.put(user.name, buffer)
  return gif
}

async function getGif(username) {
  var gif = await GIFS.get(username, &quot;arrayBuffer&quot;)
  // If the user has set one, respond with the GIF.
  if (gif) {
    return new Response(gif, {headers: {&quot;Content-Type&quot;: &quot;image/gif&quot;}})
  } else {
    return new Response({status: 404, statusText: &quot;User has no GIF!&quot;})
  }
}
</code></pre>
<p></p>
<p>Lastly, we want to thank all of our beta customers. It was your valuable feedback that led us to develop these changes to Workers KV. Make sure to stay in touch with us, we&#8217;re always looking ahead for what&#8217;s next and we love hearing from you!</p>
<h3 id="pricing">Pricing</h3>
<p>We’re also ready to announce our GA pricing. If you&#8217;re one of our Enterprise customers, your pricing obviously remains unchanged.</p>
<ul>
<li>$0.50 / GB of data stored, 1 GB included</li>
<li>$0.50 / million reads, 10 million included</li>
<li>$5 / million write, list, and delete operations, 1 million included</li>
</ul>
<p>During the beta period, we learned customers don&#8217;t want to just read values at our edge, they want to write values from our edge too. Since there is high demand for these edge operations, which are more costly, we have started charging non-read operations per month.</p>
<h3 id="limits">Limits</h3>
<p>As mentioned earlier, we increased our value size limit from <code>64 kB</code> to <code>2 MB</code>. We&#8217;ve also removed our cap on the number of keys per namespace — it&#8217;s now unlimited. Here are our GA limits:</p>
<ul>
<li>Up to 20 namespaces per account, each with unlimited keys</li>
<li>Keys of up to 512 bytes and values of up to 2 MB</li>
<li>Unlimited writes per second for different keys</li>
<li>One write per second for the same key</li>
<li>Unlimited reads per second per key</li>
</ul>
<h3 id="try-it-out-now-">Try it out now!</h3>
<p>Now open to all customers, you can start using <a href="https://www.cloudflare.com/products/workers-kv/">Workers KV</a> today from your Cloudflare dashboard under the Workers tab. You can also look at our updated <a href="https://developers.cloudflare.com/workers/kv/">documentation.</a></p>
<p>We&#8217;re really excited to see what you all can build with Workers KV!</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/bash/" rel="tag">bash</a><a href="https://noise.getoto.net/tag/javascript/" rel="tag">javascript</a><a href="https://noise.getoto.net/tag/product-news/" rel="tag">Product News</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/serverless/" rel="tag">serverless</a><a href="https://noise.getoto.net/tag/workers/" rel="tag">Workers</a><a href="https://noise.getoto.net/tag/workers-kv/" rel="tag">Workers KV</a></span></footer></article>
<article id="post-654969" class="post-654969 post type-post status-publish format-standard hentry tag-anycast tag-developers tag-ebpf tag-linux tag-programming tag-tcp">
<header class="entry-header">
<h1 class="entry-title"><a href="https://noise.getoto.net/2019/05/18/cloudflare-architecture-and-how-bpf-eats-the-world/" rel="bookmark">Cloudflare architecture and how BPF eats the world</a></h1>
<div class="entry-meta">
<span class="entry-date"><a href="https://noise.getoto.net/2019/05/18/cloudflare-architecture-and-how-bpf-eats-the-world/" rel="bookmark"><time class="entry-date" datetime="2019-05-18T18:00:00+03:00">2019-05-18</time></a></span> <span class="byline"><span class="author vcard"><a class="url fn n" href="https://noise.getoto.net/author/marek-majkowski/" rel="author">Marek Majkowski</a></span></span> </div>
</header>
<div class="entry-content">
<p class="syndicated-attribution">Post Syndicated from <a href="https://noise.getoto.net/author/0/" title="Read other posts by Marek Majkowski">Marek Majkowski</a> original <a href="https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/">https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/</a></p>
<p><img src="https://blog.cloudflare.com/content/images/2019/05/13_BPF-is-everywhere.jpg" alt="Cloudflare architecture and how BPF eats the world"></p>
<p>Recently at <a href="https://www.netdevconf.org/0x13/schedule.html">Netdev 0x13</a>, the Conference on Linux Networking in Prague, I gave <a href="https://netdevconf.org/0x13/session.html?panel-industry-perspectives">a short talk titled &#8220;Linux at Cloudflare&#8221;</a>. The <a href="https://speakerdeck.com/majek04/linux-at-cloudflare">talk</a> ended up being mostly about BPF. It seems, no matter the question &#8211; BPF is the answer.</p>
<p>Here is a transcript of a slightly adjusted version of that talk.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/01_edge-network-locations-100.jpg" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>At Cloudflare we run Linux on our servers. We operate two categories of data centers: large &#8220;Core&#8221; data centers, processing logs, analyzing attacks, computing analytics, and the &#8220;Edge&#8221; server fleet, delivering customer content from 180 locations across the world.</p>
<p>In this talk, we will focus on the &#8220;Edge&#8221; servers. It&#8217;s here where we use the newest Linux features, optimize for performance and care deeply about DoS resilience.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-9.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Our edge service is special due to our network configuration &#8211; we are extensively using anycast routing. Anycast means that the same set of IP addresses are announced by all our data centers.</p>
<p>This design has great advantages. First, it guarantees the optimal speed for end users. No matter where you are located, you will always reach the closest data center. Then, anycast helps us to spread out DoS traffic. During attacks each of the locations receives a small fraction of the total traffic, making it easier to ingest and filter out unwanted traffic.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/03_edge-network-uniform-software-100-1.jpg" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Anycast allows us to keep the networking setup uniform across all edge data centers. We applied the same design inside our data centers &#8211; our software stack is uniform across the edge servers. All software pieces are running on all the servers.</p>
<p>In principle, every machine can handle every task &#8211; and we run many diverse and demanding tasks. We have a full HTTP stack, the magical Cloudflare Workers, two sets of DNS servers &#8211; authoritative and resolver, and many other publicly facing applications like Spectrum and Warp.</p>
<p>Even though every server has all the software running, requests typically cross many machines on their journey through the stack. For example, an HTTP request might be handled by a different machine during each of the 5 stages of the processing.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-23.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Let me walk you through the early stages of inbound packet processing:</p>
<p>(1) First, the packets hit our router. The router does ECMP, and forwards packets onto our Linux servers. We use ECMP to spread each target IP across many, at least 16, machines. This is used as a rudimentary load balancing technique.</p>
<p>(2) On the servers we ingest packets with XDP eBPF. In XDP we perform two stages. First, we run volumetric DoS mitigations, dropping packets belonging to very large layer 3 attacks.</p>
<p>(3) Then, still in XDP, we perform layer 4 load balancing. All the non-attack packets are redirected across the machines. This is used to work around the ECMP problems, gives us fine-granularity load balancing and allows us to gracefully take servers out of service.</p>
<p>(4) Following the redirection the packets reach a designated machine. At this point they are ingested by the normal Linux networking stack, go through the usual iptables firewall, and are dispatched to an appropriate network socket.</p>
<p>(5) Finally packets are received by an application. For example HTTP connections are handled by a &#8220;protocol&#8221; server, responsible for performing TLS encryption and processing HTTP, HTTP/2 and QUIC protocols.</p>
<p>It&#8217;s in these early phases of request processing where we use the coolest new Linux features. We can group useful modern functionalities into three categories:</p>
<ul>
<li>DoS handling</li>
<li>Load balancing</li>
<li>Socket dispatch</li>
</ul>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-25.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Let&#8217;s discuss DoS handling in more detail. As mentioned earlier, the first step after ECMP routing is Linux&#8217;s XDP stack where, among other things, we run DoS mitigations.</p>
<p>Historically our mitigations for volumetric attacks were expressed in classic BPF and iptables-style grammar. Recently we adapted them to execute in the XDP eBPF context, which turned out to be surprisingly hard. Read on about our adventures:</p>
<ul>
<li><a href="https://blog.cloudflare.com/l4drop-xdp-ebpf-based-ddos-mitigations/">L4Drop: XDP DDoS Mitigations</a></li>
<li><a href="https://blog.cloudflare.com/xdpcap/">xdpcap: XDP Packet Capture</a></li>
<li><a href="https://netdevconf.org/0x13/session.html?talk-XDP-based-DDoS-mitigation">XDP based DoS mitigation</a> talk by Arthur Fabre</li>
<li><a href="https://netdevconf.org/2.1/papers/Gilberto_Bertin_XDP_in_practice.pdf">XDP in practice: integrating XDP into our DDoS mitigation pipeline</a> (PDF)</li>
</ul>
<p>During this project we encountered a number of eBPF/XDP limitations. One of them was the lack of concurrency primitives. It was very hard to implement things like race-free token buckets. Later we found that <a href="http://vger.kernel.org/lpc-bpf2018.html#session-9">Facebook engineer Julia Kartseva</a> had the same issues. In February this problem has been addressed with the introduction of <code>bpf_spin_lock</code> helper.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-26.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>While our modern volumetric DoS defenses are done in XDP layer, we still rely on <code>iptables</code> for application layer 7 mitigations. Here, a higher level firewall’s features are useful: connlimit, hashlimits and ipsets. We also use the <code>xt_bpf</code> iptables module to run cBPF in iptables to match on packet payloads. We talked about this in the past:</p>
<ul>
<li><a href="https://speakerdeck.com/majek04/lessons-from-defending-the-indefensible">Lessons from defending the indefensible</a> (PPT)</li>
<li><a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">Introducing the BPF tools</a></li>
</ul>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-34.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>After XDP and iptables, we have one final kernel side DoS defense layer.</p>
<p>Consider a situation when our UDP mitigations fail. In such case we might be left with a flood of packets hitting our application UDP socket. This might overflow the socket causing packet loss. This is problematic &#8211; both good and bad packets will be dropped indiscriminately. For applications like DNS it&#8217;s catastrophic. In the past to reduce the harm, we ran one UDP socket per IP address. An unmitigated flood was bad, but at least it didn&#8217;t affect the traffic to other server IP addresses.</p>
<p>Nowadays that architecture is no longer suitable. We are running more than 30,000 DNS IP&#8217;s and running that number of UDP sockets is not optimal. Our modern solution is to run a single UDP socket with a complex eBPF socket filter on it &#8211; using the <code>SO_ATTACH_BPF</code> socket option. We talked about running eBPF on network sockets in past blog posts:</p>
<ul>
<li><a href="https://blog.cloudflare.com/epbf_sockets_hop_distance/">eBPF, Sockets, Hop Distance and manually writing eBPF assembly</a></li>
<li><a href="https://blog.cloudflare.com/sockmap-tcp-splicing-of-the-future/">SOCKMAP &#8211; TCP splicing of the future</a></li>
</ul>
<p>The mentioned eBPF rate limits the packets. It keeps the state &#8211; packet counts &#8211; in an eBPF map. We can be sure that a single flooded IP won&#8217;t affect other traffic. This works well, though during work on this project we found a rather worrying bug in the eBPF verifier:</p>
<ul>
<li><a href="https://blog.cloudflare.com/ebpf-cant-count/">eBPF can&#8217;t count?!</a></li>
</ul>
<p>I guess running eBPF on a UDP socket is not a common thing to do.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-27.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Apart from the DoS, in XDP we also run a layer 4 load balancer layer. This is a new project, and we haven&#8217;t talked much about it yet. Without getting into many details: in certain situations we need to perform a socket lookup from XDP.</p>
<p>The problem is relatively simple &#8211; our code needs to look up the &#8220;socket&#8221; kernel structure for a 5-tuple extracted from a packet. This is generally easy &#8211; there is a <code>bpf_sk_lookup</code> helper available for this. Unsurprisingly, there were some complications. One problem was the inability to verify if a received ACK packet was a valid part of a three-way handshake when SYN-cookies are enabled. My colleague Lorenz Bauer is working on adding support for this corner case.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-28.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>After DoS and the load balancing layers, the packets are passed onto the usual Linux TCP / UDP stack. Here we do a socket dispatch &#8211; for example packets going to port 53 are passed onto a socket belonging to our DNS server.</p>
<p>We do our best to use vanilla Linux features, but things get complex when you use thousands of IP addresses on the servers.</p>
<p>Convincing Linux to route packets correctly is relatively easy with <a href="https://blog.cloudflare.com/how-we-built-spectrum">the &#8220;AnyIP&#8221; trick</a>. Ensuring packets are dispatched to the right application is another matter. Unfortunately, standard Linux socket dispatch logic is not flexible enough for our needs. For popular ports like TCP/80 we want to share the port between multiple applications, each handling it on a different IP range. Linux doesn&#8217;t support this out of the box. You can call <code>bind()</code> either on a specific IP address or all IP&#8217;s (with 0.0.0.0).</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-29.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>In order to fix this, we developed a custom kernel patch which adds <a href="https://patchwork.ozlabs.org/patch/602916/">a <code>SO_BINDTOPREFIX</code> socket option</a>. As the name suggests &#8211; it allows us to call <code>bind()</code> on a selected IP prefix. This solves the problem of multiple applications sharing popular ports like 53 or 80.</p>
<p>Then we run into another problem. For our Spectrum product we need to listen on all 65535 ports. Running so many listen sockets is not a good idea (see <a href="https://blog.cloudflare.com/revenge-listening-sockets/">our old war story blog</a>), so we had to find another way. After some experiments we learned to utilize an obscure iptables module &#8211; TPROXY &#8211; for this purpose. Read about it here:</p>
<ul>
<li><a href="https://blog.cloudflare.com/how-we-built-spectrum/">Abusing Linux&#8217;s firewall: the hack that allowed us to build Spectrum</a></li>
</ul>
<p>This setup is working, but we don&#8217;t like the extra firewall rules. We are working on solving this problem correctly &#8211; actually extending the socket dispatch logic. You guessed it &#8211; we want to extend socket dispatch logic by utilizing eBPF. Expect some patches from us.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-32.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Then there is a way to use eBPF to improve applications. Recently we got excited about doing TCP splicing with SOCKMAP:</p>
<ul>
<li><a href="https://blog.cloudflare.com/sockmap-tcp-splicing-of-the-future/">SOCKMAP &#8211; TCP splicing of the future</a></li>
</ul>
<p>This technique has a great potential for improving tail latency across many pieces of our software stack. The current SOCKMAP implementation is not quite ready for prime time yet, but the potential is vast.</p>
<p>Similarly, the new <a href="https://netdevconf.org/2.2/papers/brakmo-tcpbpf-talk.pdf">TCP-BPF aka BPF_SOCK_OPS</a> hooks provide a great way of inspecting performance parameters of TCP flows. This functionality is super useful for our performance team.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/12_prometheus-ebpf_exporter-100.jpg" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>Some Linux features didn&#8217;t age well and we need to work around them. For example, we are hitting limitations of networking metrics. Don&#8217;t get me wrong &#8211; the networking metrics are awesome, but sadly they are not granular enough. Things like <code>TcpExtListenDrops</code> and <code>TcpExtListenOverflows</code> are reported as global counters, while we need to know it on a per-application basis.</p>
<p>Our solution is to use eBPF probes to extract the numbers directly from the kernel. My colleague Ivan Babrou wrote a Prometheus metrics exporter called &#8220;ebpf_exporter&#8221; to facilitate this. Read on:</p>
<ul>
<li><a href="https://blog.cloudflare.com/introducing-ebpf_exporter/">Introducing ebpf_exporter</a></li>
<li><a href="https://github.com/cloudflare/ebpf_exporter">https://github.com/cloudflare/ebpf_exporter</a></li>
</ul>
<p>With &#8220;ebpf_exporter&#8221; we can generate all manner of detailed metrics. It is very powerful and saved us on many occasions.</p>
<p></p>
<hr>
<p></p>
<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2019/05/image-33.png" class="kg-image" alt="Cloudflare architecture and how BPF eats the world"></figure>
<p></p>
<p>In this talk we discussed 6 layers of BPFs running on our edge servers:</p>
<ul>
<li>Volumetric DoS mitigations are running on XDP eBPF</li>
<li>Iptables <code>xt_bpf</code> cBPF for application-layer attacks</li>
<li><code>SO_ATTACH_BPF</code> for rate limits on UDP sockets</li>
<li>Load balancer, running on XDP</li>
<li>eBPFs running application helpers like SOCKMAP for TCP socket splicing, and TCP-BPF for TCP measurements</li>
<li>&#8220;ebpf_exporter&#8221; for granular metrics</li>
</ul>
<p>And we&#8217;re just getting started! Soon we will be doing more with eBPF based socket dispatch, eBPF running on <a href="https://linux.die.net/man/8/tc">Linux TC (Traffic Control)</a> layer and more integration with cgroup eBPF hooks. Then, our SRE team is maintaining ever-growing list of <a href="https://github.com/iovisor/bcc">BCC scripts</a> useful for debugging.</p>
<p>It feels like Linux stopped developing new API&#8217;s and all the new features are implemented as eBPF hooks and helpers. This is fine and it has strong advantages. It&#8217;s easier and safer to upgrade eBPF program than having to recompile a kernel module. Some things like TCP-BPF, exposing high-volume performance tracing data, would probably be impossible without eBPF.</p>
<p>Some say &#8220;software is eating the world&#8221;, I would say that: &#8220;BPF is eating the software&#8221;.</p>
</div>
<footer class="entry-meta"><span class="tag-links"><a href="https://noise.getoto.net/tag/anycast/" rel="tag">Anycast</a><a href="https://noise.getoto.net/tag/developers/" rel="tag">Developers</a><a href="https://noise.getoto.net/tag/ebpf/" rel="tag">eBPF</a><a href="https://noise.getoto.net/tag/linux/" rel="tag">linux</a><a href="https://noise.getoto.net/tag/programming/" rel="tag">programming</a><a href="https://noise.getoto.net/tag/tcp/" rel="tag">TCP</a></span></footer></article>
<nav class="navigation paging-navigation" role="navigation">
<h1 class="screen-reader-text">Posts navigation</h1>
<div class="pagination loop-pagination">
<span aria-current="page" class="page-numbers current">1</span>
<a class="page-numbers" href="https://noise.getoto.net/tag/programming/page/2/">2</a>
<span class="page-numbers dots">&hellip;</span>
<a class="page-numbers" href="https://noise.getoto.net/tag/programming/page/20/">20</a>
<a class="next page-numbers" href="https://noise.getoto.net/tag/programming/page/2/">Next &rarr;</a> </div>
</nav>
</div>
</section>
<div id="secondary">
<h2 class="site-description">The collective thoughts of the interwebz</h2>
<div id="primary-sidebar" class="primary-sidebar widget-area" role="complementary">
<aside id="linkcat-1931" class="widget widget_links"><h1 class="widget-title">Contributors</h1>
<ul class='xoxo blogroll'>
<li><a href="http://www.devttys0.com" title="Embedded Device Hacking">/dev/ttyS0</a></li>
<li><a href="https://www.anchor.com.au" title="AWS automation, management and DevOps consulting services">Anchor | Cloud Engineering Services</a></li>
<li><a href="http://esr.ibiblio.org" title="Sex, software, politics, and firearms. Life&#8217;s simple pleasures&#8230;">Armed and Dangerous</a></li>
<li><a href="https://www.arp242.net/" title="Website of Martin Tournoij/arp242. I write about stuff, occasionally.">arp242.net</a></li>
<li><a href="https://aws.amazon.com/blogs/architecture/" title="Just another Amazon Web Services site">AWS Architecture Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/big-data/" title="Official Big Data Blog of Amazon Web Services">AWS Big Data Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/compute/">AWS Compute Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/devops/" title="Just another AWS Brew Blogs  site">AWS DevOps Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/messaging-and-targeting/" title="Just another AWS Brew Blogs  site">AWS Messaging &amp; Targeting Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/aws/" title="Announcements, Updates, and Launches">AWS News Blog</a></li>
<li><a href="https://aws.amazon.com/blogs/security/" title="The latest AWS security, identity, and compliance launches, announcements, and how-to posts.">AWS Security Blog</a></li>
<li><a href="https://www.backblaze.com/blog/" title="Cloud Storage &#038; Cloud Backup">Backblaze Blog | Cloud Storage &amp; Cloud Backup</a></li>
<li><a href="https://www.youtube.com/channel/UCuqokNoK8ZFNQdXxvlE129g">BeardedTinker</a></li>
<li><a href="https://bivol.bg" title="Съ рогата напрѣдъ!">Bivol.bg</a></li>
<li><a href="https://techblog.bozho.net" title="Tips and thoughts on developing software, by Bozhidar Bozhanov">Bozho&#039;s tech blog</a></li>
<li><a href="http://ebb.org/bkuhn/blog/" title="The personal blog of Bradley M. Kuhn (aka bkuhn ), in which he covers issues related to Free, Libre and Open Source Software, software freedom, licensing, GPL, copyleft and various other computer science topics.">Bradley M. Kuhn&#039;s Blog ( bkuhn )</a></li>
<li><a href="https://www.youtube.com/channel/UCVS6ejD9NLZvjsvhcbiDzjw">Crosstalk Solutions</a></li>
<li><a href="https://www.youtube.com/channel/UC726J5A0LLFRxQ0SZqr2mYQ">Curious Droid</a></li>
<li><a href="https://www.darknet.org.uk" title="Hacking Tools, Hacker News &#038; Cyber Security">Darknet</a></li>
<li><a href="https://deliantech.blogspot.com/" title="A little blog on IT topics, telecommunications and programming">Delian&#8217;s Tech blog</a></li>
<li><a href="https://devilsadvocatesecurity.blogspot.com/" title="&lt;center&gt;Devil&#8217;s Advocate Security is a blog dedicated to even handed discussion of security topics, security news, and  observations from the front lines of the daily business of IT security.&lt;/center&gt;">Devil&#8217;s Advocate Security</a></li>
<li><a href="https://www.youtube.com/channel/UC5ZdPKE2ckcBhljTc2R_qNA">digiblurDIY</a></li>
<li><a href="https://blog.erratasec.com/" title="Advanced persistent cybersecurity">Errata Security</a></li>
<li><a href="http://explosm.net" title="Flash Animations, Daily Comics and more!">Explosm.net</a></li>
<li><a href="https://eev.ee/">fuzzy notepad</a></li>
<li><a href="https://www.youtube.com/channel/UCHKRfxkMTqiiv4pF99qGKIw">Geographics</a></li>
<li><a href="https://engineering.grab.com/" title="Grab&#8217;s Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
">Grab Tech</a></li>
<li><a href="http://www.gatchev.info/blog" title="Just another WordPress site">Grigor Gatchev – A Weblog</a></li>
<li><a href="https://www.youtube.com/channel/UCbX3YkedQunLt7EQAdVxh7w">Home Assistant</a></li>
<li><a href="https://ibms360.co.uk" title="Documenting the recovery and restoration of an IBM System 360 Model 20 and potentially an IBM System 370 Model 125">IBM 360 Model 20 Rescue and Restoration</a></li>
<li><a href="https://www.joelonsoftware.com">Joel on Software</a></li>
<li><a href="http://kendov.com" title="Новини">Kendov.com</a></li>
<li><a href="https://www.youtube.com/channel/UC3XTzVzaHQEd30rQbuvCtTQ">LastWeekTonight</a></li>
<li><a href="https://laur.ie/blog" title="Sometimes I make things or think things. Here they are.">laur.ie&#039;s blog</a></li>
<li><a href="https://lcamtuf.blogspot.com/">lcamtuf&#8217;s blog</a></li>
<li><a href="https://letsencrypt.org/" title="  Let&#8217;s Encrypt is a free, automated, and open certificate
  authority brought to you by the nonprofit &lt;a href=&quot;https://www.abetterinternet.org/&quot;&gt;Internet Security Research Group (ISRG)&lt;/a&gt;.
">Let&#039;s Encrypt</a></li>
<li><a href="https://www.youtube.com/channel/UCLx053rWZxCiYWsBETgdKrQ">LGR</a></li>
<li><a href="https://lwn.net" title="
 LWN.net is a comprehensive source of news and opinions from
        and about the Linux community.  This is the main LWN.net feed,
        listing all articles which are posted to the site front page.

    ">LWN.net</a></li>
<li><a href="https://www.youtube.com/channel/UCL5Hf6_JIzb3HpiJQGqs8cQ">Matt Granger</a></li>
<li><a href="https://mjg59.dreamwidth.org/" title="Matthew Garrett &#8211; Dreamwidth Studios">Matthew Garrett</a></li>
<li><a href="https://monty-says.blogspot.com/" title="Rambling thoughts about recent events in MariaDB / MySQL or Free software/Open source">Monty says</a></li>
<li><a href="https://netflixtechblog.com" title="Learn about Netflix’s world class engineering efforts, company culture, product developments and more. &#8211; Medium">Netflix TechBlog &#8211; Medium</a></li>
<li><a href="https://blog.ntpsec.org/" title="The blog for the NTPsec Project. NTPsec is a secure, hardened, and improved implementation of Network Time Protocol derived from NTP Classic, Dr. David Mills’s original. Our goal is to deliver code that can be used with confidence in deployments with the ">NTPsec Project Blog</a></li>
<li><a href="https://www.oglaf.com/latest/" title="Comics. Often dirty. Updates Sundays.">Oglaf! &#8212; Comics. Often dirty.</a></li>
<li><a href="https://0pointer.net/blog/">Pid Eins</a></li>
<li><a href="https://prometheus.io/">Prometheus Blog</a></li>
<li><a href="https://blog.rapid7.com/" title="Rapid7 transforms data into insight, empowering security professionals to progress and protect their organizations.">Rapid7 Blog</a></li>
<li><a href="https://www.raspberrypi.org" title="Teach, learn and make with Raspberry Pi">Raspberry Pi Foundation blog: news, announcements, stories, ideas</a></li>
<li><a href="https://www.schneier.com">Schneier on Security</a></li>
<li><a href="http://devopscafe.org/show/" title="Show Notes">Show Notes</a></li>
<li><a href="https://spritesmods.com" title="Sprites mods: website documenting various hardware and software mods and hacks.">Sprites mods</a></li>
<li><a href="https://www.youtube.com/channel/UCbmNph6atAoGfqLoCL_duAg">Talks at Google</a></li>
<li><a href="https://www.youtube.com/channel/UC5I2hjZYiW9gZPVkvzM8_Cw">Techmoan</a></li>
<li><a href="https://www.youtube.com/channel/UClRwC5Vc8HrB6vGx6Ti-lhA">Technology Connextras</a></li>
<li><a href="https://www.youtube.com/channel/UCK0z0_5uL7mb9IjntOKi5XQ">The Atlantic</a></li>
<li><a href="https://blog.cloudflare.com/" title="Get the latest news on how products at Cloudflare are built, technologies used, and join the teams helping to build a better Internet.">The Cloudflare Blog</a></li>
<li><a href="http://thecodelesscode.com" title="Kōans for the Software Engineer &#8212; An illustrated collection of (sometimes violent) fables, concerning the Art and Philosophy of software development.">The Codeless Code</a></li>
<li><a href="https://github.blog" title="Updates, ideas, and inspiration from GitHub to help developers build and design software.">The GitHub Blog: Engineering News and Updates</a></li>
<li><a href="https://www.youtube.com/channel/UC4sEmXUuWIFlxRIFBRV6VXQ">The History Guy: History Deserves to Be Remembered</a></li>
<li><a href="https://www.youtube.com/channel/UC2gyzKcHbYfqoXA5xbyGXtQ">The Hook Up</a></li>
<li><a href="https://turnoff.us/" title="turnoff.us is a geek comic site. Comics about Programming Languages, Web, Cloud, Linux, etc.">turnoff.us &#8211; geek comic site</a></li>
<li><a href="https://xkcd.com/">xkcd.com</a></li>
<li><a href="https://yahooeng.tumblr.com/" title="A peek under the purple rug!">Yahoo Engineering</a></li>
<li><a href="https://blog.yate.ro">Yate – Software Defined Mobile Networks</a></li>
<li><a href="https://yovko.net/" title="Размисли, истории и идеи от Йовко Ламбрев">yovko in a nutshell</a></li>
<li><a href="https://blog.zabbix.com/" title="The Future of Monitoring">Zabbix Blog</a></li>
<li><a href="https://blog.bozho.net" title="блог на Божидар Божанов">БЛОГодаря</a></li>
<li><a href="https://delian.blogspot.com/" title="Трябва много да ви е скучно, щом сте стигнали дотук&#8230;">Блогът на Делян Делчев</a></li>
<li><a href="https://yurukov.net/blog" title="Нещата които искам да споделя с другите">Блогът на Юруков</a></li>
<li><a href="http://georgi.unixsol.org/diary/" title="Мрън, мрън, всеки ден.">Дневникът на Георги</a></li>
<li><a href="http://dni.li">Дни</a></li>
<li><a href="http://kaka-cuuka.com">Како Сийке, не съм от тях!</a></li>
<li><a href="https://nookofselene.wordpress.com">Кътчето на Селин</a></li>
<li><a href="https://nellyo.wordpress.com" title=" [Media Law]   [Nelly Ognyanova]  ">Медийно право </a></li>
<li><a href="https://alex.stanev.org/blog" title="мисли, чувства, съмнения&#8230;">Неосъзнато</a></li>
<li><a href="https://vasil.ludost.net/blog" title="Имам теле в главата.">татко Крокодил</a></li>
<li><a href="https://toest.bg" title="Смисълът на новините">Тоест</a></li>
</ul>
</aside>
<aside id="tag_cloud-3" class="widget widget_tag_cloud"><h1 class="widget-title">Tags</h1><div class="tagcloud"><a href="https://noise.getoto.net/tag/ad/" class="tag-cloud-link tag-link-6101 tag-link-position-1" style="font-size: 11.92pt;" aria-label="AD (2,960 items)">AD</a>
<a href="https://noise.getoto.net/tag/ai/" class="tag-cloud-link tag-link-3287 tag-link-position-2" style="font-size: 16.4pt;" aria-label="AI (4,284 items)">AI</a>
<a href="https://noise.getoto.net/tag/all/" class="tag-cloud-link tag-link-63 tag-link-position-3" style="font-size: 16.96pt;" aria-label="All (4,424 items)">All</a>
<a href="https://noise.getoto.net/tag/app/" class="tag-cloud-link tag-link-111 tag-link-position-4" style="font-size: 16.4pt;" aria-label="app (4,282 items)">app</a>
<a href="https://noise.getoto.net/tag/art/" class="tag-cloud-link tag-link-119 tag-link-position-5" style="font-size: 17.24pt;" aria-label="art (4,525 items)">art</a>
<a href="https://noise.getoto.net/tag/ati/" class="tag-cloud-link tag-link-126 tag-link-position-6" style="font-size: 19.76pt;" aria-label="ATI (5,686 items)">ATI</a>
<a href="https://noise.getoto.net/tag/aws/" class="tag-cloud-link tag-link-141 tag-link-position-7" style="font-size: 8.28pt;" aria-label="AWS (2,172 items)">AWS</a>
<a href="https://noise.getoto.net/tag/bec/" class="tag-cloud-link tag-link-172 tag-link-position-8" style="font-size: 8.84pt;" aria-label="BEC (2,306 items)">BEC</a>
<a href="https://noise.getoto.net/tag/ble/" class="tag-cloud-link tag-link-6177 tag-link-position-9" style="font-size: 9.4pt;" aria-label="ble (2,416 items)">ble</a>
<a href="https://noise.getoto.net/tag/c/" class="tag-cloud-link tag-link-239 tag-link-position-10" style="font-size: 22pt;" aria-label="C (6,797 items)">C</a>
<a href="https://noise.getoto.net/tag/cas/" class="tag-cloud-link tag-link-257 tag-link-position-11" style="font-size: 8pt;" aria-label="CAS (2,152 items)">CAS</a>
<a href="https://noise.getoto.net/tag/ci/" class="tag-cloud-link tag-link-5674 tag-link-position-12" style="font-size: 10.52pt;" aria-label="ci (2,606 items)">ci</a>
<a href="https://noise.getoto.net/tag/code/" class="tag-cloud-link tag-link-301 tag-link-position-13" style="font-size: 9.12pt;" aria-label="code (2,358 items)">code</a>
<a href="https://noise.getoto.net/tag/curity/" class="tag-cloud-link tag-link-358 tag-link-position-14" style="font-size: 9.4pt;" aria-label="Curity (2,379 items)">Curity</a>
<a href="https://noise.getoto.net/tag/data/" class="tag-cloud-link tag-link-387 tag-link-position-15" style="font-size: 9.68pt;" aria-label="data (2,450 items)">data</a>
<a href="https://noise.getoto.net/tag/ec/" class="tag-cloud-link tag-link-6518 tag-link-position-16" style="font-size: 12.48pt;" aria-label="ec (3,116 items)">ec</a>
<a href="https://noise.getoto.net/tag/ed/" class="tag-cloud-link tag-link-492 tag-link-position-17" style="font-size: 20.88pt;" aria-label="ed (6,159 items)">ed</a>
<a href="https://noise.getoto.net/tag/et/" class="tag-cloud-link tag-link-5657 tag-link-position-18" style="font-size: 13.88pt;" aria-label="et (3,444 items)">et</a>
<a href="https://noise.getoto.net/tag/go/" class="tag-cloud-link tag-link-656 tag-link-position-19" style="font-size: 16.4pt;" aria-label="Go (4,304 items)">Go</a>
<a href="https://noise.getoto.net/tag/hat/" class="tag-cloud-link tag-link-6839 tag-link-position-20" style="font-size: 10.24pt;" aria-label="HAT (2,545 items)">HAT</a>
<a href="https://noise.getoto.net/tag/ice/" class="tag-cloud-link tag-link-2947 tag-link-position-21" style="font-size: 12.48pt;" aria-label="ICE (3,102 items)">ICE</a>
<a href="https://noise.getoto.net/tag/ip/" class="tag-cloud-link tag-link-790 tag-link-position-22" style="font-size: 18.08pt;" aria-label="IP (4,944 items)">IP</a>
<a href="https://noise.getoto.net/tag/irs/" class="tag-cloud-link tag-link-796 tag-link-position-23" style="font-size: 11.64pt;" aria-label="irs (2,865 items)">irs</a>
<a href="https://noise.getoto.net/tag/iss/" class="tag-cloud-link tag-link-802 tag-link-position-24" style="font-size: 10.52pt;" aria-label="iss (2,601 items)">iss</a>
<a href="https://noise.getoto.net/tag/make/" class="tag-cloud-link tag-link-961 tag-link-position-25" style="font-size: 12.76pt;" aria-label="Make (3,138 items)">Make</a>
<a href="https://noise.getoto.net/tag/mit/" class="tag-cloud-link tag-link-1017 tag-link-position-26" style="font-size: 8.84pt;" aria-label="mit (2,312 items)">mit</a>
<a href="https://noise.getoto.net/tag/nes/" class="tag-cloud-link tag-link-1075 tag-link-position-27" style="font-size: 11.92pt;" aria-label="NES (2,937 items)">NES</a>
<a href="https://noise.getoto.net/tag/oss/" class="tag-cloud-link tag-link-1145 tag-link-position-28" style="font-size: 9.4pt;" aria-label="OSS (2,396 items)">OSS</a>
<a href="https://noise.getoto.net/tag/other/" class="tag-cloud-link tag-link-1148 tag-link-position-29" style="font-size: 13.88pt;" aria-label="Other (3,503 items)">Other</a>
<a href="https://noise.getoto.net/tag/r/" class="tag-cloud-link tag-link-6394 tag-link-position-30" style="font-size: 16.12pt;" aria-label="R (4,212 items)">R</a>
<a href="https://noise.getoto.net/tag/rat/" class="tag-cloud-link tag-link-1294 tag-link-position-31" style="font-size: 16.4pt;" aria-label="rat (4,244 items)">rat</a>
<a href="https://noise.getoto.net/tag/rest/" class="tag-cloud-link tag-link-1311 tag-link-position-32" style="font-size: 8.84pt;" aria-label="rest (2,269 items)">rest</a>
<a href="https://noise.getoto.net/tag/rov/" class="tag-cloud-link tag-link-1334 tag-link-position-33" style="font-size: 12.2pt;" aria-label="ROV (2,993 items)">ROV</a>
<a href="https://noise.getoto.net/tag/rti/" class="tag-cloud-link tag-link-3768 tag-link-position-34" style="font-size: 8pt;" aria-label="RTI (2,145 items)">RTI</a>
<a href="https://noise.getoto.net/tag/s/" class="tag-cloud-link tag-link-1345 tag-link-position-35" style="font-size: 20.04pt;" aria-label="S. (5,741 items)">S.</a>
<a href="https://noise.getoto.net/tag/security/" class="tag-cloud-link tag-link-1381 tag-link-position-36" style="font-size: 11.08pt;" aria-label="security (2,754 items)">security</a>
<a href="https://noise.getoto.net/tag/sts/" class="tag-cloud-link tag-link-1476 tag-link-position-37" style="font-size: 8.56pt;" aria-label="sts (2,233 items)">sts</a>
<a href="https://noise.getoto.net/tag/support/" class="tag-cloud-link tag-link-1484 tag-link-position-38" style="font-size: 8.56pt;" aria-label="support (2,219 items)">support</a>
<a href="https://noise.getoto.net/tag/ted/" class="tag-cloud-link tag-link-5213 tag-link-position-39" style="font-size: 12.2pt;" aria-label="ted (3,005 items)">ted</a>
<a href="https://noise.getoto.net/tag/tor/" class="tag-cloud-link tag-link-1569 tag-link-position-40" style="font-size: 16.4pt;" aria-label="tor (4,217 items)">tor</a>
<a href="https://noise.getoto.net/tag/ui/" class="tag-cloud-link tag-link-1601 tag-link-position-41" style="font-size: 16.4pt;" aria-label="UI (4,314 items)">UI</a>
<a href="https://noise.getoto.net/tag/un/" class="tag-cloud-link tag-link-5663 tag-link-position-42" style="font-size: 14.44pt;" aria-label="un (3,610 items)">un</a>
<a href="https://noise.getoto.net/tag/us/" class="tag-cloud-link tag-link-1613 tag-link-position-43" style="font-size: 22pt;" aria-label="US (6,825 items)">US</a>
<a href="https://noise.getoto.net/tag/win/" class="tag-cloud-link tag-link-1708 tag-link-position-44" style="font-size: 10.52pt;" aria-label="win (2,641 items)">win</a>
<a href="https://noise.getoto.net/tag/work/" class="tag-cloud-link tag-link-2986 tag-link-position-45" style="font-size: 11.64pt;" aria-label="Work (2,897 items)">Work</a></div>
</aside> </div>
</div>
</div>
<footer id="colophon" class="site-footer" role="contentinfo">
<div class="site-info">
Proudly powered by Ants
</div>
</footer>
</div>
<link rel='stylesheet' id='basecss-css' href='https://noise.getoto.net/wp-content/plugins/eu-cookie-law/css/style.css?ver=5.8.4' type='text/css' media='all' />
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script type='text/javascript' src='https://noise.getoto.net/wp-content/themes/z/js/functions.js?ver=20150315' id='twentyfourteen-script-js'></script>
<script type='text/javascript' id='eucookielaw-scripts-js-extra'>
/* <![CDATA[ */
var eucookielaw_data = {"euCookieSet":"","autoBlock":"0","expireTimer":"360","scrollConsent":"0","networkShareURL":"","isCookiePage":"","isRefererWebsite":""};
/* ]]> */
</script>
<script type='text/javascript' src='https://noise.getoto.net/wp-content/plugins/eu-cookie-law/js/scripts.js?ver=3.1.6' id='eucookielaw-scripts-js'></script>
<div class="pea_cook_wrapper pea_cook_bottomright" style="color:#FFFFFF;background:rgb(0,0,0);background: rgba(0,0,0,0.85);"><p>By continuing to use the site, you agree to the use of cookies. <a style="color:#FFFFFF;" href="#" id="fom">more information</a> <button id="pea_cook_btn" class="pea_cook_btn">Accept</button></p></div><div class="pea_cook_more_info_popover"><div class="pea_cook_more_info_popover_inner" style="color:#FFFFFF;background-color: rgba(0,0,0,0.9);"><p>The cookie settings on this website are set to "allow cookies" to give you the best browsing experience possible. If you continue to use this website without changing your cookie settings or you click "Accept" below then you are consenting to this.</p><p><a style="color:#FFFFFF;" href="#" id="pea_close">Close</a></p></div></div><script>(function(){var js = "window['__CF$cv$params']={r:'737aa8cd6e0682a5',m:'BHT6ODC3onElgxsO2cWVW16UdCdpAiq24SfLiYsdxMo-1659986951-0-AU5tZTT7fgpwsa+cees0poaNybOTCVTKm7CxqOPSCFQyOgOgRs/toQh5cNyl5HeyMDeLLd6ufpJVHeKfp3c4Tx4dKY+BXRG+2blkxDcKGH+Ki12gayObXbt3bt8qz2D4dECbBDyPDrejonpbroAsRqE=',s:[0xc7b3ca99c5,0xbd898fe0b4],u:'/cdn-cgi/challenge-platform/h/g'};var now=Date.now()/1000,offset=14400,ts=''+(Math.floor(now)-Math.floor(now%offset)),_cpo=document.createElement('script');_cpo.nonce='',_cpo.src='/cdn-cgi/challenge-platform/h/g/scripts/alpha/invisible.js?ts='+ts,document.getElementsByTagName('head')[0].appendChild(_cpo);";var _0xh = document.createElement('iframe');_0xh.height = 1;_0xh.width = 1;_0xh.style.position = 'absolute';_0xh.style.top = 0;_0xh.style.left = 0;_0xh.style.border = 'none';_0xh.style.visibility = 'hidden';document.body.appendChild(_0xh);function handler() {var _0xi = _0xh.contentDocument || _0xh.contentWindow.document;if (_0xi) {var _0xj = _0xi.createElement('script');_0xj.nonce = '';_0xj.innerHTML = js;_0xi.getElementsByTagName('head')[0].appendChild(_0xj);}}if (document.readyState !== 'loading') {handler();} else if (window.addEventListener) {document.addEventListener('DOMContentLoaded', handler);} else {var prev = document.onreadystatechange || function () {};document.onreadystatechange = function (e) {prev(e);if (document.readyState !== 'loading') {document.onreadystatechange = prev;handler();}};}})();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"737aa8cd6e0682a5","version":"2022.6.0","r":1,"token":"cecbc7705ec84a85ad1fb6c36eaeb0f3","si":100}' crossorigin="anonymous"></script>
</body>
</html>
